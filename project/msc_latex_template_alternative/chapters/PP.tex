\chapter{Probabilistic Programming} \label{ch:pp}

This chapter begins with an introduction to Banach spaces based on \cite{rudin91functional,InfiniteDimensionalAnalysis2006, ryanIntroductionTensorProducts2013}. We then show that $\catBan$, the category of Banach spaces and short maps, is a model in this setting. The  next section  introduces the fundamentals of measure theory, a key component in defining the semantics of probabilistic programs, drawing inspiration primarily from \cite{dahlqvistSemanticsProbabilisticProgramming2020a, bogachevMeasureTheory2007,InfiniteDimensionalAnalysis2006}.  
Finally, we study approximate equivalence in the context of a random walk on the real line.



\section{Banach spaces}




\subsection{Normed spaces}

\begin{definition} \label{def:norm}
  A \emph{norm} \gls{norm} is a function that associates an element of a vector space $V$ with a non-negative real number, such that the following properties hold:
  \begin{enumerate}
    \item Positive definiteness: $\|v\| \geq 0$ for all $v \in V$, with $\|v\| = 0$ if and only if $v = 0$;
    \item Positive scalability: $\|av\| = |a|\|v\|$ for all $v \in V$ scalar $a$;
    \item The triangle inequality: $\|v + w\| \leq \|v\| + \|w\|$ for all $v, w \in V$.
  \end{enumerate}
\end{definition}

\begin{definition} \label{def:normed_space}
A vector space together with a norm is called a \emph{normed vector space}.
\end{definition}


Every normed space may be regarded as a metric space, in which the
distance \gls{distance} between vectors $x$ and $y$ is $\|x-y\|$ . The relevant properties of $d(x,y)$ are

\begin{enumerate}
  \item $ d(x, y) \leq 0 $ for all $x$ and $y$, with equality holding iff $x = y$,
  \item $d(x, y) = d(y, x)$ for all $x$ and $y$,
  \item $d(x, z) < d(x, y) + d(y, z)$ for all $x, y, z$.
\end{enumerate}

\begin{definition} \label{def:op_norm}
Let \( V \) and \( W \) be normed vector spaces, and let \( T: V \rightarrow W \) be a linear operator. The \emph{operator norm}, denoted by \gls{op-norm}, is defined as
\[
\norm{T}_{\text{op}} = \sup \{ \norm{T(v)} : v \in V, \, \norm{v} = 1 \}.
\]
If \( \norm{T}_{\text{op}} < \infty \), we say that \( T \) is a \emph{bounded operator}; otherwise, if \( \norm{T}_{\text{op}} = \infty \), we say that \( T \) is \emph{unbounded}. We denote by \gls{boundedoperators} the vector space of all bounded linear operators from \( V \) to \( W \), and we write  \gls{boundedoperatorsVV} for \( \mathcal{B}(V, V) \).
\end{definition}

\begin{lemma} \cite[Lemma 6.4]{InfiniteDimensionalAnalysis2006} \label{lemma:op_norm_submult} %inf_dim_anal
Let \( T: V \rightarrow W \) be a bounded linear operator between normed spaces. Then the following statements hold:
\begin{enumerate}
  \item For every \( v \in V \), we have $
  \norm{T(v)} \leq \norm{T}_{\text{op}} \cdot \norm{x}.$
  \item The operator \( T \) is continuous if and only if it is bounded.
\end{enumerate}
\end{lemma}




\begin{definition}
  Let \( V \) and \( W \) be normed vector spaces, and let \( T: V \rightarrow W \) be a linear operator. $T$ is called a \emph{short map} if $\opnorm{T} \leq 1$.
\end{definition}



\subsection{Banach spaces}

\begin{definition} (\emph{Cauchy sequence})
  Suppose $ d $ is a metric on a set $ X $. A sequence $ \{x_n\} \subset X $ is called a \emph{Cauchy sequence} if, for every $ \varepsilon > 0 $, there exists an integer $N \in \mathbb{N} $ such that $ d(x_m, x_n) < \varepsilon $ for all $ m, n > N $.  The metric \( d \) is said to be \emph{complete} if every Cauchy sequence in \( X \) converges to a point in \( X \)
\end{definition}

\begin{definition}
  A \emph{Banach space} is a normed vector space that is complete with respect to the metric induced by its norm. In other words, every Cauchy sequence in the space must converge to a limit within the space.
\end{definition}
 

\todo[inline,size=\normalsize]{Meter isto direito -> Aqui está apenas a prop universal}


\begin{definition} [Algebraic Tensor Product]
The tensor product of vector spaces \( V \) and \( W \) is a vector space 
\( V \otimes W \) together with a bilinear function (\ie linear in both variables)
\(f : V \times W \to V \otimes W\)
such that for every bilinear function \( g: V \times W \to R \), there exists a unique linear function 
\(h: V \otimes W \to R\)
such that \( g = h \circ f \).
\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes,row sep=4em,column sep=7em,minimum width=2em]
  {
   V \times W  & V \otimes W    \\
      & R \\
  };
  \path[-stealth]
    (m-1-1) edge  node [above] {$f$} (m-1-2)
    (m-1-1) edge  node [below] {$g$} (m-2-2)
    (m-1-2) edge [dotted]  node [right] {$h$} (m-2-2);
    ;
\end{tikzpicture}
\]
The function \( f \) usually remains anonymous and is written as \( (a, b) \mapsto a \otimes b \).

It follows that arbitrary elements of \( V \otimes W \) take the form 
\[
\sum_{i=1}^{n} a_i (v_i \otimes w_i)
\]
for \( a_i \in \mathbb{C} \), \( v_i \in V \), and \( w_i \in W \).

The tensor product also extends to linear maps. If 
\(f_1: V_1 \to W_1 \quad \text{and} \quad f_2: V_2 \to W_2\)
are linear maps, then there is a unique linear map 
\(
f_1 \otimes f_2: V_1 \otimes V_2 \to W_1 \otimes W_2
\)
that satisfies
\[(f_1 \otimes f_2)(v_1 \otimes v_2) = f_1(v_1) \otimes f_2(v_2)
\]
for all \( v_1 \in V_1 \), \( v_2 \in V_2 \).
\end{definition}

\begin{comment}
\begin{definition} [Algebraic Tensor Product]
  Let \( V_1, \dots, V_n \) and \( W \) be vector spaces, and let
\[
\varphi : V_1 \times \cdots \times V_n \to W
\]
be a multilinear function, meaning a function for which the mapping
\[
u_k \mapsto \varphi(u_1, \dots, u_n)
\]
is linear for each \( k \in \{1, \dots, n\} \) and every fixed choice of vectors \( u_1, \dots, u_{k-1}, u_{k+1}, \dots, u_n \).

Then there exists a unique linear mapping
\[
A : V_1 \otimes \cdots \otimes V_n \to W
\]
such that
\[
\varphi(u_1, \dots, u_n) = A(u_1 \otimes \cdots \otimes u_n)
\]
for all choices of \( u_1 \in V_1, \dots, u_n \in V_n \).
\end{definition}
\end{comment}

\begin{definition}
  Let $V$ and $W$ be Banach spaces. Let $u$ be any element of $V \otimes W$. The \emph{projective norm}, denoted $\norm{ \cdot }_{\pi}$,  is defined by: 
  \[
 \projnorm{u} = \inf\left\{ \sum_{i=1}^n \norm{v_i} \norm{w_i} \Bigg| \, u = \sum_{i=1}^n v_i \otimes w_i\right\}.
\]
\end{definition}

%\begin{proposition} %ryan-artigoprofRenato \label{prop:proj_norm_tensor_mult}
   %Let $V$ and $W$ be Banach spaces. Then, for every $v \in V$ and $w \in W$, it holds that $ \projnorm{v \otimes w} = \norm{v} \otimes \norm{w}$.
%\end{proposition}

\begin{definition}
  Let \( V \) and \( W \) be Banach spaces. The \emph{projective tensor product} of \( V \) and \( W \), denoted  $ V \widehat{\otimes}_\pi W$, is the completion of the algebraic tensor product \( V \otimes W \) with respect to the projective norm \( \projnorm{\cdot} \).
\end{definition}


\section{Category Ban}

\todo[inline,size=\normalsize]{falta o producto tensorial e dizer o que é a L1 norm e tb soma direta, i guess}

\begin{definition}
Let \( x = (x_1, x_2, \dots, x_n) \in \mathbb{C}^n \). The \( L^1 \) norm, \gls{l1_norm},  is defined by
\[
\|x\|_{L^1} = \sum_{i=1}^n |x_i|.
\]
\end{definition}

\begin{definition}
  The category $\catBan$ is the category of Banach spaces and short maps.  In the category \(\catBan\), the coproduct of Banach spaces is given by their direct sum equipped with the \(L_1\)-norm. The injections and copairing map are defined analogously to those in \(\catVect\). 
\end{definition}


\begin{lemma} \label{lem_op_max_trace}
  Let $V$, $W$ and $U$ be Banach spaces. Let $ T: V \to U$ and $ S: W \to U$ be short maps. Then, it holds that 
  $$ \opnorm{[T, S]} \leq \sup \{\opnorm{T},\opnorm{S}\}$$
\end{lemma}

\begin{proof}
We calculate,
\begin{align*} 
   \opnorm{[T, S]} &  = \text{sup}{\{ \norm{[T, S] (v_0)}   \hspace{2pt} |  \hspace{2pt}  \norm{(v_0)} = 1  \}}\\
   & = \text{sup}{\{ \norm{[T, S] (v, w)}   \hspace{2pt} |  \hspace{2pt}  \norm{(v, w )} = 1  \}}  \\
   & = \sup \left\{  \norm{T (v) + S (w)}  \, \vert \, \norm{v} + \norm{w}= 1 \right\} \\
   & \leq \sup \left\{  \norm{T (v)} + \norm{S (w)}  \, \vert \, \norm{v} + \norm{w}= 1 \right\} \\
   & = \sup \left\{ \norm{v} \cdot   T \left( v / \norm{v }\right) + \norm{w} \cdot S \left( w / \norm{w}\right)  \, \vert \, \norm{v} + \norm{w}= 1  \right\}  \\
   & = \sup  \left\{ \sup \left\{\norm{T(v)}   \hspace{2pt} |  \hspace{2pt}  \norm{(v)} = 1  \right\},\sup \left\{\norm{S(w)}   \hspace{2pt} |  \hspace{2pt}  \norm{(w)} = 1   \right\}  \right\} \\
   & = \sup \{\opnorm{T},\opnorm{S}\}
\end{align*}
 
\end{proof}


\begin{theorem} \cite[Theorem 4.3]{dahlqvist2023syntactic} \label{thm:ban_monoidal_met}
      The category $\catBan$ is a  symmetric monoidal $\catMet$-category.
  \end{theorem}

  \begin{theorem}
      The category $\catBan$ is a  symmetric monoidal $\catMet$-category with binary coproducts.
  \end{theorem}

\begin{proof}
  Considering the definition of a symmetric monoidal $\catMet$-category with binary coproducts, this follows directly from \autoref{thm:ban_monoidal_met} and \autoref{lem_op_max_trace}.    
\end{proof}



\section{Measure theory}
Probabilistic computation involves running programs incorporating randomness, leading to output behaviors characterized by probability distributions rather than deterministic outcomes. To effectively understand and analyze these programs, it is essential to have a solid foundation in reasoning about probability distributions. That is where measure theory comes into play.


In this work, we only consider finitemeasures; hence, the term ``measure" implicitly refers to a finite measure unless stated otherwise.

\subsection{What is measure theory?}

Throughout history, mathematicians sought to extend the ideas of length, area, and volume. The most effective way to generalize these concepts is through the idea of a measure. Abstractly, a measure is a function defined on sets with additive properties mirroring length, area, and volume.

We begin with a simple example inspired by \cite{athreyaMeasureTheoryProbability2006} to develop an intuition for the concepts of measure and measure space.
Imagine an open field $S$ covered in snow after a storm. Suppose we wish to measure the amount of snow accumulated in as many field regions as possible.
Assume we have accurate tools for measuring snow over standard geometric shapes like triangles, rectangles, and circles. 
We can approximate irregularly shaped regions using combinations of these standard shapes and then apply a limiting process to assign a consistent measure to such regions. 
Let $\mathcal{B}$ denote the collection of subsets of $S$ that are deemed \emph{measurable}, let $\lambda(A)$ represent the amount of snow in each $A \in \mathcal{B}$, and let $A^c$ denote the complement of a set $A$.


For this framework to make sense, it is reasonable to require that $ \mathcal{B}$ and $\lambda (\cdot)$ satisfy the following properties:

\subsubsection*{Properties of $B$:}
\begin{enumerate}
    \item If $A \in B$, then the complement $A^c \in \mathcal{B}$. (\ie, if we can measure the snow on a set $A$, and we know the total amount on $S$, then we can determine the snow on the remaining part $A^c$.)
    \item If $A_1, A_2 \in \mathcal{B}$, then \(A_1 \cup A_2 \in \mathcal{B}\).  
    (\ie, if we can measure the snow on two regions \(A_1\) and \(A_2\), we should also be able to measure it on their union.)
    \item If $\{A_n\}_{n \geq 1} \subset \mathcal{B}$ is an increasing sequence, \ie, $A_n \subset A_{n+1}$ for all $n$, then $\bigcup_{n=1}^{\infty} A_n \in \mathcal{B}$.  
    \\(\ie, if each set in a increasing sequence of regions is measurable, then their limit—the union—should also be measurable.)
    \item The collection $\mathcal{B}$ contains a base class $C$ of simple, well-behaved sets (e.g., triangles, rectangles, circles) for which measurement is initially defined.
\end{enumerate}

\subsubsection*{Properties of $\lambda (\cdot)$:}
\begin{enumerate}
    \item  $\lambda(A) \geq 0$ for all $A \in \mathcal{B}$ (\ie, the amount of snow on any set must be nonnegative). 
    \item If $A_1, A_2 \in \mathcal{B}$ and $A_1 \cap A_2 = \emptyset$, then  
    $\lambda(A_1 \cup A_2) = \lambda(A_1) + \lambda(A_2)$
 (\ie, The total amount of snow over two non-overlapping regions is just the sum of the snow in each region. This characteristic of 
$\lambda$ is known as \emph{finite additivity}.)
    \item If $\{A_n\}_{n \geq 1} \subset \mathcal{B}$ is an increasing sequence, \ie, $A_n \subset A_{n+1}$ then  
    $
    \lambda( \lim_{n \to \infty} A_n) = \lambda\left( \bigcup_{n=1}^\infty A_n \right) = \lim_{n \to \infty} \lambda(A_n).
    $
    (\ie, if a set can be approximated by an increasing sequence of measurable sets $\{A_n\}_{n \geq 1}$, then $\lambda(A) = \lim_{n \to \infty} \lambda(A_n)$. This is known as \emph{monotone continuity from below}.)
\end{enumerate}

\subsection{Measurable spaces and measures}
Remarkably, these  intuitive conditions give rise to a profoundly versatile and far-reaching theoretical framework. The requirements imposed on $\mathcal{B}$ and $\lambda$ can equivalently be stated as follows:

\subsubsection*{Properties of $\mathcal{B}$:}
\begin{enumerate}
    \item $\emptyset \in \mathcal{B}$.
    \item $A \in \mathcal{B}  \implies A^c \in \mathcal{B}$. 
    \item  $A_1, A_2, \dots \in \mathcal{B} \implies \bigcup_i A_i \in \mathcal{B}$ (this is known as \emph{closure
 under countable unions}).
\end{enumerate}

\subsubsection*{Properties of $\lambda$:}
\begin{enumerate}
    \item $\lambda(\cdot) \geq 0$  and $\lambda(\emptyset) = 0$.
    \item  If \(\{A_n\}_{n \geq 1} \subset \mathcal{B}\) is a sequence of pairwise disjoint sets (i.e., \(A_i \cap A_j = \emptyset\) for \(i \neq j\)), then
    $\lambda\left( \bigcup_{n=1}^\infty A_n \right) = \sum_{n=1}^\infty \lambda(A_n)$ (this is known as \emph{countable additivity}). 
\end{enumerate}

A collection $\mathcal{B}$ of subsets of $S$ satisfying the above conditions for $B$ is designated a $\sigma$\emph{-algebra}. Similarly, a set function $\lambda$ defined on a $\sigma$-algebra $\mathcal{B}$ that fulfills the above properties for $\lambda$ qualifies as a \emph{measure}.

\begin{definition} 
  A $\sigma$\emph{-algebra} $\mathcal{B}$ on a set $S$ is a collection of subsets of $S$ that includes the empty set, is closed under complementation with respect to $S$, and is closed under countable unions. 
\end{definition}

%p157
\begin{definition}
  The \emph{Borel $\sigma$-algebra} of a metric space space is the smallest family
 of sets that includes  the closed sets and is closed under countable intersections and countable unions. Elements of the Borel
 $\sigma$-algebra are known as \emph{Borel sets}. 
   %The Borel $\sigma$-algebra of $\mathbb{R}^n$ is the $\sigma$-algebra $\mathcal{B}(\mathbb{R}^n)$ generated by all open sets. The sets in $\mathcal{B}(\mathbb{R}^n)$ are called Borel sets. %For any set $E \subset \mathbb{R}^n$, let B(E) denote the class of all sets of the form $E \cap \mathbb{R}$,where $B \in \mathbb{B}(\mathbb{R}^n)$
\end{definition}

\begin{definition} 
  The pair $(S, \mathcal{B})$ where $\mathcal{B}$ is a $\sigma$-algebra constitutes a \emph{measurable space}. The elements of $\mathcal{B}$ are called  the \emph{measurable sets} of the space. 
\end{definition}



\begin{definition} 
  A  \emph{measure} on the measurable space $(S,\mathcal{B})$ is a function $\mu: \mathcal{B} \to  \mathbb{R} $ that is countably additive and satisfies $\mu(\emptyset)=0$. A measure  on $(S,\mathcal{B})$ is called a \emph{probability measure} if $\mu(S) = 1$.
\end{definition}

 In the context of probability theory, such measures are often referred to as \emph{distributions}. In what follows, we will use the terms measure and distribution interchangeably.

 
% lebesgue measure

 One of the most important measures is the Lebesgue measure on the real line (\ie, the length in $\mathbb{R}$), and its generalizations to $\mathbb{R}^n$.  It is characterized as the unique measure on the Borel sets, whose value on every interval is its length. That is, for any interval $(a, b) \subset \mathbb{R}$,
$
\lambda((a, b)) = b - a.$ The Lebesgue measure is \emph{translation-invariant}, meaning that shifting a set does not change its measure.

For any $ s \in S $, the \emph{Dirac measure} (also known as the \emph{Dirac delta} or \emph{point mass} at \( s \)) is the probability measure defined by
$$
\delta_s(B) =
\begin{cases}
1, & \text{if } s \in B, \\
0, & \text{if } s \notin B.
\end{cases} \quad \text{ for all } B \in \mathcal{B}
$$
A measure is called \emph{discrete} if represented as a countable weighted sum of Dirac measures. In particular, a \emph{convex combination} of Dirac measures yields a discrete probability measure. These are of the form $\sum_{i} a_i \delta_i$,
where $ a_i \geq 0 $, and the weights satisfy $ \sum_{i} a_i = 1 $.

On the other hand, a measure $ \mu $ on a measurable space $ (S, \mathcal{B}) $ is called \emph{continuous} if it assigns zero measure to all singleton sets, i.e., $ \mu(\{s\}) = 0 $ for every $ s \in S $. An example of a continuous measure is the \emph{Lebesgue measure} on $ \mathbb{R}^n $ (for $ n \in \mathbb{N} $).



\begin{definition} \label{def:pushforward_meas_1}
  Let $(S, \mathcal{B}_S)$ and $(T, \mathcal{B}_T)$ be measurable spaces. Given a function $f: (S, \mathcal{B}_S) \to (T, \mathcal{B}_T)$ and a measure $\mu$ on $\mathcal{B}_S$, the \emph{pushforward measure} $f_*(\mu)$ on $\mathcal{B}_T$ is defined by:
$$
f_*(\mu)(B) = \mu(f^{-1}(B)), \quad  B \in \mathcal{B}_T.
$$
\end{definition}


% lebesgue integral

\begin{definition}
  Let $(S, \mathcal{B}_S)$ and $(T, \mathcal{B}_T)$ be measurable spaces. A function $f: S \to T$ is said to be \emph{measurable} if for every  measurable subset  $B \in \mathcal{B}_T$, the preimage $f^{-1}(B) \in \mathcal{B}_S$.
\end{definition}


\begin{definition} 
  The \emph{Lebesgue integral} generalizes the familiar Riemann integral. Consider a measurable space $(S, \mathcal{B})$ and a bounded measurable function $f \colon S \to \mathbb{R}$, with upper and lower bounds $M$ and $m$, respectively. The \emph{Lebesgue integral} of $f$ with respect to a measure $\mu \colon \mathcal{B} \to \mathbb{R}$, denoted $\int f \, d\mu$, is defined as the limit of finite weighted sums of the form:
$$
\sum_{i=0}^n f(s_i) \mu(B_i),
$$
where $\{B_0, \dots, B_n\}$ forms a measurable partition of $S$, and within each $B_i$, the variation of $f$ does not exceed $(M - m)/n$. Here, $s_i \in B_i$ for each $i$, and the limit is taken over increasingly refined partitions. 
\end{definition}


In the case of a finite discrete space $n = \{1, 2, \dots, n\}$, the Lebesgue integral simplifies to a weighted sum:
$$
\int f \, d\mu = \sum_{i=1}^n f(i) \mu(i).
$$

Given two measurable spaces $(S_1, \mathcal{B}_1)$ and $(S_2, \mathcal{B}_2)$, their product is the measurable space $(S_1 \times S_2, \mathcal{B}_1 \otimes \mathcal{B}_2)$, where $S_1  \times S_2$ is the cartesian product and $\mathcal{B}_1 \otimes \mathcal{B}_2$ is the $\sigma$-algebra generated by all measurable rectangles $B_1 \times B_2$ with $B_1 \in \mathcal{B}_1$ and $B_2 \in \mathcal{B}_2$:
$$
\mathcal{B}_1 \otimes_{\text{meas}} \mathcal{B}_2 \coloneqq \sigma\left(\{ B_1 \times B_2 \mid B_1 \in \mathcal{B}_1,\, B_2 \in \mathcal{B}_2 \}\right).
$$
Measures on this product space are called \emph{joint distributions}, and are uniquely determined by their values on measurable rectangles due to the inductive structure of the product $\sigma$-algebra. \emph{Product measures} are a significant class of joint distributions and are defined from measures

\begin{definition} 
   Let $(S_1, \mathcal{B}_1)$ and $(S_2, \mathcal{B}_2)$ be measurable spaces, and let $\mu_1$ and $\mu_2$ be measures on these spaces, respectively. The \emph{product measure} $\mu_1 \gls{product_meas} \, \mu_2$ is  defined on measurable rectangles by
$$
(\mu_1 \otimes_{\text{meas}} \mu_2)(B_1 \times B_2) = \mu_1(B_1)\mu_2(B_2).
$$
This definition extends uniquely to a joint distribution $\mu_1 \otimes \mu_2: \mathcal{B}_1 \otimes \mathcal{B}_2 \to \mathbb{R}$, and reflects the notion of probabilistic independence: sampling from $\mu_1 \otimes \mu_2$ is equivalent to independently sampling from $\mu_1$ and $\mu_2$.
\end{definition}


%MarkovKernels
\begin{definition}
Let $(S, \mathcal{B}_S)$ and $(T, \mathcal{B}_T)$ be measurable spaces. A \emph{Markov kernel} is a mapping $P : S \times \mathcal{B}_T \to [0,1]$
satisfying the following two properties:
\begin{enumerate}
    \item For each fixed $s \in S$, the function $P(s, \cdot) : \mathcal{B}_T \to [0,1]$ is a probability measure on $(T, \mathcal{B}_T)$.
    \item For each fixed $A \in \mathcal{B}_T$, the function $P(\cdot, A) : S \to [0,1]$ is a measurable function on $(S, \mathcal{B}_S)$.
\end{enumerate}
\end{definition}


%By a slight abuse of terminology, we will also use the term \emph{Markov kernel} to refer to a mapping  $P': S \to (\mathcal{B}_T \to [0,1]), \, P'(s)=\mu$, when $P : S \times \mathcal{B}_T \to [0,1],  P(s,A)=\mu(A)$ is a Markov kernel in the definition above.

By a slight abuse of terminology, we will also refer to a mapping $ P' : S \to (\mathcal{B}_T \to [0,1]), \, P'(s)=\mu $, as a Markov kernel, when there exists a Markov kernel $ P : S \times \mathcal{B}_T \to [0,1], \, P(s,A)=\mu (A) $  for all $s \in S $ and $A \in \mathcal{B}_T$.

\begin{definition}
  Given a measure $\mu$ on $S$ and a Markov kernel $P: S \times \mathcal{B}_T \to [0,1]$, we can define the \emph{pushforward} of $\mu$   under the Markov kernel $P$  as:
$$
P_*(\mu)(B) = \int_S P(s, B) \, \mu(ds), \quad \forall B \in \mathcal{B}_T.
$$
\end{definition}

Any measurable function \( f : (S, \mathcal{B}_S) \to (T, \mathcal{B}_T) \) induces a simple Markov kernel $ s \mapsto \delta_{f(s)} $. As a result,  the usual definition of the pushforward measure (Definition \ref{def:pushforward_meas_1}) becomes a special case of the general formulation defined above.

\subsection{Spaces of Measures}

The set of all finite measures on a measurable space $(S, \mathcal{B})$ will be denoted by $\mathcal{M}(S, \mathcal{B})$, 
or simply $\mathcal{M}S$ when the $\sigma$-algebra $\mathcal{B}$ is clear from context. In particular, $\gls{mr}$ denotes  the Banach space of finite Borel measures on $\mathbb{R}$.

 $\mathcal{M}S $ forms a real vector space, where addition and scalar multiplication are defined pointwise. Specifically, for  $ B \in \mathcal{B} $, $ \mu, \nu \in \mathcal{M}S $, and $ \alpha \in \mathbb{R} $, the operations are given by
$$
(\mu + \nu)(B) = \mu(B) + \nu(B), \quad (a\mu)(B) = \alpha \mu(B).
$$


\( \mathcal{M}S \) is also a normed space equipped with the \emph{total variation norm}. 

\begin{definition} \label{def:tvnorm}
  A \emph{partition} of a set \( B \in \mathcal{B} \) is any finite collection \( \{B_1, \dots, B_n\} \) of pairwise disjoint subsets of \( B \) satisfying \( \bigcup_{i=1}^{n} B_i = B \). For a measure \( \mu \), the \emph{total variation norm} is defined as
$$
\|\mu\| := \sup \left\{ \sum_{i=1}^n |\mu(B_i)| : \{B_1, \dots, B_n\} \text{ is a finite measurable partition of } S \right\}.
$$
\end{definition}

For positive measures, this reduces to \( \mu(S) \), and for probability measures, the norm is 1. The total variation norm turns \( \mathcal{M}S \) into a Banach space, meaning it is complete under this norm. 

The following alternative definition is useful to compute the total variation norm between measures.

\begin{theorem} \cite[Theorem 3.1.1]{bogachevMeasureTheory2007}
  Let \( \mu \) measure on a measurable space \( (S, \mathcal{B}) \). Then, there exist disjoint sets \( S^-, S^+ \in \mathcal{A} \) such that $S^- \cup S^+ = S$
and for all \( B \in \mathcal{B} \), one has
\[
\mu(B \cap S^-) \leq 0 \quad \text{and} \quad \mu(B \cap S^+) \geq 0.
\]
\end{theorem}

\begin{corollary} \cite[Corollary 3.1.2]{bogachevMeasureTheory2007}
  Attending to the theorem above, define:
\[
\mu^+(B) := \mu(B \cap S^+), \quad \mu^-(B) := -\mu(B \cap S^-). 
\]
Then \( \mu^+ \) and \( \mu^- \) are nonnegative measures, and we have:
\[
\mu = \mu^+ - \mu^-.
\]
\end{corollary}

The measures \( \mu^+ \) and \( \mu^- \) have the following properties:
\[
\mu^+(B) = \sup\{ \mu(B_i) : B_i \subset B,\ B_i \in \mathcal{B} \},
\]
\[
\mu^-(B) = \sup\{ -\mu(B_i) : B_i \subset B,\ B_i \in \mathcal{B} \},
\]
for all \( B \in \mathcal{B} \).

\begin{definition} \label{def:signed_meas}
  Let $\mu^+$ and $\mu^-$ be defined as in the corollary above. Then, For a measure \( \mu \), the \emph{total variation norm} is defined as
   \[\norm{\mu} = \mu^{+}(S) + \mu^{-}(S)\] 
\end{definition}

\begin{comment}
  \begin{definition} \cite{tsybakov2008}
    Let  let $P$ and $Q$ be two probability measures on $\mathcal{M}\mathbb{R}$. Define
    $$
      \nu = P + Q, \quad p = \frac{dP}{d\nu}, \quad q = \frac{dQ}{d\nu},
    $$
    where $\frac{dP}{d\nu}$ denotes the  the Radon–Nikodym derivative of the measure $P$ with respect to the measure $\nu$. It holds that:
    \begin{align*}
      \norm{P-Q} = \sup_{A \in  \mathcal{B}} \left\{ \left\vert \int_{A} (p - q) \, d\nu \right\vert \right\}.
    \end{align*}
     \end{definition}
\end{comment}

 

  
\section{Example}

 

We proceed by presenting a metric $\lambda$-theory on which to reason about random walks, as previously discussed and briefly illustrating of the synergy between syntax and semantics that our framework provides. Our (only) ground type
will be $\mathtt{real}$ to represent measures over real numbers, \ie\ we set
$\sem{\mathtt{real}}$ to be the space of measures over the real line, $\mathcal{M}(\mathbb{R})$ .
Concerning operations we take a pre-determined set of coin toss functions $\emph{CoinToss}_p : \typeI \to \typeI \oplus \typeI$ whose interpretation takes the form $\sem{\emph{CoinToss}_p}:\mathbb{R} \to \mathbb{R} \oplus \mathbb{R},\ 1 \mapsto (p, 1-p)$.
We also take a pre-determined set of measures 
$$ m = \{\mathtt{unif}(a,b) : \typeI \to \mathtt{real} \} \cup \{\mathtt{delta}_{p_1,\ldots,p_n,x_1,\ldots,x_n} : \typeI \to \mathtt{real}\} $$ which are interpreted as 
$$ \sem{\mathtt{unif}(a,b)} (1) = \mathtt{unif}(a,b) \quad \text{and} \quad \sem{\mathtt{delta}_{p_1,\ldots,p_n, x_1,\ldots,x_n}}(1) = \sum_{i=1}^n p_i\cdot \delta_{x_i},  $$
for all $a,b, p_1,\ldots,p_n,  x_1,\ldots,x_n \in \mathbb{Q}$, such that $\sum_i p_i = 1$. Here $\mathtt{unif}(0,1) \in \mathcal{M}(\Reals)$ is the uniform distribution on the interval $[a,b]$.
Note that we are slightly abusing notation by using $\mathtt{unif}(a,b)$ both as syntactic and semantic objects. We consider yet addition $+ : \mathtt{real},\mathtt{real}
\to \mathtt{real}$ whose interpretation is given by $\mu \otimes_{\text{meas}} \nu \mapsto
+_\ast(\mu \otimes \nu)$.
Finally, we consider a pre-determined set of jumps $j: \typeI \to (\mathtt{real} \multimap \mathtt{real}) $ interpreted as 
\[ 
\sem{j}(1)= \mu \mapsto +_\ast(\mu \otimes \sem{m_0}(*)),
\]
where $m_0 \in m$.



%We consider yet a pre-determined set of actions $a : \typeI \to (\typeA \multimap \typeA) $ whose interpretation takes no particular form.

\begin{example}[Random walk] 

In general terms, a \emph{random walk} on $\mathbb{R}$ is a stochastic process in which a particle---the walker---starts at an initial position and repeatedly ``tosses a coin" (possibly biased) to decide whether to move left or right.

Given jumps $jl,jr$ we can describe a single step of the random walk a follows,
\[
        \textbf{step} =  - \vljud \text{case } \emph{CoinToss}_p (*) \{ \inl(x) \Rightarrow jl(x) ; 
        \inr(y) \Rightarrow jr(y) \} : \mathtt{real} \multimap \mathtt{real}
\]
Given an argument $r$ representing the walker's current position, the program \textbf{step} performs a random jump: with probability $p$, the jump is sampled from the underlying distribution of $jl$; with probability $1 - p$, it is sampled from the distribution of $jr$.

Now, consider the $\lambda$-term $\textbf{apply-n} = \lambda f_1, \dots, f_n, r .\; f_1(f_2(\dots(f_n (r))))$ which operationally speaking sequences $n$ terms given as input. The term that follows represents a $n$-step walk. 
\[
\textbf{rwalk} = \textbf{apply-n } \textbf{ step} \ldots \textbf{step } (\mathtt{delta}_{1,0}) :  \mathtt{real} \multimap \mathtt{real}
\]

%Suppose that $\emph{CoinToss}_p =_{\epsilon} \emph{CoinToss}_p, jl =_{\epsilon}jl^{\epsilon}$, and  it follows from our system that

Recall the interpretation of the jump operations. It is straightforward to prove that the following axiom is sound for each of them:
        \[
                j(\ast) =_0 \lambda x. \, +(x, m_0 (\ast)).
        \]

Now, consider we set the interpretations of $\sem{jl}, \sem{jr}: \mathbb{R} \to ( \mathcal{M}(\mathbb{R}) \multimap  \mathcal{M}(\mathbb{R}))$ to be:
\[
                        \sem{jl}(1)= \mu \mapsto +_\ast(\mu \otimes \mathtt{unif}(0,-1))
                        \hspace{2cm}
                        \sem{jr}(1) =\mu \mapsto +_\ast(\mu \otimes \mathtt{unif}(1,0))
        \]
Operationally $jl$ corresponds to a jump to the left with magnitude between $0$ and $1$, and analogously for $jr$.
Suppose we have another jump $\sem{jr^{\delta}} : \mathbb{R} \to ( \mathcal{M}(\mathbb{R}) \multimap  \mathcal{M}(\mathbb{R}))$ whose interpretation is that of $jr$ except for the 
fact that $\mathtt{unif}(0,1)$ is replaced by $\mathtt{unif}(0,1+\delta)$.
What will be the effect on the random walk when replacing $jr$ by $jr^{\delta}$?
Observe that one can put an upper bound between $jr(\ast)$ and $jr^{\delta}(\ast)$ via the previous axioms and an upper bound between the terms $\mathtt{unif}(0,1)(\ast)$ and $\mathtt{unif}(0,1+\delta)(\ast)$. The latter upper bound is obtained \emph{semantically} by computing the norm $\norm{\mathtt{unif}(0,1) - \mathtt{unif}(0,1+\delta) }$.  First, attending to \autoref{def:signed_meas}, we have,
        \begin{align*}
        &\hspace{-15pt} \norm{ \mathtt{unif}(0,1) - \mathtt{unif}(0,1+\delta) }
        \\
        & \hspace{-15pt} =
        (\mathtt{unif}(0,1) - \mathtt{unif}(0,1+\delta))^+ (\Reals)
        +
        (\mathtt{unif}(0,1) - \mathtt{unif}(0,1+\delta))^- (\Reals)
        \end{align*}
        and proceed by computing the left-hand side of the addition,
        \begin{align*} 
        & \hspace{-15pt}(\mathtt{unif}(0,1) - \mathtt{unif}(0,1+\delta))^+ (\Reals)
        \\
        & \hspace{-15pt} = 
        \sup \{ \mathtt{unif}(0,1)(U) - \mathtt{unif}(0,1 + \delta)(U)
        \mid U \subseteq \Reals \}
        \\
        & \hspace{-15pt}
        =
        \sup \{ \mathtt{unif}(0,1)(U \cap [0,1]) 
        - \mathtt{unif}(0,1 + \delta)(U \cap [0,1]) \\
        & \hspace{-15pt} \hspace{10pt}
        - \mathtt{unif}(0,1 + \delta)(U \cap (1,1 + \delta]) 
        \mid U \subseteq \Reals \}
        \\
        &
        \hspace{-15pt}= \sup \left \{ \left (1 - \frac{1}{1+\delta} \right ) 
                \mathtt{unif}(0,1)(U \cap [0,1]) 
        - \mathtt{unif}(0,1 + \delta)(U \cap (1,1 + \delta]) 
        \mid U \subseteq \Reals \right \}
        \\
        & \hspace{-15pt} = 1 - \frac{1}{1+\delta} 
        \end{align*}
        It follows from an analogous reasoning the right-hand side of the
        addition will be $\frac{\delta}{1 + \delta}$ and therefore the norm
        will be $2 \cdot {\frac{\delta}{1 + \delta}}$.

Additionally, suppose  $\emph{CoinToss}_p$ is replaced by $\emph{CoinToss}_q$. We calculate:
\begin{align*}
    \norm {\sem{\emph{CoinToss}_p(*)} - \sem{\emph{CoinToss}_q(*)}} & = \norm {(p,1-p) - (q, 1-q)} \\
    & =\norm {(p-q,q-p)}  = 2|p-q|
  \end{align*}


Then as our final step we proceed
        \emph{syntactically} via our metric deductive system, as follows.
        \begin{align*}
               &\, \text{case } \emph{CoinToss}_p (*) \text{ of } \inl(x) \Rightarrow jl(x) ; 
               \inr(y) \Rightarrow jr(y)
               \\
               & =_0
               \text{case } \emph{CoinToss}_p \text{ of } \inl(x) \Rightarrow
               jl(y)
               ; 
               \inr(y) \Rightarrow  x \text{ to} 
               \ast. \, jr(\ast) 
               \\
               & =_{2 \cdot \left(|p-q|+ \frac{\delta}{1 + \delta}\right)}
               \text{case } \emph{CoinToss}_q \text{ of } \inl(x) \Rightarrow 
               jl(y); 
               \inr(y) \Rightarrow  x \text{ to} 
               \ast. \, jr^{\delta}(\ast) 
               \\
               & =_0
               \text{case } \emph{CoinToss}_q \text{ of } \inl(x) \Rightarrow jl(x) 
               ; 
               \inr(y) \Rightarrow jr^{\delta}
        \end{align*}
        Thus if $\textbf{rwalk}$ is the random walk that
        involves jump $jl$ and $ \emph{CoinToss}_p$  and $\textbf{rwalk'}$ the random
        walk that involves jump $jl^\delta$ and $ \emph{CoinToss}_q$ we deduce from the framework the metric
        equation,
        \[
                \textbf{rwalk} =_{2n \cdot \left(|p-q|+ \frac{\delta}{1 + \delta}\right)}
                \textbf{rwalk'} 
        \]
        which will converge to $0$ as $\delta$ and $|p-q|$ tends to $0$.

  
The same reasoning applies to alternative interpretations of $jl$ and $jr$. For example, consider:
\[
                        \sem{jl}(1)= \mu \mapsto +_\ast \left(\mu \otimes \sum_{i=1}^n  p_i\cdot  \delta_{-x_i}\right)
                        \hspace{2cm}
                        \sem{jr}(1) =\mu \mapsto +_\ast \left(\mu \otimes \sum_{i=1}^n p_i\cdot \delta_{x_i}\right).
        \]
Operationally, this means that $jl$ performs a jump to the left, landing at position $-x_i$ with probability $p_i$, and $jl$ behaves analogously, jumping to $x_i$ with the same probabilities. Now, consider another jump $jl^{q_i}$ whose interpretation corresponds to that of $jl$ xcept for the fact that $\sum_{i=1}^n p_i\cdot \delta_{-x_i}$ is replaced with $ \sum_{i=1}^n  q_i\cdot \delta_{-x_i}$.
Given \autoref{def:tvnorm}, we compute,
    \begin{align*}
      &\norm{ \sum_i p_i \delta_{-x_i} - \sum_i q_i \delta_{-x_i}}  \\
      & = \sup \left\{ \sum_{i=1}^{n} \left\lvert \left(\sum_i p_i \delta_{-x_i} - \sum_i q_i \delta_{-x_i} \right) (B_i) \right\rvert \,\Bigg| \, B_i \in \mathbb{R}, B_i \cap B_j = \emptyset i,  \neq j, n \in \mathbb{N}  \right\} \\
      & = \sum_i |p_i-q_i|
    \end{align*}
    Here, we use the inequality
\[
\left| \sum_{i=1}^{n} a_i \right| \leq \sum_{i=1}^{n} |a_i|, \quad \text{for all } n \in \mathbb{N}.
\]

Applying the same reasoning as above, if $\textbf{rwalk}$ is the random walk that involves jump $jl$ and $ \emph{CoinToss}_p$  and $\textbf{rwalk'}$ the random walk that involves jump $jl^{q_i}$ and $ \emph{CoinToss}_q$ , we obtain 
 \[
                \textbf{rwalk} =_{n \cdot \left(2 |p-q|+ \sum_i |p_i-q_i|\right)}
                \textbf{rwalk'}. 
        \]


        
\end{example}