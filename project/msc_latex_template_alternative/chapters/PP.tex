\chapter{Probabilistic Programming} \label{ch:pp}


Computer science and probability theory have shared a fruitful relationship since the early days \cite{de1956computability}. Over the years, probabilistic algorithms have emerged as powerful tools across diverse domains—from machine learning \cite{pearl2014} and robotics \cite{thrun2002robotic} to computational linguistics \cite{manning1999foundations}. These algorithms also play a pivotal role in modern cryptography, particularly in public-key systems \cite{goldwasserProbabilisticEncryption1984}, and tackle computationally intractable problems \cite{motwaniRandomizedAlgorithms1995}.

The growing influence of probabilistic methods has also spurred the development of probabilistic programming languages, both concrete and abstract. Early examples include higher-order probabilistic languages like Church \cite{Church2008}, while more recent innovations, such as Anglican \cite{Anglican2015}, continue to expand the expressive power and practicality of probabilistic programming.


In this setting, Crubillé and Dal Lago introduced the notion of a \emph{context distance} in~\cite{crubilleMetricReasoningLterms2015,crubilleMetricReasoninglambda2017}, as a metric analogue of Morris' context equivalence. In Morris's framework, two programs are said to be \emph{context equivalent} if their observable behavior---that is, 
what an external observer can measure during execution---is identical in any context.  This distance was first developed for an affine $\lambda$-calculus and later extended to a more general 
setting that, for instance, allows copying.
%
In \cite{dahlqvist2023syntactic}, the authors reason about approximate equivalence in the probabilistic setting using the \emph{operator norm}. The latter induces a metric on the space of probabilistic programs (which are interpreted as short maps between Banach spaces).

This chapter begins with an introduction to tensor products of Banach spaces based on \cite{ryanIntroductionTensorProducts2013}. We then show that $\catBan$, the category of Banach spaces and short maps, is a model of our metric lambda calculus (\autoref{def:model_metric_cond}). The next section introduces the fundamentals of measure theory, a key component in defining the semantics of probabilistic programs, drawing inspiration primarily from \cite{dahlqvistSemanticsProbabilisticProgramming2020a, bogachevMeasureTheory2007,guide2006infinite}.  
Finally, using our calculus, we study approximate equivalence in the context of a random walk on the real line.



\section{Tensor Product in Banach spaces}



Before introducing the category of Banach spaces and proving it is a model, we first establish some notation and define the tensor product in this context, as it is less familiar than the standard basics of Banach space theory.

First, we establish some notation. The letters \gls{vectorspaces} will often refer to vector spaces, and $\gls{field}$ represents the field of scalars of a vector space.  We denote by \gls{boundedoperators} the vector space of all bounded linear operators from \( V \) to \( V \), and we write  \gls{boundedoperatorsVV} for \( \mathcal{B}(V, V) \). The corresponding operator norm is denoted by \gls{op-norm}.



\begin{definition} [Algebraic Tensor Product] \label{def:Algebraic_Tensor_Product}
The tensor product of vector spaces \( V \) and \( W \) is a vector space 
\gls{alg_tensor} together with a bilinear function (\ie, linear in both variables)
\(\otimes : V \times W \to V \odot W\)
such that for every bilinear function \( g: V \times W \to R \), there exists a unique linear function 
\(h: V \odot W \to R\)
such that \( g = h \circ \otimes \).
\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes,row sep=4em,column sep=7em,minimum width=2em]
  {
   V \times W  & V \odot W    \\
      & R \\
  };
  \path[-stealth]
    (m-1-1) edge  node [above] {$\otimes$} (m-1-2)
    (m-1-1) edge  node [below] {$g$} (m-2-2)
    (m-1-2) edge [dashed]  node [right] {$h$} (m-2-2);
    ;
\end{tikzpicture}
\]
The function \( \otimes \) usually remains anonymous and is written as \( (a, b) \mapsto a \otimes b \).

It follows that arbitrary elements of \( V \odot W \) take the form 
\[
\sum_{i=1}^{n} \alpha_i (v_i \otimes w_i)
\]
for \( \alpha_i \in \mathcal{F} \), \( v_i \in V \), and \( w_i \in W \).

The tensor product extends in particular to linear maps. If 
\(f_1: V_1 \to W_1 \quad \text{and} \quad f_2: V_2 \to W_2\)
are linear maps, then there is a unique linear map 
\(
f_1 \odot f_2: V_1 \odot V_2 \to W_1 \odot W_2
\)
that satisfies
\[(f_1 \odot f_2)(v_1 \otimes v_2) = f_1(v_1) \otimes f_2(v_2)
\]
for all \( v_1 \in V_1 \), \( v_2 \in V_2 \).
\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes,row sep=4em,column sep=7em,minimum width=2em]
  {
   V_1 \times V_2  & V_1 \odot V_2    \\
     W_1 \times W_2  &  W_1 \odot W_2 \\
  };
  \path[-stealth]
    (m-1-1) edge  node [above] { } (m-1-2)
    (m-1-1) edge  node [below] { } (m-2-1)
    (m-2-1) edge  node [below] { } (m-2-2)
    (m-1-2) edge [dashed]  node [right] { } (m-2-2);
    ;
\end{tikzpicture}
\]
\end{definition}

\begin{comment}
\begin{definition} [Algebraic Tensor Product]
  Let \( V_1, \dots, V_n \) and \( W \) be vector spaces, and let
\[
\varphi : V_1 \times \cdots \times V_n \to W
\]
be a multilinear function, meaning a function for which the mapping
\[
u_k \mapsto \varphi(u_1, \dots, u_n)
\]
is linear for each \( k \in \{1, \dots, n\} \) and every fixed choice of vectors \( u_1, \dots, u_{k-1}, u_{k+1}, \dots, u_n \).

Then there exists a unique linear mapping
\[
A : V_1 \otimes \cdots \otimes V_n \to W
\]
such that
\[
\varphi(u_1, \dots, u_n) = A(u_1 \otimes \cdots \otimes u_n)
\]
for all choices of \( u_1 \in V_1, \dots, u_n \in V_n \).
\end{definition}
\end{comment}


\begin{definition} \cite[Chapter 2.1]{ryanIntroductionTensorProducts2013}
  Let $V$ and $W$ be Banach spaces. Let $u$ be any element of $V \odot W$. The \emph{projective norm}, denoted $\norm{ \cdot }_{\pi}$,  is defined by: 
  \[
 \projnorm{u} = \inf\left\{ \sum_{i=1}^n \norm{v_i} \norm{w_i} \Bigg| \, u = \sum_{i=1}^n v_i \otimes w_i\right\}.
\]
\end{definition}

%\begin{proposition} %ryan-artigoprofRenato \label{prop:proj_norm_tensor_mult}
   %Let $V$ and $W$ be Banach spaces. Then, for every $v \in V$ and $w \in W$, it holds that $ \projnorm{v \otimes w} = \norm{v} \otimes \norm{w}$.
%\end{proposition}

\begin{definition} \cite[Chapter 2.1]{ryanIntroductionTensorProducts2013}
  Let \( V \) and \( W \) be Banach spaces. The \emph{projective tensor product} of \( V \) and \( W \), denoted  $ V \widehat{\otimes}_\pi W$, is the Cauchy  completion of the algebraic tensor product \( V \odot W \) with respect to the projective norm \( \projnorm{\cdot} \).
\end{definition}

%(\cite[Chapter 7.3]{goubault-larrecqNonHausdorffTopologyDomain2013}) 






\section{The category Ban}

In this section, leveraging results from \cite{dahlqvist2023syntactic}, we prove that the category of Banach spaces with short maps forms a suitable model of our calculus.

\begin{comment}
\begin{definition}
Let \( x = (x_1, x_2, \dots, x_n) \in \mathbb{C}^n \). The \( L^1 \) norm, \gls{l1_norm},  is defined by
\[
\|x\|_{L^1} = \sum_{i=1}^n |x_i|.
\]
\end{definition}
\end{comment}

\begin{definition}
  The category $\catBan$ is the category of Banach spaces and short maps. It has a symmetric monoidal structure where the tensor product is the projective tensor $\widehat{\otimes}_\pi$.
 The binary coproduct of two Banach spaces $V, W$ is given by their direct sum equipped with the norm $\norm{(v,w)} = \norm{v} + \norm{w}$.
\end{definition}


\begin{lemma} \label{lem_op_max_trace}
  Let $V$, $W$ and $R$ be Banach spaces. Let $ T: V \to R$ and $ S: W \to R$ be short maps. Then, it holds that 
  $$ \opnorm{[T, S]} \leq \sup \{\opnorm{T},\opnorm{S}\}$$
\end{lemma}

%\todo[inline, size=\normalsize]{Não sei se chega, mas tb não sei justificar muito bem sem me meter em cenas convexas (extreme points) e não me apetecia muito.}

\begin{proof}
We calculate,
\begin{align*} 
   \opnorm{[T, S]} &  = \sup{\{ \norm{[T, S] (v_0)}   \hspace{2pt} |  \hspace{2pt}  \norm{(v_0)} = 1  \}}\\
   & = \sup{\{ \norm{[T, S] (v, w)}   \hspace{2pt} |  \hspace{2pt}  \norm{(v, w )} = 1  \}}  \\
   & = \sup \left\{  \norm{T (v) + S (w)}  \, \vert \, \norm{v} + \norm{w}= 1 \right\} \\
   & \leq \sup \left\{  \norm{T (v)} + \norm{S (w)}  \, \vert \, \norm{v} + \norm{w}= 1 \right\} \\
   & = \sup \left\{ \norm{v} \cdot   \norm{T \left( v / \norm{v }\right) } + \norm{w} \cdot \norm{S \left( w / \norm{w}\right)} \, \vert \, \norm{v} + \norm{w}= 1  \right\}  \\
   & = \sup  \left\{ \sup \left\{\norm{T(v)}   \hspace{2pt} |  \hspace{2pt}  \norm{v} = 1  \right\},\sup \left\{\norm{S(w)}   \hspace{2pt} |  \hspace{2pt}  \norm{w} = 1   \right\}  \right\} \\
   & = \sup \{\opnorm{T},\opnorm{S}\}
\end{align*}

In the second to last step we observe that the expression 
\[\norm{v} \cdot   \norm{T \left( v / \norm{v }\right) } + \norm{w} \cdot \norm{S \left( w / \norm{w}\right)} \]
is maximized when either $\norm{v}=1$ or $\norm{w}=1$.
 
\end{proof}


\begin{theorem} \cite[Theorem 4.3]{dahlqvist2023syntactic} \label{thm:ban_monoidal_met}
      The category $\catBan$ is a  symmetric monoidal closed $\catMet$-category in which both the tensor product and the internal hom-functor (currying) are non-expansive.
  \end{theorem}

  \begin{theorem}
      The category $\catBan$ is a  symmetric monoidal closed $\catMet$-category with binary coproducts in which both the tensor product and the internal hom-functor (currying) are non-expansive.
  \end{theorem}

\begin{proof}
  This follows from \autoref{thm:ban_monoidal_met} and \autoref{lem_op_max_trace}.    
\end{proof}



\section{Measure theory}
Probabilistic computation involves running programs that incorporate randomness, leading to output behaviors characterized by probability distributions rather than deterministic outcomes. To effectively understand and analyze these programs, it is essential to have a solid foundation in reasoning about probability distributions. That is where measure theory comes into play.
In this work, we only consider finite measures; hence, the term ``measure" implicitly refers to a finite measure unless stated otherwise.

\subsection{What is measure theory?}

Throughout history, mathematicians sought to extend the ideas of length, area, and volume. The most effective known way to generalize these concepts is through the idea of a measure. Abstractly, a measure is a function defined on subsets of a set with additive properties mirroring length, area, and volume.

We begin with a simple example inspired by \cite{athreyaMeasureTheoryProbability2006} to develop an intuition for the concepts of measure and measure space.
Imagine an open field $S$ covered in snow after a storm. Suppose we wish to measure the amount of snow accumulated in as many field regions as possible.
Assume we have accurate tools for measuring snow over standard geometric shapes like triangles, rectangles, and circles. 
We can approximate irregularly shaped regions using combinations of these standard shapes and then apply a limiting process to assign a consistent measure to such regions. 
Let $\mathcal{B}$ denote the collection of subsets of $S$ that are deemed \emph{measurable}, let $\lambda(A)$ represent the amount of snow in each $A \in \mathcal{B}$, and let $A^c$ denote the complement of a set $A$.


For this framework to make sense, it is reasonable to require that $ \mathcal{B}$ and $\lambda (\cdot)$ satisfy the following properties:

\subsubsection*{Properties of $\mathcal{B}$:}
\begin{enumerate}
    \item If $A \in B$, then  $A^c \in \mathcal{B}$ (\ie, if we can measure the snow on a set $A$, and we know the total amount on $S$, then we can determine the snow on the remaining part $A^c$).
    \item If $A_1, A_2 \in \mathcal{B}$, then \(A_1 \cup A_2 \in \mathcal{B}\)  
    (\ie, if we can measure the snow on two regions \(A_1\) and \(A_2\), we should also be able to measure it on their union).
    \item If $\{A_n\}_{n \geq 1} \subset \mathcal{B}$ is an increasing sequence, \ie, $A_n \subset A_{n+1}$ for all $n$, then $\bigcup_{n=1}^{\infty} A_n \in \mathcal{B}$  
    \\(\ie, if each set in a increasing sequence of regions is measurable, then their limit, the union, should also be measurable).
    \item The collection $\mathcal{B}$ contains a base class $C$ of simple, well-behaved sets (\eg, triangles, rectangles, circles) for which measurement is initially defined.
\end{enumerate}

\subsubsection*{Properties of $\lambda (\cdot)$:}
\begin{enumerate}
    \item  $\lambda(A) \geq 0$ for all $A \in \mathcal{B}$ (\ie, the amount of snow on any set must be nonnegative). 
    \item If $A_1, A_2 \in \mathcal{B}$ and $A_1 \cap A_2 = \emptyset$, then  
    $\lambda(A_1 \cup A_2) = \lambda(A_1) + \lambda(A_2)$
 (\ie, The total amount of snow over two non-overlapping regions is just the sum of the snow in each region. This characteristic of 
$\lambda$ is known as \emph{finite additivity}.)
    \item If $\{A_n\}_{n \geq 1} \subset \mathcal{B}$ is an increasing sequence, \ie, $A_n \subset A_{n+1}$ then  
    $
    \lambda( \lim_{n \to \infty} A_n) = \lambda\left( \bigcup_{n=1}^\infty A_n \right) = \lim_{n \to \infty} \lambda(A_n)
    $
    (\ie, if a set can be approximated by an increasing sequence of measurable sets $\{A_n\}_{n \geq 1}$, then $\lambda(A) = \lim_{n \to \infty} \lambda(A_n)$. This is known as \emph{monotone continuity from below}).
\end{enumerate}

\subsection{Measurable spaces and measures}
Remarkably, these  intuitive conditions give rise to a profoundly versatile and far-reaching theoretical framework. The requirements imposed on $\mathcal{B}$ and $\lambda$ can more formally be stated as follows:

\subsubsection*{Properties of $\mathcal{B}$:}
\begin{enumerate}
    \item $\emptyset \in \mathcal{B}$.
    \item $A \in \mathcal{B}  \implies A^c \in \mathcal{B}$. 
    \item  $A_1, A_2, \dots \in \mathcal{B} \implies \bigcup_i A_i \in \mathcal{B}$ (this is known as \emph{closure
 under countable unions}).
\end{enumerate}

\subsubsection*{Properties of $\lambda$:}
\begin{enumerate}
    \item $\lambda(\cdot) \geq 0$  and $\lambda(\emptyset) = 0$.
    \item  If \(\{A_n\}_{n \geq 1} \subset \mathcal{B}\) is a sequence of pairwise disjoint sets (i.e., \(A_i \cap A_j = \emptyset\) for \(i \neq j\)), then
    $\lambda\left( \bigcup_{n=1}^\infty A_n \right) = \sum_{n=1}^\infty \lambda(A_n)$ (this is known as \emph{countable additivity}). 
\end{enumerate}

A collection $\mathcal{B}$ of subsets of $S$ satisfying the above conditions for $B$ is designated a $\sigma$\emph{-algebra}. Similarly, a set function $\lambda$ defined on a $\sigma$-algebra $\mathcal{B}$ that fulfills the above properties for $\lambda$ qualifies as a \emph{measure}. We note, however, that a measure can be negative; as a result, we will drop the requirement $\lambda(\cdot) \geq 0$.


\begin{definition} 
  A $\sigma$\emph{-algebra} $\mathcal{B}$ on a set $S$ is a collection of subsets of $S$ that includes the empty set, is closed under complementation with respect to $S$, and is closed under countable unions. 
\end{definition}

%p157
\begin{definition}
  The \emph{Borel $\sigma$-algebra} of a metric space is the smallest family
 of sets that includes  the closed sets and is closed under countable intersections and countable unions. Elements of the Borel
 $\sigma$-algebra are known as \emph{Borel sets}. 
   %The Borel $\sigma$-algebra of $\mathbb{R}^n$ is the $\sigma$-algebra $\mathcal{B}(\mathbb{R}^n)$ generated by all open sets. The sets in $\mathcal{B}(\mathbb{R}^n)$ are called Borel sets. %For any set $E \subset \mathbb{R}^n$, let B(E) denote the class of all sets of the form $E \cap \mathbb{R}$,where $B \in \mathbb{B}(\mathbb{R}^n)$
\end{definition}

\begin{definition} 
  The pair $(S, \mathcal{B})$ where $\mathcal{B}$ is a $\sigma$-algebra constitutes a \emph{measurable space}. The elements of $\mathcal{B}$ are called  the \emph{measurable sets} of the space. 
\end{definition}



\begin{definition} 
  A  \emph{measure} on the measurable space $(S,\mathcal{B})$ is a function $\mu: \mathcal{B} \to  \mathbb{R} $ that is countably additive and satisfies $\mu(\emptyset)=0$. A measure  on $(S,\mathcal{B})$ is called a \emph{probability measure} if $\mu(S) = 1$.
\end{definition}

 In the context of probability theory, such measures are often referred to as \emph{distributions}. In what follows, we will use the terms measure and distribution interchangeably.

 
% lebesgue measure

 One of the most important measures is the Lebesgue measure on the real line (\ie, the length in $\mathbb{R}$), $\lambda$, and its generalizations to $\mathbb{R}^n$,  $\lambda_n$.  It is characterized as the unique measure on the Borel sets whose value on every interval is its length, \ie, for any interval $[a, b] \subset \mathbb{R}$,
$
\lambda([a, b]) = b - a.$ The Lebesgue measure, enjoys the properties listed in the theorem below.
\begin{theorem} \cite[Theorem 1.7.3]{bogachevMeasureTheory2007}\label{thm:props_lebesgue_meas}
  Let \( B \) be a Lebesgue measurable set of finite measure. Then:
\begin{enumerate}
  \item\( \lambda_n(B + v) = \lambda_n(B) \) for any vector \( v \in \mathbb{R}^n \);
  \item \( \lambda_n(\alpha B) = |\alpha|^n \lambda_n(B) \) for any real number \( \alpha \).
\end{enumerate}
\end{theorem}

%The Lebesgue measure is \emph{translation-invariant}, meaning that shifting a set $B \in \mathbb{R}^n$ by a fixed vector, does not change its measure. 

For any $ s \in S $, the \emph{Dirac measure} (also known as the \emph{Dirac delta} or \emph{point mass} at \( s \)) is the probability measure defined by
$$
\delta_s(B) =
\begin{cases}
1, & \text{if } s \in B, \\
0, & \text{if } s \notin B.
\end{cases} \quad \text{ for all } B \in \mathcal{B}
$$
A measure is called \emph{discrete} if it is represented as a countable weighted sum of Dirac measures. In particular, a \emph{convex combination} of Dirac measures yields a discrete probability measure. These are of the form $\sum_{i} \alpha_i \delta_i$,
where $ \alpha_i \geq 0 $, and the weights satisfy $ \sum_{i} \alpha_i = 1 $.

On the other hand, a measure $ \mu $ on a measurable space $ (S, \mathcal{B}) $ is called \emph{continuous} if it assigns zero measure to all singleton sets, i.e., $ \mu(\{s\}) = 0 $ for every $ s \in S $. An example of a continuous measure is the \emph{Lebesgue measure} on $ \mathbb{R}^n $ (for $ n \in \mathbb{N} $).

\begin{definition}
  Let $(S, \mathcal{B}_S)$ and $(T, \mathcal{B}_T)$ be measurable spaces. A function $f: S \to T$ is said to be \emph{measurable} if for every  measurable subset  $B \in \mathcal{B}_T$, the preimage $f^{-1}(B) \in \mathcal{B}_S$.
\end{definition}

\begin{definition} \label{def:pushforward_meas_1}
  Let $(S, \mathcal{B}_S)$ and $(T, \mathcal{B}_T)$ be measurable spaces. Given a measurable function $f: (S, \mathcal{B}_S) \to (T, \mathcal{B}_T)$ and a measure $\mu$ on $\mathcal{B}_S$, the \emph{pushforward measure} $f_*(\mu)$ on $\mathcal{B}_T$ is defined by:
$$
f_*(\mu)(B) = \mu(f^{-1}(B)), \quad  B \in \mathcal{B}_T.
$$
\end{definition}


% lebesgue integral




\begin{definition} 
  The \emph{Lebesgue integral} generalizes the familiar Riemann integral. Consider a measurable space $(S, \mathcal{B})$ and a bounded measurable function $f \colon S \to \mathbb{R}$, with upper and lower bounds $M$ and $m$, respectively. The \emph{Lebesgue integral} of $f$ with respect to a measure $\mu \colon \mathcal{B} \to \mathbb{R}$, denoted $\int f \, d\mu$, is defined as the limit of finite weighted sums of the form:
$$
\sum_{i=0}^n f(s_i) \mu(B_i),
$$
where $\{B_0, \dots, B_n\}$ is a measurable partition of $S$, and within each $B_i$, the variation of $f$ does not exceed $(M - m)/n$. Here, $s_i \in B_i$ for each $i$, and the limit is taken over increasingly finer partitions. 
\end{definition}


In the case of a finite discrete space $n = \{1, 2, \dots, n\}$, the Lebesgue integral simplifies to a weighted sum:
$$
\int f \, d\mu = \sum_{i=1}^n f(i) \mu(i).
$$

Given two measurable spaces $(S_1, \mathcal{B}_1)$ and $(S_2, \mathcal{B}_2)$, their product is the measurable space $(S_1 \times S_2, \mathcal{B}_1 \otimes \mathcal{B}_2)$, where $S_1  \times S_2$ is the cartesian product and $\mathcal{B}_1 \otimes \mathcal{B}_2$ is the $\sigma$-algebra generated by all measurable rectangles $B_1 \times B_2$ with $B_1 \in \mathcal{B}_1$ and $B_2 \in \mathcal{B}_2$:
$$
\mathcal{B}_1 \otimes_{\text{meas}} \mathcal{B}_2 \coloneqq \sigma\left(\{ B_1 \times B_2 \mid B_1 \in \mathcal{B}_1,\, B_2 \in \mathcal{B}_2 \}\right).
$$
Measures on this product space are called \emph{joint distributions}, and are uniquely determined by their values on measurable rectangles due to the inductive structure of the product $\sigma$-algebra. \emph{Product measures} are a particular class of joint distributions and are defined from measures, as detailed next.

\begin{definition} 
   Let $(S_1, \mathcal{B}_1)$ and $(S_2, \mathcal{B}_2)$ be measurable spaces, and let $\mu_1$ and $\mu_2$ be measures on these spaces, respectively. The \emph{product measure} $\mu_1 \gls{product_meas} \, \mu_2$ is  defined on measurable rectangles by
$$
(\mu_1 \otimes_{\text{meas}} \mu_2)(B_1 \times B_2) = \mu_1(B_1)\mu_2(B_2).
$$
This definition extends uniquely to a joint distribution $\mu_1 \otimes_{\text{meas}} \mu_2: \mathcal{B}_1 \otimes_{\text{meas}} \mathcal{B}_2 \to \mathbb{R}$, and reflects the notion of probabilistic independence: sampling from $\mu_1 \otimes_{\text{meas}} \mu_2$ is equivalent to independently sampling from $\mu_1$ and $\mu_2$.
\end{definition}

\begin{comment}
%MarkovKernels
\begin{definition}
Let $(S, \mathcal{B}_S)$ and $(T, \mathcal{B}_T)$ be measurable spaces. A \emph{Markov kernel} is a mapping $P : S \times \mathcal{B}_T \to [0,1]$
satisfying the following two properties:
\begin{enumerate}
    \item For each fixed $s \in S$, the function $P(s, \cdot) : \mathcal{B}_T \to [0,1]$ is a probability measure on $(T, \mathcal{B}_T)$.
    \item For each fixed $A \in \mathcal{B}_T$, the function $P(\cdot, A) : S \to [0,1]$ is a measurable function on $(S, \mathcal{B}_S)$.
\end{enumerate}
\end{definition}


%By a slight abuse of terminology, we will also use the term \emph{Markov kernel} to refer to a mapping  $P': S \to (\mathcal{B}_T \to [0,1]), \, P'(s)=\mu$, when $P : S \times \mathcal{B}_T \to [0,1],  P(s,A)=\mu(A)$ is a Markov kernel in the definition above.

By a slight abuse of terminology, we will also refer to a mapping $ P' : S \to (\mathcal{B}_T \to [0,1]), \, P'(s)=\mu $, as a Markov kernel, when there exists a Markov kernel $ P : S \times \mathcal{B}_T \to [0,1], \, P(s,A)=\mu (A) $  for all $s \in S $ and $A \in \mathcal{B}_T$.

\begin{definition}
  Given a measure $\mu$ on $S$ and a Markov kernel $P: S \times \mathcal{B}_T \to [0,1]$, we can define the \emph{pushforward} of $\mu$   under the Markov kernel $P$  as:
$$
P_*(\mu)(B) = \int_S P(s, B) \, \mu(ds), \quad \forall B \in \mathcal{B}_T.
$$
\end{definition}

Any measurable function \( f : (S, \mathcal{B}_S) \to (T, \mathcal{B}_T) \) induces a simple Markov kernel $ s \mapsto \delta_{f(s)} $. As a result,  the usual definition of the pushforward measure (Definition \ref{def:pushforward_meas_1}) becomes a special case of the general formulation defined above.

\end{comment}

\subsection{Spaces of Measures}

The set of all finite measures on a measurable space $(S, \mathcal{B})$ will be denoted by $\mathcal{M}(S, \mathcal{B})$, 
or simply $\mathcal{M}S$ when the $\sigma$-algebra $\mathcal{B}$ is clear from context. In particular, $\gls{mr}$ denotes  the Banach space of finite Borel measures on $\mathbb{R}$.

 $\mathcal{M}S $ forms a real vector space, where addition and scalar multiplication are defined pointwise. Specifically, for  $ B \in \mathcal{B} $, $ \mu, \nu \in \mathcal{M}S $, and $ \alpha \in \mathbb{R} $, the operations are given by
$$
(\mu + \nu)(B) = \mu(B) + \nu(B), \quad (a\mu)(B) = \alpha \mu(B).
$$


\( \mathcal{M}S \) is also a normed space when equipped with the \emph{total variation norm}. 

\begin{definition} \label{def:tvnorm}
  A \emph{partition} of a set \( B \in \mathcal{B} \) is any finite collection \( \{B_1, \dots, B_n\} \) of pairwise disjoint subsets of \( B \) satisfying \( \bigcup_{i=1}^{n} B_i = B \). For a measure \( \mu \), the \emph{total variation norm} is defined as
$$
\|\mu\| := \sup \left\{ \sum_{i=1}^n |\mu(B_i)| : \{B_1, \dots, B_n\} \text{ is a finite measurable partition of } S \right\}.
$$
\end{definition}

For positive measures, this reduces to \( \mu(S) \), and for probability measures, the norm is 1. The total variation norm turns \( \mathcal{M}S \) into a Banach space, meaning it is complete under this norm. 

The following alternative definition is useful to compute the total variation norm between measures.

  \begin{comment}

\begin{theorem} \cite[Theorem 3.1.1]{bogachevMeasureTheory2007}
  Let \( \mu \) be a measure on a measurable space \( (S, \mathcal{B}) \). Then, there exist disjoint sets \( S^-, S^+ \in \mathcal{A} \) such that $S^- \cup S^+ = S$
and for all \( B \in \mathcal{B} \), one has
\[
\mu(B \cap S^-) \leq 0 \quad \text{and} \quad \mu(B \cap S^+) \geq 0.
\]
\end{theorem}

\begin{corollary} \cite[Corollary 3.1.2]{bogachevMeasureTheory2007}
  Attending to the theorem above, define:
\[
\mu^+(B) := \mu(B \cap S^+), \quad \mu^-(B) := -\mu(B \cap S^-). 
\]
Then \( \mu^+ \) and \( \mu^- \) are nonnegative measures, and we have:
\[
\mu = \mu^+ - \mu^-.
\]
\end{corollary}

The measures \( \mu^+ \) and \( \mu^- \) have the following properties:
\[
\mu^+(B) = \sup\{ \mu(B_i) : B_i \subset B,\ B_i \in \mathcal{B} \},
\]
\[
\mu^-(B) = \sup\{ -\mu(B_i) : B_i \subset B,\ B_i \in \mathcal{B} \},
\]
for all \( B \in \mathcal{B} \).

\begin{definition} \label{def:signed_meas}
  Let $\mu^+$ and $\mu^-$ be defined as in the corollary above. Then, for a measure \( \mu \), the \emph{total variation norm} is defined as
   \[\norm{\mu} = \mu^{+}(S) + \mu^{-}(S).\] 
\end{definition}

\begin{comment}
  \begin{definition} \cite{tsybakov2008}
    Let  let $P$ and $Q$ be two probability measures on $\mathcal{M}\mathbb{R}$. Define
    $$
      \nu = P + Q, \quad p = \frac{dP}{d\nu}, \quad q = \frac{dQ}{d\nu},
    $$
    where $\frac{dP}{d\nu}$ denotes the  the Radon–Nikodym derivative of the measure $P$ with respect to the measure $\nu$. It holds that:
    \begin{align*}
      \norm{P-Q} = \sup_{A \in  \mathcal{B}} \left\{ \left\vert \int_{A} (p - q) \, d\nu \right\vert \right\}.
    \end{align*}
     \end{definition}
\end{comment}

\begin{definition} \label{def:mu+_mu-}
  Let \( \mu \) be a measure on a measurable space \( (S, \mathcal{B}) \). The measures \( \mu^+ \) and \( \mu^- \) are defined as follows:
\[
\mu^+(B) \triangleq \sup\{ \mu(B_i) : B_i \subset B,\ B_i \in \mathcal{B} \},
\]
\[
\mu^-(B) \triangleq \sup\{ -\mu(B_i) : B_i \subset B,\ B_i \in \mathcal{B} \},
\]
for all \( B \in \mathcal{B} \).
  
\end{definition}

\begin{proposition}  \cite[Section 3.1]{bogachevMeasureTheory2007} \label{def:signed_meas}
   For a measure \( \mu \), it holds that:
   \[\norm{\mu} = \mu^{+}(S) + \mu^{-}(S).\] 
\end{proposition}

 

  
\section{Case-study : Random Walk}

 

We proceed by presenting a metric $\lambda$-theory on which to reason about random walks, as previously discussed, and this will briefly illustrate the synergy between syntax and semantics that our framework provides. Our (only) ground type
will be $\mathtt{real}$ to represent measures over real numbers, \ie\ we set
$\sem{\mathtt{real}}$ to be the space of measures over the real line, $\mathcal{M}\mathbb{R}$ .
Concerning operations we take a pre-determined set of coin toss functions $\emph{CoinToss}_p : \typeI \to \typeI \oplus \typeI$ whose interpretation takes the form $\sem{\emph{CoinToss}_p}:\mathbb{R} \to \mathbb{R} \oplus \mathbb{R},\ 1 \mapsto (p, 1-p)$.
We also take a pre-determined set of measures 
$$ m = \{\mathtt{unif}(a,b) : \typeI \to \mathtt{real} \} \cup \{\mathtt{delta}_{p_1,\ldots,p_n;x_1,\ldots,x_n} : \typeI \to \mathtt{real}\} $$ 
which are interpreted as 
$$ \sem{\mathtt{unif}(a,b)} (1) = \mathtt{unif}(a,b) \quad \text{and} \quad \sem{\mathtt{delta}_{p_1,\ldots,p_n; x_1,\ldots,x_n}}(1) = \sum_{i=1}^n p_i\cdot \delta_{x_i},  $$
for all $a,b, p_1,\ldots,p_n,  x_1,\ldots,x_n \in \mathbb{Q}$, such that $\sum_i p_i = 1$. Here $\mathtt{unif}(0,1) \in \mathcal{M}\Reals$ is the uniform distribution on the interval $[a,b]$.
Note that we are slightly abusing notation by using $\mathtt{unif}(a,b)$ both as syntactic and semantic objects. We consider yet addition $+ : \mathtt{real},\mathtt{real}
\to \mathtt{real}$ whose interpretation is given by $(\mu, \nu) \mapsto
+_\ast(\mu \otimes_{\text{meas}} \nu)$.
Finally, we consider a pre-determined set of jumps $j: \typeI \to (\mathtt{real} \multimap \mathtt{real}) $ interpreted as 
\[ 
\sem{j}(1)= \mu \mapsto +_\ast(\mu \otimes_{\text{meas}} \sem{m_0}(*)),
\]
where $m_0 \in m$.



%We consider yet a pre-determined set of actions $a : \typeI \to (\typeA \multimap \typeA) $ whose interpretation takes no particular form.

\begin{example}[Random walk] 

In general terms, a \emph{random walk} on $\mathbb{R}$ is a stochastic process in which a particle---the walker---starts at an initial position and repeatedly ``tosses a coin" (possibly biased) to decide whether to move left or right.

Given jumps $jl,jr:\typeI \to (\mathtt{real} \multimap \mathtt{real})$ we can describe a single step of the random walks a follows,
\[
        \textbf{step} =  - \vljud \text{case } \emph{CoinToss}_p (*) \{ \inl(x) \Rightarrow jl(x) ; 
        \inr(y) \Rightarrow jr(y) \} : \mathtt{real} \multimap \mathtt{real}
\]
Given an argument $ r:\mathtt{real}$ representing the walker's current position, the program \textbf{step} performs a random jump: with probability $p$, the walker jumps to the left, and with probability $1 - p$ the walker jumps to the right.

%the jump is sampled from the underlying distribution of $jl$; with probability $1 - p$, it is sampled from the distribution of $jr$.



Now that we have defined a single step of the walk, we introduce the $\lambda$-term 
\[
\textbf{apply-n} = \lambda f_1, \dots, f_n, r.\; f_1(f_2(\dots(f_n(r))))\,,
\]
which composes a sequence of \( n \) functions and applies them to an initial input \( r \). This allows us to define a random walk of \( n \) steps starting from the origin as
\[
\textbf{rwalk} = \textbf{apply-n } \textbf{ step} \ldots \textbf{step } (\mathtt{delta}_{1;0}) :  \mathtt{real}.
\]


%Now, consider the $\lambda$-term $\textbf{apply-n} = \lambda f_1, \dots, f_n, r .\; f_1(f_2(\dots(f_n (r))))$ which operationally speaking sequences $n$ terms given as input. The term that follows represents a $n$-step walk. 


%Suppose that $\emph{CoinToss}_p =_{\epsilon} \emph{CoinToss}_p, jl =_{\epsilon}jl^{\epsilon}$, and  it follows from our system that

Recall that jumps $j: \typeI \to (\mathtt{real} \multimap \mathtt{real}) $ are interpreted as 
\[ 
\sem{j}(1)= \mu \mapsto +_\ast(\mu \otimes_{\text{meas}} \sem{m_0}(*)),
\]
where $m_0 \in m$.
It is straightforward to prove that the following axiom is sound for each of them:
        \begin{equation} \label{eq:ax_jump}
                j(\ast) =_0 \lambda x. \, +(x, m_0 (\ast)).
         \end{equation}

Now, consider we set the interpretations of $\sem{jl}, \sem{jr}: \mathbb{R} \to ( \mathcal{M}\mathbb{R} \multimap  \mathcal{M}\mathbb{R})$ to be:
\[
                        \sem{jl}(1)= \mu \mapsto +_\ast(\mu \otimes_{\text{meas}} \mathtt{unif}(0,-1))
                        \hspace{1.5cm}
                        \sem{jr}(1) =\mu \mapsto +_\ast(\mu \otimes_{\text{meas}} \mathtt{unif}(1,0)).
        \]
Operationally, $jl$ corresponds to a jump to the left with magnitude between $0$ and $1$, and analogously for $jr$.
Suppose we have another jump $\sem{jr^{\delta}} : \mathbb{R} \to ( \mathcal{M}\mathbb{R} \multimap  \mathcal{M}\mathbb{R})$ whose interpretation is that of $jr$ except for the 
fact that $\mathtt{unif}(0,1)$ is replaced by $\mathtt{unif}(0,1+\delta)$.
What will be the effect on the random walk when replacing $jr$ by $jr^{\delta}$?
Observe that we can put an upper bound between the terms $\mathtt{unif}(0,1)(\ast)$ and $\mathtt{unif}(0,1+\delta)(\ast)$, \emph{semantically} by computing the norm $\norm{\mathtt{unif}(0,1) - \mathtt{unif}(0,1+\delta) }$.  Attending to \autoref{def:signed_meas}, we have,
 %The latter upper bound is obtained \emph{semantically} by computing the norm $\norm{\mathtt{unif}(0,1) - \mathtt{unif}(0,1+\delta) }$.  First, attending to \autoref{def:signed_meas}, we have,
        \begin{align*}
        &\hspace{-15pt} \norm{ \mathtt{unif}(0,1) - \mathtt{unif}(0,1+\delta) }
        \\
        & \hspace{-15pt} =
        (\mathtt{unif}(0,1) - \mathtt{unif}(0,1+\delta))^+ (\Reals)
        +
        (\mathtt{unif}(0,1) - \mathtt{unif}(0,1+\delta))^- (\Reals)
        \end{align*}
        and proceed by computing the left-hand side of the addition,
        \begin{align*} 
        & \hspace{-15pt}(\mathtt{unif}(0,1) - \mathtt{unif}(0,1+\delta))^+ (\Reals)
        \\
        & \hspace{-15pt} = 
        \sup \{ \mathtt{unif}(0,1)(U) - \mathtt{unif}(0,1 + \delta)(U)
        \mid U \subseteq \Reals \}
        \\
        & \hspace{-15pt}
        =
        \sup \{ \mathtt{unif}(0,1)(U \cap [0,1]) 
        - \mathtt{unif}(0,1 + \delta)(U \cap [0,1]) \\
        & \hspace{-15pt} \hspace{10pt}
        - \mathtt{unif}(0,1 + \delta)(U \cap (1,1 + \delta]) 
        \mid U \subseteq \Reals \}
        \\
        &
        \hspace{-15pt}= \sup \left \{ \left (1 - \frac{1}{1+\delta} \right ) 
                \mathtt{unif}(0,1)(U \cap [0,1]) 
        - \mathtt{unif}(0,1 + \delta)(U \cap (1,1 + \delta]) 
        \mid U \subseteq \Reals \right \}
        \\
        & \hspace{-15pt} = 1 - \frac{1}{1+\delta} 
        \end{align*}
        The first follows from \autoref{def:mu+_mu-};
        the second step uses the countable additivity of measures; the third follows from the second property in \autoref{thm:props_lebesgue_meas}; the fourth step follows from the definition of \emph{supremum}.

        It follows from an analogous reasoning the right-hand side of the
        addition will be $\frac{\delta}{1 + \delta}$ and therefore the norm
        will be $2 \cdot {\frac{\delta}{1 + \delta}}$.

Then, with this in hand, one can put an upper bound between $jr(\ast)$ and $jr^{\delta}(\ast)$ via the previous axioms (\autoref{eq:ax_jump}) and our deductive metric system, $ jr(\ast) =_{2 \cdot {\frac{\delta}{1 + \delta}}} jr^{\delta}$.

Additionally, suppose  $\emph{CoinToss}_p$ is replaced by $\emph{CoinToss}_q$. We calculate:
\begin{align*}
    \norm {\sem{\emph{CoinToss}_p(*)} - \sem{\emph{CoinToss}_q(*)}} & = \norm {(p,1-p) - (q, 1-q)} \\
    & =\norm {(p-q,q-p)}  = 2|p-q|
  \end{align*}


Then as our final step we proceed
        \emph{syntactically} via our metric deductive system, as follows.
        \begin{align*}
               &\, \text{case } \emph{CoinToss}_p (*)  \{ \inl(x) \Rightarrow jl(x) ; 
               \inr(y) \Rightarrow jr(y) \}
               \\
               & =_0
               \text{case } \emph{CoinToss}_p \, \{ \inl(x) \Rightarrow
               jl(y) 
               ; 
               \inr(y) \Rightarrow  x \text{ to} 
               \ast. \, jr(\ast) \}
               \\
               & =_{2 \cdot \left(|p-q|+ \frac{\delta}{1 + \delta}\right)}
               \text{case } \emph{CoinToss}_q  \{ \inl(x) \Rightarrow 
               jl(y); 
               \inr(y) \Rightarrow  x \text{ to} 
               \ast. \, jr^{\delta}(\ast) \}
               \\
               & =_0
               \text{case } \emph{CoinToss}_q \{  \inl(x) \Rightarrow jl(x) 
               ; 
               \inr(y) \Rightarrow jr^{\delta}  \}
        \end{align*}
        Thus, if $\textbf{rwalk}$ is the random walk that
        involves jump $jl$ and $ \emph{CoinToss}_p$  and $\textbf{rwalk'}$ the random
        walk that involves jump $jl^\delta$ and $ \emph{CoinToss}_q$ we deduce from the framework the metric
        equation,
        \[
                \textbf{rwalk} =_{2n \cdot \left(|p-q|+ \frac{\delta}{1 + \delta}\right)}
                \textbf{rwalk'} 
        \]
        which will converge to $0$ as $\delta$ and $|p-q|$ tend to $0$.

  
The same reasoning applies to alternative interpretations of $jl$ and $jr$. For example, consider:
\[
                        \sem{jl}(1)= \mu \mapsto +_\ast \left(\mu \otimes_{\text{meas}} \sum_{i=1}^n  p_i\cdot  \delta_{-x_i}\right)
                        \hspace{1cm}
                        \sem{jr}(1) =\mu \mapsto +_\ast \left(\mu \otimes_{\text{meas}} \sum_{i=1}^n p_i\cdot \delta_{x_i}\right).
        \]
Operationally, this means that $jl$ performs a jump to the left, landing at position $-x_i$ with probability $p_i$, and $jl$ behaves analogously, jumping to $x_i$ with the same probability $p_i$. Now, consider another jump $jl^{q_i}$ whose interpretation corresponds to that of $jl$ except for the fact that $\sum_{i=1}^n p_i\cdot \delta_{-x_i}$ is replaced with $ \sum_{i=1}^n  q_i\cdot \delta_{-x_i}$.
Given \autoref{def:tvnorm}, we compute,
    \begin{align*}
      &\norm{ \sum_i p_i \delta_{-x_i} - \sum_i q_i \delta_{-x_i}}  \\
      & = \sup \left\{ \sum_{i=1}^{n} \left\lvert \left(\sum_i p_i \delta_{-x_i} - \sum_i q_i \delta_{-x_i} \right) (B_i) \right\rvert \,\Bigg| \, B_i \in \mathbb{R}, B_i \cap B_j = \emptyset,  i \neq j, n \in \mathbb{N}  \right\} \\
      & = \sum_i |p_i-q_i|
    \end{align*}
    Here, using the inequality
\[
\left| \sum_{i=1}^{n} \alpha_i \right| \leq \sum_{i=1}^{n} |\alpha_i|, \quad \text{for all } n \in \mathbb{N},
\]
we observe that the supremum is achieved when each Dirac mass is placed in a distinct partition.

Applying the same reasoning as above, if $\textbf{rwalk}$ is the random walk with  $jl$ and $ \emph{CoinToss}_p$  and $\textbf{rwalk'}$ the random walk with $jl^{q_i}$ and $ \emph{CoinToss}_q$ , we obtain 
 \[
                \textbf{rwalk} =_{n \cdot \left(2 |p-q|+ \sum_i |p_i-q_i|\right)}
                \textbf{rwalk'}, 
        \]
which converges to $0$ as $|p - q|$ and $|p_i - q_i|$ tend to $0$ for all $1 \leq i \leq n$.

        
\end{example}