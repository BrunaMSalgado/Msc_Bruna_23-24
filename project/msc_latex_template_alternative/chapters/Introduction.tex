\chapter{Introduction}



\section{Motivation and Context}




\subsection*{Some History}

\noindent \textbf{Hilbert’s Optimistic Vision of Mathematics}
In September 1928, David Hilbert presented his vision for the foundations of mathematics at the International Congress of Mathematicians in Bologna. He believed it would be possible to place mathematics on an absolutely secure foundation. This would mean that no matter how difficult a mathematical problem might be, one would only need to ``take up the pen, sit at the abacus, and calculate" \cite{ferreiraProblemaDecisaoMaquina}. The process would be entirely deterministic—requiring no intuition or creativity, only strict adherence to formal rules, like performing multiplication in decimal notation. Every problem would, in principle, be solvable by such mechanical procedures. Mathematics, would be both complete (able to answer every question) and consistent (free of contradictions). 

\noindent \textbf{ Gödel’s Incompleteness Theorems} However, this vision was shattered by Kurt Gödel’s Incompleteness Theorems (1931) \cite{Godel}, which showed that no set of mathematical rules powerful enough to handle basic arithmetic could ever be both complete (answering every question) and consistent (free of contradictions) at the same time. 

\noindent \textbf{ Gödel’s Completeness Theorems} 
Interestingly, in his doctoral thesis, Gödel proved a foundational result in logic: first-order predicate logic---a formal system used to express statements involving quantifiers like ``for all'' and ``there exists''---is \emph{complete}~\cite{godelVollstandigkeitAxiomeLogischen1930}. It is important to note that the term ``completeness'' here differs from its use in Gödel’s later Incompleteness Theorems.
Before exploring this notion of completeness, it is helpful to introduce a few core concepts. \emph{Syntax} refers to the formal symbols and inference rules used to construct well-formed statements, while \emph{semantics} concerns the meaning assigned to these statements through interpretations. A \emph{model} of a first-order system is a mathematical structure in which the axioms (or rules) hold true under a given interpretation.
With these notions in place, we can now turn to Gödel’s result, known as the \emph{Completeness Theorem}. This theorem states that  if a statement holds in every possible model of a theory, then it can also be \emph{syntactically} proven using the system’s formal rules. In other words, completeness is the property that all universally valid statements are provable within the system.  The converse also holds: any statement provable syntactically must hold true in all models. This is known as \emph{soundness} \cite{franzenGodelsTheorem2008}.
 


%The formal rules of logical reasoning used in a first-order theory have the property of being sound with respect to the notion of logical consequence. What this means is that anything that can be proved from a set of axioms using these rules of reasoning is also a logical consequence of the axioms in the sense defined.







\noindent \textbf{Entscheidungsproblem}
%we just intoduced two of the main points of focus of this thesis soundness and completeness - we will proced to introduce another the lambda calculus with has close ties with the notion of an effective method/computability fists formalized by hilbert as one of the thing that should hold in its optimistic vision of mathmatics 
Why is this relevant to the present dissertation? Remarkably, it was Alonzo Church—using $\lambda$-\textit{calculus}—who first addressed Hilbert’s \emph{Entscheidungsproblem} (German for ``decision problem''), a cornerstone in his  optimistic vision for mathematics\cite{hilbert1938}. This \emph{Entscheidungsproblem} sought an effective method (also called a mechanical procedure or algorithm) to determine the truth or falsity of any mathematical statement. A method or procedure is effective if:
\begin{enumerate}
    \item it can be described by a finite number of exact instructions;
    \item it produces the desired result after a finite number of steps (provided the instructions are followed without error);
    \item it can, in principle, be carried out by a human using only paper and pencil;
    \item it does not require any creativity or insight from the human.
\end{enumerate}
The algorithms that children learn to perform basic arithmetic operations are examples of effective procedures.

 In 1936, Alonzo Church published a solution to the \emph{Entscheidungsproblem}, proving that no such universal method exists for all mathematical statements~\cite{church1936}. Today, this result is often referred to as Church’s Theorem. In the same work, he introduced a mathematically precise definition of effective computability using what is now known as the $\lambda$-calculus: a function is computable if
 and only if it can be written as a lambda term. This calculus played an important role in functional programming, influencing the design of languages like LISP, Pascal, and GEDANKEN—many of which incorporate $\lambda$-calculus-inspired features, either explicitly or implicitly.Furthermore, Lambda calculus may be employed to prove properties of programming language (such as: a well-formed program will not crash)and as a tool in the construction of compilers \cite{jonesImplementationFunctionalProgramming}.


 At the same time, another individual was working on this problem independently—without prior knowledge of Church’s work. His name was Alan Turing. In science, credit typically goes to the first person to prove a result. Yet Turing’s 1937 paper, On Computable Numbers, with an Application to the Entscheidungsproblem, was groundbreaking in its own right. In it, he introduced the concept of a universal machine and demonstrated that any function computable by a human following a systematic procedure could also be computed by a Turing machine \cite{turingComputableNumbersApplication1937}. Moreover, Turing proved that his definition of computability aligned with Church’s.

%By Turing’s analysis, it became clear that the $\lambda$-calculus was sufficiently powerful to express all mechanically computable functions.

Nowadays, computers are ubiquitous household appliances, as commonplace as televisions or refrigerators. Yet there is  something astounding in the fact that the personal computers we use daily trace their roots to an idea born from questions about the foundations of mathematics: the principle of universality in computation. 

The idea that such important aspects of modern computer science emerged from foundational questions in mathematics is nothing short of extraordinary.




\subsection*{Interpretation}

Moreover, the $\lambda$-calculus includes a set of equations that clarify and simplify the meaning of operations. For instance, one such equation states that a function applying another function $f$ to an argument $x$ can be simplified to $f$ itself: $\lambda x.(f, x) = f$. When viewed as a programming language, the $\lambda$-calculus is typically equipped with a  semantics, \ie, its terms are assigned specific meanings. In this work, we are particularly interested in interpreting these terms as mathematical objects, especially those arising in category theory. If the aforementioned equations hold under a given interpretation, we refer to it as a \emph{model}.
%One way to study the lambda calculus is to give mathematical models of it, i.e.,to provide spaces in which lambda terms can be given meaning. Such models are  constructed using methods from algebra, partially ordered sets, topology,category theory, and other areas of mathematics

On another note, the lambda calculus not only allows us to express all computable functions, but also establishes a correspondence between logical proofs and programs. This is known as the \emph{Curry-Howard isomorphism} \cite{girardProofsTypes1989}.

% Categorical logic stuff

%the objects of type theory and set theory are structured by the operations of their respective systems in certain ways that are not mathematically salient. That additional information is essentially what is lost by our comparisons, e.g. distinctions between basic data and derived objects, between types of different complexity, ordinal rank of a set, membership chains within a set, etc. Categorical structure is closer to the mathematical content, and it is not lost in translation. Equivalence of categories preserves categorical properties and structures, because these are determined only up to isomorphism in the first place. The structural approach implemented by category theory is thus more stable, more robust, more invariant than type or set theoretic constructions. By contrast, the purely structural approach of category theory sometimes, offers comparatively little such “extra” structure to hold on to. Practically speaking, it can be harder to give an invariant proof. That is why it’s good to know that such logical structure can always be introduced into a category when needed; the devices of introducing an internal logic or a set theoretic structure into a category, as sketched in the foregoing sections, were originally developed in order to benefit from their advantages, much like introducing local coordinates on a manifold for the sake of calculation. So it is with categorical versus logical foundations: category theory implements the structural approach directly. It admits interpretations of the conventional logical systems, without being tied to them. Category theory presents the invariant content of logical foundations.

%Category theory provides a language to describe precisely many similar phenomena that occur in different mathematical fields. For example, (1) Each finite dimensional vector space is isomorphic to its dual and hence also to its second dual. The second correspondence is considered “natural”, but the first is not. Category theory allows one to precisely make the distinction via the notion of natural isomorphism.

%One of the reasons why set theory was important is that sets and mappings wereactually used to characterize and study mathematical structures (like groups or topological spaces; see the chapter by McLarty). This way of looking at mathematical topics led to new kinds of definitions, problems, and proof methods, generally referred to by the name ‘structuralism.’

% category theory is in line with an important shift in mathematical methodology that emerged in the 19th and early 20th centuries, and investigating that shift further can help us understand “structuralism” better in general, including its categorical versions (as will become clearer later)

%Structuralism: Category theory is often associated with structuralism, the view that mathematical objects are defined by their relationships within a structure, rather than by their intrinsic properties. 

%When Eilenberg and Mac Lane first introduced (in 1945) the concepts of category and functor their concerns were far removed from the theory of types. Yet category theory and type theory have proved to have deep connections. In fact categories can themselves be viewed as type theories of a certain kind; this fact alone indicates that type theory is much more closely related to category theory than it is to set theory In thinking of a category as a type theory, the objects of a category are regarded as types (or sorts) and the arrows as mappings between the corresponding types. In the 1970s Lambek20 established that, viewed in this way, cartesian closed categories correspond to the typed λ-calculus. . Lambek and Dana Scott independently observed that C-monoids, i.e., categories with products and exponentials and a single, nonterminal object correspond to the untyped λ-calculus.  -> TYPES, SETS, AND CATEGORIES John L. Bell (v6 history of logic)
%At this point is matters to note that in this work we work with a typed lambda calculus wich in lawnmens terms means that each term is assined a type (\ie domain?)
%The typing concept also arises in concrete situations. Consider, for example, an automotive toolkit. Here one is provided with nuts, bolts and wrench bits to attach nuts to bolts. This gives three types: N, B, and S. Then given the instruction Use to attach to , it is implicit that the blanks be filled in with (names of) components of types S, N, and B respectively. 

%Categorical logic, as its name indicates, is logic in the setting of category theory. But this description does not say much. Most readers would probably find more instructive to learn that categorical logic is algebraic logic, pure and simple. It is logic in an algebraic dressing. Just as algebraic logic encodes propositional logic in its different guises (classical, intuitionistic, etc.) by their LindenbaumTarski algebras (Boolean algebras, Heyting algebras and so on), categorical logic encodes first-order and higher-order logics (classical, intuitionistic, etc.) by categories with additional properties and structure (Boolean categories, Heyting categories and so on). Thus, from the purely technical point of view, categorical logic constitutes a generalization of the algebraic encoding of propositional logic to firstorder, higher-order and other logics.

%A category C is an aggregate of abstract elements X, called the objects of thecategory, and abstract elements f, called mappings of the category
%. Not only sets should be treated in a categorical framework, but also logical aspects of the foundations of mathematics should be treated categorically, in as much as they have an objective content. In particular, the logical and the foundational are directly revealed by adjoint functors.

%Going back to his original program of clarifying the conceptual content of semantics, Lawvere realized that certain types of categories can be defined purely by stipulating that certain adjoint functors to given elementary functors exist. The definitions can be given by this data and nothing else. In a loose sense, defining a category via the existence of adjoints amounts to the claim that certain basic conceptual operations can be represented in that category. This in itself would probably not be of foundational relevance, were it not for the fact that the categories so defined correspond in a precise technical sense to logical concepts and theories. Thus the existence of certain adjoints to specific elementary functors amounts to a specification of logical structures and resources. With these ideas and results in his pocket, Lawvere could see that a program of “functorizing” the study of mathematical concepts in general could be formulated.

%any λ-theory T determines a Cartesian closed category C(T). Inversely, each Cartesian closed category E determines a λ-theory T h(E) -> handbook


%One of the most important observations of category theory is that large parts of mathematics can be internalized in any category with sufficient structure. The idea is to exploit the fact that all mathematics can be written in the language of logic, and seek a way to internalize logic in a category with sufficient structure. -> nlab

% We now de ne a formal language, the typed-calculus, and show how it serves as a so-called internal language for cartesian closed categories. Over the last 25 years the typed-calculus (originally invented in the 1930ies by A. Church) has experienced a renaissance in (theoretical) computer science as a foundation for functional programming.

%Typed lambda calculi are foundational programming languages and are the base of typed functional programming languages such as ML and Haskell and, more indirectly, typed imperative programming languages. Typed lambda calculi play an important role in the design of type systems for programming languages; here, typability usually captures desirable properties of the program (e.g., the program will not cause a memory access violation).
%Typed lambda calculi are closely related to mathematical logic and proof theory via the Curry–Howard isomorphism and they can be considered as the internal language of certain classes of categories. For example, the simply typed lambda calculus is the language of Cartesian closed categories (CCCs).[2]

%Moreover, as we have already mentioned, categorical logic provides bridges between constructive and classical approaches, geometry and logic, topology and logic, to name but the most obvious links



%EXCERTOS IMPORTANTES 

%categorical logic Handbook
%A category C is an aggregate of abstract elements X, called the objects of thecategory, and abstract elements f, called mappings of the category
%.
%in addition to their usual role, they become the algebraic descriptions of formal systems and, as such, can be thought of as formal systems; but they also provide the underlying framework for semantics and, as such, can be thought of as universe of interpretations.


%In particular, cartesian closed categories (§4.2) can be used to model simply typed lambda calculus. Each lambda calculus theory is the internal logical language of a cartesian closed ategory (the category's own structure defines the logic;The structure of the category (how objects and arrows interact) directly encodes the rules of logic or lambda calculus.)

%In broad terms, categorical logic represents both syntax and semantics by a category, and an interpretation by a functor.

%typed lambda calculus is a type theory

%When Eilenberg and Mac Lane first introduced (in 1945) the concepts of category and functor their concerns were far removed from the theory of types. Yet category theory and type theory have proved to have deep connections. In fact categories can themselves be viewed as type theories of a certain kind; this fact alone indicates that type theory is much more closely related to category theory than it is to set theory In thinking of a category as a type theory, the objects of a category are regarded as types (or sorts) and the arrows as mappings between the corresponding types. In the 1970s Lambek20 established that, viewed in this way, cartesian closed categories correspond to the typed λ-calculus. . Lambek and Dana Scott independently observed that C-monoids, i.e., categories with products and exponentials and a single, nonterminal object correspond to the untyped λ-calculus.  -> TYPES, SETS, AND CATEGORIES John L. Bell (v6 history of logic)

%any λ-theory T determines a Cartesian closed category C(T). Inversely, each Cartesian closed category E determines a λ-theory T h(E) -> handbook

%Moreover, as we have already mentioned, categorical logic provides bridges between constructive and classical approaches, geometry and logic, topology and logic, to name but the most obvious links


%Category theory describes properties of mathematical structures via their transformations or morphisms On the other hand mathematical logic provides languages for formalizing proper ties of structures directly in terms of their constituent parts elements of sets functions between sets relations on sets and so on It might seem that the kind of properties that can be described purely in terms of morphisms and their composition would be quite limited However beginning with the attempt of Lawvere  to reformulate the foundations of mathematics using the language of category theory the de velopment of categorical logic over the last three decades has shown that this is far from true. Indeed it turns out that many logical constructs can be characterized in terms of relatively few categorical ones principal among which is the concept of adjoint functor .
%Many systems of logic can only be modelled in a su ciently complete waybygoingbeyond the usual setbased structures of classical model theory Categorical logic introduces the idea of a structure valuedinacategory Cwith the classical model theoretic notion of structure Chang and Keisler appearing as the special case when C is the category of sets and functions. For a particular logical concept one seeks to identify what properties or extra structure are needed in an arbitrary category to interpret the concept in a way that respects given logical axioms and rules A wellknown example is the interpretation of simply typed lambda calculus in cartesian closed categories

% Ângulo Interpretação categorica -> categorias e parabola do elefante; In the 1970s Lambek20 established that, viewed in this way, cartesian closed categories correspond to the typed λ-calculus. . Lambek and Dana Scott independently observed that C-monoids, i.e., categories with products and exponentials and a single, nonterminal object correspond to the untyped λ-calculus. Furthermore, parte da lógica...

% Categorias = multliplas perspetivas, mas não só. Lambda calculus e a mesmo a lógica em geral têm laços mais profundos com teoria das categorias. Um destes laços mais "automatico" prende-se com uma restrição do lambda calculus conhecida como simply typed lambda calculus que é uma typed theory. Aqui os termos são assigned a type (ie objects of a syntactic nature that are assigned to lambda terms). In fact categories can themselves be viewed as type theories of a certain kind; this fact alone indicates that type theory is much more closely related to category theory than it is to set theory In thinking of a category as a type theory, the objects of a category are regarded as types (or sorts) and the arrows as mappings between the corresponding types. Roughly speaking, a category may be thought of a type theory shorn of its syntax . In the 1970s Lambek20 established that, viewed in this way, cartesian closed categories correspond to the typed λ-calculus, \ie any λ-theory (def lambda theory) T determines a Cartesian closed category C(T). Inversely, each Cartesian closed category E determines a λ-theory Th(E). Furtermore this connection extends to the logic: Each lambda calculus theory is the internal logical language of a cartesian closed ategory (the category's own structure defines the logic;The structure of the category (how objects and arrows interact) directly encodes the rules of logic or lambda calculus.). In deed there's a branch of logics known as categorical  which ...

%ver catl




\subsection*{Going quantitative}

Beyond its foundational aspects, this calculus incorporates extensions for modeling side effects, including probabilistic or non-deterministic behaviors and shared memory. In this work, we are concerned with a version of $\lambda$-calculus that allows us to reason about approximate equivalence of programs, refered to as \emph{metric }$\lambda$\emph{-calculus}.

Program equivalence and its underlying theories traditionally rely on a binary notion of equivalence: two programs are either equivalent or not \cite{winskel93}. While this dichotomy is often sufficient for classical programming, it proves too coarse-grained for other computational paradigms. For instance, in various programming paradigms, interaction with the physical environment calls for notions of approximate program equivalence. 

To address this, \cite{dahlqvistInternalLanguage2022,dahlqvist2023syntactic} incorporate a notion of approximate equivalence into the equational system of the affine $\lambda$-calculus by introducing, among other elements, \emph{metric equations} \cite{mardare2016quantitative, mardare2017axiomatizability}. These are equations of the form $t =_{\varepsilon} s$, where $\varepsilon$ is a non-negative real number representing the ``maximum distance'' between terms $t$ and $s$. Here we start investigating the incorporation of a metric equation for the case statements (\ie\ conditionals). Our motivation for it is highly practical: in trying to reason quantitatively about higher-order programs we often fell short when these involved conditionals.


Other works in the spirit of this dissertation include \cite{mardare2016quantitative, mardare2017axiomatizability, mio24, jurka24}, which explore (generalized) metric universal algebras. A universal algebra, in simple terms, is a set equipped with any number of operations, further defined  by axioms typically expressed as identities or equational laws. In a (generalized) metric universal algebra, these axioms are relaxed into (generalized) metric equations rather than strict equalities. In the higher-order setting, \cite{lago22}, following the framework introduced by Mardare \cite{mardare2016quantitative}, investigates the problem of defining quantitative algebras that are capable of interpreting terms in higher-order calculi.
\todo[inline,size=\normalsize]{Falar do $\&$, não falor do $\&$, eis a questão }



\begin{comment}
Remarkably a number of important results already considered additive structure
in the quantalic setting, even if sometimes implicitly.
References~\cite{mardare2016quantitative,mardare2017axiomatizability,mio24,jurka24}
for example are framed in the setting of universal algebra and therefore
involve additive conjunction (\ie\ $\&$), typically interpreted via categorical
products.  In the higher-order setting, \cite{lago22} enforces additive
conjunction to be left adjoint to implication (interpreted via
Cartesian-closedness), with a series of negative results emerging from this.
Our work is orthogonal to these in that we study the dual of $\&$ (\ie\
$\oplus$) and furthermore we assume the left adjoint of implication to be
multiplicative conjunction (\ie\ $\otimes$) instead of the additive
counterpart. Among other things, this removes the obstacles discussed
in~\cite{lago22}.
\end{comment}



\subsection*{Probabilistic Programming}

Probabilistic programs are quite  ubiquitous: they control autonomous systems, verify security protocols, and implement randomized algorithms for solving computationally intractable problems. At their core, they aim to democratize probabilistic modeling by providing programmers with expressive, high-level abstractions for machine learning and statistical reasoning \cite{bartheFoundationsProbabilisticProgramming2020}. In this context, concerns such as the development of more eco-friendly programs and algorithms could greatly benefit from a quantitative approach.

%Probabilistic programs offer a structured approach to drawing statistical conclusions from uncertain data or real-world observations. They generalize probabilistic graphical models beyond the capabilities of Bayesian networks and are expected to have broader applications in machine intelligence. These programs are are employed across various domains. They control autonomous systems, verify security protocols, and implement randomized algorithms for solving computationally intractable problems. As a result, they are becoming increasingly central to AI development. At their core, they aim to democratize probabilistic modeling by providing programmers with expressive, high-level abstractions for machine learning and statistical reasoning \cite{bartheFoundationsProbabilisticProgramming2020}. 






\subsection*{Quantum Computation}

In 1994, Peter Shor demonstrated that a quantum computer with sufficiently many qubits could pose a significant threat to the security of confidential data transmitted over the Internet \cite{shor1994algorithms}. This breakthrough spurred widespread interest in quantum computing. Nevertheless, \acrfull{nisq}  computers are expected to operate with severely limited hardware resources. Precisely controlling qubits in these systems comes at a high cost, is susceptible to errors, and faces scarcity challenges. Therefore, quantitative reasoning is indispensable for the design, optimization, and assessment of NISQ computing. 


%While holding immense promise, this paradigm encounters challenges in the \acrfull{nisq} era, namely quantum decoherence which restricts the reliable execution of quantum circuits \cite{preskill2018quantum}. Consequently, it is unreasonable to expect that the idealized quantum algorithm will run perfectly on a quantum device, instead only a mere approximation will be observed, which suggests the development of appropriate notions of approximate program equivalence.





%falar do lambda calculus e da sua ambivalencia e mencionar que nos vamos focar no caso quantico

\section{Contributions}
We build on the work of \cite{dahlqvist2023syntactic} by introducing a metric equation for conditionals and proving both its soundness and completeness. Soundness ensures that if a metric equation $t =_{\varepsilon} s$ can be derived in the calculus, then the distance between the interpretations of $t$ and $s$ is at most $\varepsilon$. Completeness guarantees that if $\varepsilon$ is the maximal distance between the interpretations of two programs, then we can derive $t =_{\varepsilon} s$ in the calculus. 

We then show that the category of metric spaces and the cocompletion of a $ \catMet $-category $ C $ satisfy the requirements for a model suitable for reasoning about approximate equivalence using this equation.  Next, to illustrate the utility of the metric equation introduced, we present two simple examples: reasoning about approximate equivalence between boolean terms (\ie terms of type $ \typeI \oplus \typeI $) the extensionality of copairing.


Next, we explore two computational paradigms in greater detail: probabilistic and quantum computation. For the former, we prove that the category $ \catBan $ of Banach spaces and short maps constitutes a model in this setting, and use a random walk as an illustrative example. For the latter, we consider two categorical models: Selinger’s \( \catQ \), the category of quantum operationts (\ie, completely positive, trace-nonincreasing superoperators) \cite{selinger2004towards}, and Cho’s \( \WstarCPSUop \), the opposite category of W$^*$-algebras and normal, completely positive, subunital maps~\cite{choSemanticsQuantumProgramming2016}. We show that both are first-order models. Finally, we use quantum state discrimination, quantum teleportation, and quantum random walks as illustrative examples in this setting.


%for enriched symmetric monoidal closed categories with binary copr0ducts over metric spaces.


\section{Document Structure}

\Cref{ch:metriclambda} introduces (metric) $\lambda$-calculus along with its categorical interpretation, accompanied by the necessary notions from category theory used throughout the thesis. One advantage of working with a metric equational system is the ability to reason syntactically about approximate equivalence. We leverage this idea in an interlude on booleans (i.e., terms of type $\typeI \oplus \typeI$) to illustrate the usefulness of the classical equational system. In \Cref{ch:conditionals}, we introduce a metric equation for conditionals, prove its soundness and completeness, and present a few models in this setting, along with a few illustrative syntactic examples. Then, in \Cref{ch:pp} and \Cref{ch:qc}, we focus on reasoning about higher-order probabilistic programs and first-order quantum programs, respectively,  including the necessary background in each domain. The thesis concludes with directions for future work in \Cref{ch:future_work}.

Although this work uses knowlage across multiple areas, the author's engagement with them is mostly limited to the scope of this thesis.


