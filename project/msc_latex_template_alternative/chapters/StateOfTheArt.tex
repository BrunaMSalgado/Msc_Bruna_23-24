\chapter{Metric Lambda Calculus}

The Lambda Calculus, developed by Church and Curry in the 1930s, serves as a formal language capturing the key attribute of higher-order functional languages, treating functions as first-class citizens, allowing them to be passed as arguments \cite{barendregt1984lambda}.  Moreover, lambda calculus has been proven to be universal in the sense that any computable function can be represented as an expression within the language \cite{bernays1936alonzo} . Beyond its foundational aspects, this calculus incorporates extensions for modeling side effects, including probabilistic or non-deterministic behaviors and shared memory.  Higher-order functions form a pivotal abstraction in practical programming languages such as LISP, Scheme, ML, and Haskell.


This chapter introduces the metric lambda calculus as presented in \cite{dahlqvist2022syntactic}. The metric lambda calculus integrates notions of
approximation into the equational system of affine lambda calculus, a variant of lambda calculus that restricts each variable to being used at most once. The metric lambda calculus incorporates a metric equational system, enabling reasoning about approximate program equivalence. This chapter offers a brief insight into lambda calculus and an overview of the syntax and metric equational system of the metric lambda calculus. For a more detailed study of lambda calculus theory, the reader is referred to \cite{barendregt1984lambda}.


\section{The Lambda Calculus}

The concept of a function takes a central role in the lambda calculus. But what exactly is a function?  In most mathematics, the “functions as graphs” paradigm the “functions as graphs” paradigm is the most elegant and appropriate framework for understanding functions. Within this paradigm, each function $f$ has a fixed domain $X$ and a fixed codomain $Y$. The function $f$ is then a subset of $X \times Y$ that satisfies the property that for each $x \in X$ there is a unique $y \in Y$ such that $(x,y) \in f$. Two functions $f$ and $g$ are equal if they yield the same output on each input, that is if $f(x) = g(x)$ for all $x \in X$. This perspective is known as the extensional view of functions, as it emphasizes that the only observable property of a function is how it maps inputs to outputs.

On the other hand, the “functions as rules” paradigm is more appropriate within computer science. In this context, defining a function involves specifying a rule or procedure for computing the function. Such a rule is often expressed in the form of a formula, for example, \( f(x) = x^2 \). As with the mathematical paradigm, two functions are considered extensionally equal if they exhibit the same input-output behavior. However, this view also introduces the notion of intensional equality: two functions are intensionally equal if they are defined by (essentially) the same formula.


In the lambda calculus, functions are described explicitly as formulae. The function $f:x \mapsto f(x)$ is represented as $\lambda x.f(x)$.  Applying a function to an argument is done by juxtaposing the two expressions. For instance consider the function $f:x \mapsto x+1$, to compute $f(2)$ one writes $(\lambda x.x+1)(2)$.

The expression of higher‑order functions - functions whose inputs and/or outputs are themselves functions- in a simple manner is an essential feature of lambda calculus. For example, the composition operator $f,g \mapsto f \circ g$ is written as $\lambda f. \lambda g. \lambda x. f(g(x))$. Considering the functions $f:x \mapsto x^2$ and $g:x \mapsto x+1$, to compute $(f \circ g)(2)$ one writes $$(\lambda f. \lambda g. \lambda x. f(g(x)))(\lambda x.x^2)(\lambda x.x+1)(2).$$

As mentioned above,  within  the “functions as rules” paradigm, is not
always necessary to specify the domain and codomain of a function in advance. For instance, the identity function $f: x \mapsto x$, can have any set $X$ as its domain and codomain, provided that the domain and codomain are the same. In this case, one says that $f$ has type $X \rightarrow{} X$. In the case of the composition operator, $h=\lambda f. \lambda g. \lambda x. f(g(x))$, the domain and codomain of the functions $f$ and $g$ must match. Specifically, $f$ can have any set $X$ as its domain and any set  $Y$ as its codomain, provided that $Y$ is the domain of $g$. Similarly, $g$ can have any set $Z$ as its codomain.  Thus,  $h$ has type $$(X \rightarrow{} Y) \rightarrow{} (Y \rightarrow{} Z) \rightarrow{} (X \rightarrow{} Z).$$ 

This flexibility regarding domains and codomains enables operations on functions that are not possible in ordinary mathematics. For instance, if $f = \lambda x.x$ is the identity function, then one has that $f(x) = x$ for any $x$. In particular, by substituting $f$ for $x$, one obtains $f(f) = (\lambda x.x)(f) = f$. Note that the equation $f(f) = f$ is not valid in conventional mathematics, as it is not permissible, due to set-theoretic constraints, for a function to belong to its own domain.

Nevertheless, this remarkable aspect of lambda calculus, this work focuses on a more restricted version of the lambda calculus, known as the simply-typed lambda calculus. Here, each expression is always assigned a type, which is very similar to the situation in mathematics. A function may only be applied to an argument if the argument's type aligns with the function's expected domain. Consequently, terms such as $f(f)$ are not allowed, even if $f$ represents the identity function.



%In order to be able to manipulate lambda-terms more easily, one can associate a type to each lambda-term


\section{Syntax}

The grammar and term formation rules of the affine lambda calculus, discussed in \cite{dahlqvist2022syntactic}, are presented in this subsection.

\subsection{Type system}

As previously mentioned, this work focuses on the simply-typed lambda calculus, this work focuses on the simply-typed lambda calculus, where each lambda term is assigned a type. Unlike sets, types are \emph{syntactic} objects, meaning they can be discussed independently of their elements. One can conceptualize types as names or labels for set. The definition of the grammar of types for affine lambda calculus is as follows, where $G$ represents a set of ground types.
\begin{equation} \label{eq:grammartypes}
\centering
\hspace{95pt} \mathbb{A} ::= X \in G \hspace{3 pt} \vert \hspace{3 pt} \mathbb{I}  \hspace{3 pt}  \vert \hspace{3 pt} \mathbb{A}  \otimes  \mathbb{A} \hspace{3 pt} \vert  \hspace{3 pt}  \mathbb{A} \multimap  \mathbb{A}
\end{equation}
Note that this is an inductive definition. Ground types are things such as booleans, integers, and so forth. The type $\mathbb{I}$ is the unit/empty type, which has only one element. The type $\mathbb{A} \otimes \mathbb{B}$ is the tensor product of types $\mathbb{A}$ and $\mathbb{B}$, while the type $\mathbb{A} \multimap \mathbb{B}$ is the type of linear maps from $\mathbb{A}$ to $\mathbb{B}$.

\subsection{(Raw)Terms}

The expressions of the lambda calculus are called lambda terms. In the simply-typed lambda calculus, each lambda term is assigned a type. The terms without the specification of a type are called \emph{raw typed lambda terms}. The grammar of \emph{raw typed lambda terms} is given below.
\begin{equation*} \label{eq:grammarlambda}
\begin{split}
 v,v_1, \ldots, v_n,w \hspace{10 pt} ::= \hspace{10 pt}& x \hspace{3 pt} \vert \hspace{3 pt} f(v_1, \ldots, v_n) \hspace{3 pt} \vert \hspace{3 pt} *  \hspace{3 pt} \vert \hspace{3 pt} (\lambda x: \mathbb{A}. v )\hspace{3 pt} \vert \hspace{3 pt} (v w) \hspace{3 pt}  \vert \hspace{3 pt} v \otimes w \hspace{3 pt} \vert
 \\&    \text{pm} \hspace{3 pt} v \hspace{3 pt} \text{to} \hspace{3 pt} x \otimes y. w  \hspace{3 pt}  \vert \hspace{3 pt} v \hspace{3 pt} \text{ to } *.w \hspace{3 pt} \vert \hspace{3 pt} \text{dis}(v)
\end{split}
\end{equation*}

Here $x$ ranges over an infinite set of variables. $f \in \Sigma$, where  $\Sigma$ corresponds to a class of sorted operation symbols and $f(v_1, \ldots, v_n)$ corresponds to the aplication of the function $f$ to the arguments $v_1, \ldots, v_n$. The symbol $*$ is the unit element of the type $\mathbb{I}$. The term $(\lambda x: \mathbb{A}. v )$ is the lambda abstraction term, which represents a function that takes an argument of type $\mathbb{A}$ and returns the value of $v$. The term $(v w)$ is the application term, which applies the function $v$ to the argument $w$.  The term $v \otimes w$ is the tensor product of $v$ and $w$. The term $\text{pm} \hspace{3 pt} v \hspace{3 pt} \text{to} \hspace{3 pt} x \otimes y. w$ is the pattern-matching construct, which is used to deconstruct a tensor product into components $x$ and $y$. The term $v \text{ to } *.w$ is used to discard a variable $v$ of the unit type. The term $\text{dis}(v)$ is the discard term, which is used to discard a term $v$. 

\todo[inline,size=\normalsize]{Ver o que por antes do ::= porque v1,..., vn tb são termos } 

\subsection{Free and Bound Variables}
An occurrence of a variable $x$ within a term of the form $\lambda x.v$ is referred to as bound.  Similarly, the variables $x$ and $y$ in the term $\text{pm} \hspace{3 pt} v \hspace{3 pt} \text{to} \hspace{3 pt} x \otimes y. w$ are also bound. A variable occurrence that is not bound is said to be free. For example, in the term $\lambda x.xy$, the variable $y$ is free, whereas the variable $x$ is bound.  

The set of free variables of a term $v$ is denoted by $FV(v)$, and is defined inductively as follows:
\begin{equation*}
\begin{split}
FV(x) &= \{x\}, &  FV(*) &= \emptyset,  \\
FV(f(v_1, \ldots, v_n)), &= FV(v_1) \cup \ldots \cup FV(v_n)& FV(\lambda x: \mathbb{A}. v) &= FV(v) \backslash \{x\}, \\
FV(v w) &= FV(v) \cup FV(w), & FV(v \otimes w) &= FV(v) \cup FV(w), \\
FV(\text{pm} \hspace{3 pt} v \hspace{3 pt} \text{to} \hspace{3 pt} x \otimes y. w), &= FV(v) \cup (FV(w)  \backslash \{x,y\}) & FV(\text{dis}(v)) &= FV(v),\\
FV(v \text{ to } *.w) &= FV(v) \cup FV(w). \\
\end{split}
\end{equation*}


\subsection{Term formation rules}

To prevent the formation of nonsensical terms within the context of lambda calculus, such as $(v \otimes w (u))$, the typing rules are imposed.

A typed term is a pair consisting of a term and its corresponding type. The notation $v:\mathbb{A}$ denotes that the term $v$ has type $\mathbb{A}$. Typing rules are formulated using typing judgments. A typing judgment is an expression of the form $x_{1}: \mathbb{A}_{1}, \ldots, x_{n}: \mathbb{A}_{n} \triangleright v: \mathbb{A}$ (where $n \geq 1$), which asserts that the term $v$ is a well-typed term of type $\mathbb{A}$ under the assumption that each variable variable $x_{i}$ has type $\mathbb{A}_{i}$, for $1 \leq i \leq n$. The list $x_{1}: \mathbb{A}_{1}, \ldots, x_{n}: \mathbb{A}_{n}$ of typed variables is called the typing context of the judgment, and it might be empty.  Each variable $x_i$ (where $1 \leq i \leq n$) must occur at most once in $x_1, \ldots, x_n$. The typing contexts are denoted by Greek letters $\Gamma$, $\Delta$, and $E$. The empty context is denoted by $-$. 


The concept of shuffling is employed to construct a linear typing system that ensures the admissibility of the exchange rule and enables unambiguous reference to judgment's denotation $[\![ \Gamma \triangleright v: \mathbb{A} ]\!]$. An admissible rule is not explicitly included in the formal definition of type theory, but its validity can be proven by demonstrating that whenever the premises can be derived, it is possible to construct a derivation of its conclusion. Shuffling is defined as a permutation of typed variables in a sequence of contexts, $\Gamma_1, \ldots, \Gamma_n$, preserving the relative order of variables within each $\Gamma_i$ \cite{shulman2019practical}. For instance, if $\Gamma_1=x:\mathbb{A}, y:\mathbb{B}$ and $\Gamma_2=z:\mathbb{C}$, then $z:\mathbb{C}, x:\mathbb{A}, y:\mathbb{B}$ is a valid shuffle of $\Gamma_1, \Gamma_2$. On the other hand, $y:\mathbb{B}, x:\mathbb{A}, z:\mathbb{C}$ is not a shuffle because it alters the occurrence order of $x$ and $y$ in $\Gamma_1$. The set of shuffles in $\Gamma_1, \ldots, \Gamma_n$ is denoted as $\text{Sf} (\Gamma_1, \ldots, \Gamma_n)$. A valid typing derivation is constructed using the inductive rules shown in \autoref{fig:typing_rules_linear}.
%An admissible rule is not explicitly included in the formal definition of the type theory, but it can be proven valid using the fact that whenever one has derivations of its premises it is possible to construct a derivation of its conclusion.
%an admissible rule is one that is not asserted as part of the specification of the type theory, but for which we can prove after the fact that whenever we have derivations of its premises we can construct a derivation of its conclusion — usually by inductively traversing and modifying the given derivations of its premises. 
\begin{figure} [H]
  \small{
\begin{equation*}
\begin{split}
\begin{aligned}
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \Gamma_{i} \triangleright v_{i}: \mathbb{A}_{i} \quad f: \mathbb{A}_{1}, \ldots, \mathbb{A}_{n} \xrightarrow{} \mathbb{A} \in \Sigma \quad E \in \text{Sf}(\Gamma_{1}; \ldots; \Gamma_{n})\\
    \hline
   E \triangleright f( v_{1},\ldots,v_{n}): \mathbb{A}
\end{array}
$
\end{minipage}
\hspace{148pt}
\text{(ax)} 
 \hspace{40pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
      \\
    \hline
   x:\mathbb{A} \triangleright x:\mathbb{A}
\end{array}
$ \end{minipage}
\hspace{-68pt} \text{(hyp)} \\
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    \\
    \hline
   - \triangleright *: \mathbb{I}
\end{array}
$
\end{minipage}
\hspace{-87pt}
\text{($\mathbb{I}_{i}$)} 
 \hspace{7pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \Gamma \triangleright v: \mathbb{A} \otimes \mathbb{B} \quad  \Delta,x: \mathbb{A}, y: \mathbb{B}  \triangleright w: \mathbb{C}  \quad E \in \text{Sf}(\Gamma;\Delta)\\
    \hline
   E\triangleright \text{pm } v \text{ to } x \otimes y. w :\mathbb{C}
\end{array}
$ \end{minipage}
\hspace{117pt} (\otimes_{e}) 
\hspace{5pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \Gamma \triangleright v: \mathbb{A}  \\
    \hline
   \Gamma \triangleright \text{dis}(v):  \mathbb{I} 
\end{array}
$
\end{minipage}
\hspace{-67pt} (\text{dis})\\
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \Gamma \triangleright v: \mathbb{A} \quad  \Delta \triangleright w: \mathbb{B}  \quad E \in \text{Sf}(\Gamma;\Delta) \\
    \hline
   E \triangleright v \otimes w: \mathbb{A} \otimes \mathbb{B} 
\end{array}
$
\end{minipage}
\hspace{41pt} (\otimes_{i}) 
 \hspace{46pt}
 \begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \Gamma \triangleright v: \mathbb{I} \quad  \Delta \triangleright w: \mathbb{A}  \quad E \in \text{Sf}(\Gamma;\Delta)  \\
    \hline
   E \triangleright v \text { to } *.w: \mathbb{A}  
\end{array}
$ \end{minipage}
\hspace{38pt} (\mathbb{I}_{e}) \\
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \Gamma,x:\mathbb{A} \triangleright v: \mathbb{B} \\
    \hline
   \Gamma \triangleright \lambda x:\mathbb{A} . v: \mathbb{A} \multimap \mathbb{B} 
\end{array}
$
\end{minipage}
\hspace{-27pt} (\multimap_{i}) 
 \hspace{76pt}
 \begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \Gamma \triangleright v: \mathbb{A} \multimap \mathbb{B} \quad  \Delta \triangleright w: \mathbb{A}  \quad E \in \text{Sf}(\Gamma;\Delta)  \\
    \hline
   E \triangleright v w: \mathbb{B}  
\end{array}
$ \end{minipage}
\hspace{67pt} (\multimap_{e}) 
\end{aligned}
\end{split}
\end{equation*}
  }
\caption{Term formation rules of affine lambda calculus.}
\label{fig:typing_rules_linear}
\end{figure}
The rule (ax) states that if there is a function $f \in \Sigma$ that has type $\mathbb{A}_1, \ldots, \mathbb{A}_n \rightarrow \mathbb{A}$ and a set of variables $v_1,\ldots, v_n$ whose types match the type of the arguments of $f$, then if that function is applied to $v_1,…,v_n$ the respective result is of type $\mathbb{A}$.
The rule (hyp) is a tautology: under the assumption that $x$ has type $\mathbb{A}$, $x$ has type $\mathbb{A}$. 
The rule ($\mathbb{I}_{i}$) asserts that the unit element $*$ always has type $\mathbb{I}$. 
The rule ($\multimap_i$) expresses that if $v$ is a term of type $\mathbb{B}$ with a variable $x$ of type $\mathbb{A}$, then $\lambda x:\mathbb{A} . v$ is a function of type $\mathbb{A} \multimap \mathbb{B} $. 
The rule $(\multimap_e)$ states that a function of type $\mathbb{A} \multimap \mathbb{B}$  can be applied to an argument of type $\mathbb{A}$  to produce a result of type $\mathbb{B}$. 
The rule $(\mathbb{\otimes}_i)$  asserts that if there is a term $v$ of type $\mathbb{A}$ and a term $w$ of type $\mathbb{B}$,  then the tensor of these terms is of type $\mathbb{A} \otimes \mathbb{B}$.
The rule $(\mathbb{\otimes}_e)$ expresses if there is a term $w$ of type $\mathbb{C}$ with variables $x$ and $y$ of types $\mathbb{A}$ and $\mathbb{B}$, respectively, and a term $v$ of type $\mathbb{A} \otimes \mathbb{B}$, then $v$ can be deconstructed into $x \otimes y$. 
The rule $(\mathbb{I}_e)$ states that if there is a term $w$ of type $\mathbb{A}$ and a term $v$ of type $\mathbb{I}$, then $v$ can be discarded, and only the term $w$ remains. 
Finally, the rule $(\text{dis})$ asserts that a term $v$ of type $\mathbb{A}$ can be discarded, resulting in a term of type $\mathbb{I}$.

For a better understanding of the rules, a few straightforward programming examples are provided.  For instance, the program that swaps the elements of a tensor product can be written as follows:
\begin{equation*}
\begin{split}
& x : \mathbb{A},  y : \mathbb{B} \triangleright \text{pm} \hspace{3 pt} x \otimes y\hspace{3 pt} \text{to} \hspace{3 pt} a \otimes b. \hspace{1pt} b \otimes a : \mathbb{B} \otimes \mathbb{A}
\end{split}
\end{equation*}
Now, to prove that this program is well-typed one can write the following typing derivation:
\begin{equation*}
\begin{split}
1 \hspace{10 pt} & x : \mathbb{A} \triangleright x : \mathbb{A}  \hspace{10 pt} & {(\text{hyp})} \\
2 \hspace{10 pt} &  y : \mathbb{B} \triangleright   y : \mathbb{B} \hspace{10 pt} & {(\text{hyp})} \\
3 \hspace{10 pt} & x : \mathbb{A},  y : \mathbb{B} \triangleright x \otimes y : \mathbb{A} \otimes \mathbb{B} \hspace{10pt} & \text{($1,2,\otimes_i$)} \\
4 \hspace{10 pt} &  b : \mathbb{B} \triangleright   b : \mathbb{B} \hspace{10 pt}&{(\text{hyp})} \\
5 \hspace{10 pt} &   b : \mathbb{B} \triangleright  b : \mathbb{B} \hspace{10 pt}&{(\text{hyp})} \\
6 \hspace{10 pt} & a : \mathbb{A},  b : \mathbb{B} \triangleright b \otimes a : \mathbb{B} \otimes \mathbb{A} \hspace{10pt} &\text{($4,5,\otimes_i$)} \\
7\hspace{10 pt}& x : \mathbb{A},  y : \mathbb{B} \triangleright \text{pm} \hspace{3 pt} x \otimes y\hspace{3 pt} \text{to} \hspace{3 pt} a \otimes b. \hspace{1pt} b \otimes a : \mathbb{B} \otimes \mathbb{A}& \hspace{10pt} \text{($3,6,\otimes_e$)}
\end{split}
\end{equation*}
Observe that in the notation of the third column, the numbers correspond to the premises utilized in the application of the rule.

Another example is the function that recieves a tensor product and returns first element and discards the second:
\begin{equation*}
\begin{split}
& - \triangleright \lambda x: \mathbb{A \otimes B}. \text{pm} \hspace{3 pt} x \hspace{3 pt} \text{to} \hspace{3 pt} a \otimes b. \hspace{1 pt} \text{dis}(b) \hspace{3 pt} \text{ to } *.a: \mathbb{A}
\end{split}
\end{equation*}
Now, to prove that this program is well-typed one can write the following typing derivation:
\begin{equation*}
\begin{split}
1  \hspace{10 pt} & b : \mathbb{B} \triangleright b : \mathbb{B}  \hspace{10 pt} & {(\text{hyp})} \\
2 \hspace{10 pt} & b : \mathbb{B} \triangleright \text{dis}(b): \mathbb{I} \hspace{10 pt} & {(1,\text{dis})} \\
3 \hspace{10 pt} & a : \mathbb{A} \triangleright a : \mathbb{A}  \hspace{10 pt} & {(\text{hyp})} \\
4 \hspace{10 pt} &  a : \mathbb{A}, b : \mathbb{B}  \triangleright \text{dis}(b) \hspace{3 pt} \text{ to } *.a  & {(2,3,\mathbb{I}_{e})} \\
5 \hspace{10 pt} & x : \mathbb{A \otimes B} \triangleright x : \mathbb{A \otimes B}  \hspace{10 pt} & {(\text{hyp})} \\
6 \hspace{10 pt} & x : \mathbb{A \otimes B} \triangleright \text{pm} \hspace{3 pt} x \hspace{3 pt} \text{to} \hspace{3 pt} a \otimes b. \hspace{1 pt} \text{dis}(b) \hspace{3 pt} \text{ to } *.a : \mathbb{A} \hspace{10pt} & \text{($4,5,\otimes{I}_{e}$)} \\
4 \hspace{10 pt} & - \triangleright \lambda x: \mathbb{A \otimes B}. \text{pm} \hspace{3 pt} x \hspace{3 pt} \text{to} \hspace{3 pt} a \otimes b. \hspace{1 pt} \text{dis}(b) \hspace{3 pt} \text{ to } *.a: \mathbb{A} \hspace{10pt} & \text{($6,\multimap_i$)}
\end{split}
\end{equation*}


\todo[inline,size=\normalsize]{Isto fica aqui ou vai para o capítulo seguinte? } 
\todo[inline,size=\normalsize]{Also fala-se de Type inference algorithm? Tipo existe...} 
The no-cloning theorem states that it is impossible to duplicate a quantum bit \cite{wootters1982single}. This principle is upheld by the type system outlined in \autoref{fig:typing_rules_linear}, which does not allow the repeated use of a variable (seen as a quantum resource).

%substituição e exchange
%beta e eta reductions


Linear $\lambda$-calculus comes equipped with a class of equations, given in \autoref{fig:equations-linear-lambda}, specifically equations-in-context $\Gamma \triangleright v = w : \mathbb {A}$.

\begin{figure}[H]
  \centering
  \begin{tabular}{ |c|c| }
      \hline 
      Monoidal structure & Higher-order structure \\
      \hline
      pm $v \otimes w$ to $x \otimes y.$ $u = u[v/x,w/y]$& \\
      pm $v$ to $x \otimes y.$ $u[x \otimes y/z] = u[v/z]$ & $(\lambda x : A.$ $v) w = v[w/x]$\\
      $* \text { to } *.$ $v = v$ & $\lambda x : A.(v x) = v$ \\
      $v$ to $*$ . $w[* / z] = w[v / z]$ & \\
      \hline
      \multicolumn{2}{|c|}{Commuting conversions} \\
      \hline
      \multicolumn{2}{|c|}{$u[v \text{ to } \ast . w/z] = v \text{ to } \ast . u[w/z]$}  \\
      \multicolumn{2}{|c|}{$u[$pm $v$ to $x \otimes y.$ $w/z] =$ pm $v$ to $x \otimes y.$ $u[w/z]$} \\
      \hline
      \multicolumn{2}{|c|}{Discard} \\
      \hline
      \multicolumn{2}{|c|}{$v: \mathbb{I} = \text{dis}(x_1) \text{ to } \ast.$ $\ldots$ $\text{dis}(x_{n-1}) \text{ to } \ast \text{ dis}(x_{n})$} \\
      \hline
  \end{tabular}
  \caption{Equations-in-context for affine lambda calculus}
  \label{fig:equations-linear-lambda}
\end{figure}




\section{Metric equational system}
Metric equations \cite{mardare2016quantitative}, \cite{mardare2017axiomatizability} are a strong candidate for reasoning about approximate program equivalence. These equations take the form of $t=_{\epsilon} s$, where  $\epsilon$ is a non-negative rational representing the ``maximum distance" between the two terms $t$ and $s$. The metric equational system for linear lambda calculus is depicted in \autoref{fig:metric deductive system} \cite{dahlqvist2022syntactic}.
\vspace{-10pt}
\begin{figure} [H]
\begin{equation*}
\begin{split}
\begin{aligned}
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \\
    \hline
   v=_{0}v
\end{array}
$
\end{minipage}
\hspace{-90pt}
\text{(refl)} 
 \hspace{55pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    v=_{q}w \quad w=_{r}u  \\
    \hline
   v=_{q + r} u
\end{array}
$ \end{minipage}
\hspace{-40pt} \text{(trans)} 
\hspace{55pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    v=_{q}w \quad r\geq q  \\
    \hline
   v=_{r} w
\end{array}
$ \end{minipage}
\hspace{-45pt} \text{(weak)} \\
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    \forall r < q . \hspace{4pt} v=_{r} w \\
    \hline
   v=_{q}w
\end{array}
$
\end{minipage}
\hspace{-45pt}
\text{(arch)} 
 \hspace{40pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    \forall i \leq n. \hspace{4pt} v=_{q_i} w\\
    \hline
   v=_{\wedge q_i} w
\end{array}
$ \end{minipage}
\hspace{-40pt} \text{(join)} 
\hspace{40pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    v=_{q} w \quad v'=_{r} w' \\
    \hline
   v \otimes v' =_{q + r} w \otimes w'
\end{array}
$ \end{minipage}
\hspace{-45pt}  \\
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
   \forall i \leq n. \hspace{4pt} v_{i}=_{q_i} w_{i}\\
    \hline
   f(v_{1},...,v_{n})=_{\Sigma q_i} f(w_{1},...,,w_{n}) 
\end{array}
$
\end{minipage}
 \hspace{34pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
   v=_{q}w  \quad v'=_{r}w'\\
    \hline
    v \text { to } *.v' =_{q+r} w \text { to } *.w'
\end{array}
$ \end{minipage}
\hspace{0pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    v=_{q} w  \\
    \hline
  \lambda x : \mathbb{A}. \hspace{4pt} v=_{q} \lambda x:\mathbb{A}. \hspace{4pt} w
\end{array}
$ \end{minipage}
\hspace{20pt}  \\
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    v=_{q} w \quad  v'=_{r} w'  \\
    \hline
   \text{pm} \hspace{4pt} v \hspace{4pt} \text{to} \hspace{4pt} x \otimes y. \hspace{4pt} v'=_{q + r}\text{pm} \hspace{4pt} w \hspace{4pt} \text{to} \hspace{4pt} x \otimes y .  \hspace{4pt} w'
\end{array}
$
\end{minipage}
\hspace{200pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    v =_{q} w \quad v'=_{r} w'   \\
    \hline
  v v' =_{q + r} w w'
\end{array}
$ \end{minipage}
 \\
 &
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
  \Gamma \triangleright v =_{q} w: \mathbb{A} \quad \Delta \in \text{perm}(\Gamma)\\
    \hline
   \Delta \triangleright v =_{q} w: \mathbb{A}
\end{array}
$
\end{minipage}
\hspace{180pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    v =_{q} w \quad v'=_{r} w'    \\
    \hline
  v[v'/x]=_{q + r} w[w'/x]
\end{array}
$ \end{minipage}
\hspace{10pt}
\end{aligned}
\end{split}
\end{equation*}
\caption{Metric equational system}
\label{fig:metric deductive system}
\end{figure}
\vspace{-5pt}







\chapter{Quantum Meets Lambda Calculus} \label{sec:Quantum Lambda Calculus}

In quantum information theory, the role of higher-order functions encompasses two fundamental aspects. The first involves the concept of entangled functions and how well-known quantum phenomena find natural descriptions through such functions. The second concerns the interplay between classical objects and quantum objects in a higher-order context. Quantum computation conventionally handles classical and quantum data, while the higher-order context introduces a third data type: functions. These functions fall into two categories - those "quantum-like" (entangled, single-use) and those "classical-like" (duplicable, reusable). Remarkably, this classification transcends input/output types, highlighting the coexistence of quantum-like functions operating on classical data and classical-like functions operating on quantum data. \cite{selinger2009quantum}.

\section{Quantum Computing Preliminaries} \label{sec:Quantum Computing Preliminaries}
This section presents background on quantum information and quantum computation \cite{nielsen2010quantum}.


The basic unit of information in quantum computation is a quantum bit or qubit \cite{perdrix2008quantum}. The state of a single qubit is described by a normalized vector of the 2-dimensional Hilbert space $\mathbb{C}^{2}$. When global phases are ignored we can represent a quantum state $\ket{\psi} \in \mathbb{C}^{2}$ in the form,
\begin{equation} \label{eq:qubit_bs}
     \cos\left(\frac{\theta}{2}\right) \ket{0} + e^{i\phi}\sin\left(\frac{\theta}{2}\right)\ket{1}
\end{equation}
which corresponds to a point in the unit sphere where $\theta$ marks the latitude (\textit{i.e.} the polar angle) and $\phi$ marks the longitude (\textit{i.e.} the azimuthal angle). This representation is traditionally called the Bloch sphere representation. A point in the latter representation
corresponds to the vector in $\mathbb{R}^{3}$ defined by $(\cos \phi \sin \theta, \sin \phi \sin \theta, \cos \theta)$ and often called Bloch vector.

An $n$-qubit state can be represented by a unit vector in $2^n$-dimensional Hilbert space $\mathbb{C}^{2^{n}}$. An $n$-qubit mixed state can be represented by a density operator $ \mathbb{C}^{2^{n}} \xrightarrow{} \mathbb{C}^{2^{n}}$, whose matrix representation is $\rho = \Sigma_{i} \hspace{2pt} p_{i} \vert \phi_{i} \rangle \langle \phi_{i} \vert$. A density operator encodes uncertainty about the current state of the quantum system at hand. For example, a mixed state with half probability of $\vert 0 \rangle$ and $\vert 1 \rangle$ can be represented by $\frac{\vert 0 \rangle \langle 0 \vert + \vert 1 \rangle \langle 1 \vert}{2}=I/2$, where $I$ is the identity matrix.  One usually denotes density matrices by the greek letters $\rho$, $\sigma$, and so forth. The set of density operators is denoted by $\mathcal{D}_{n} \subseteq \mathbb{C}^{ 2^{n \times n}}$.

Measurements extract classical information from quantum states.  If a measurement ${M_m}$ is performed on a state $\rho$, the outcome $m$ is observed with probability $p_m = \text{Tr}(M_{m} \rho M^{\dag}_{m})$ for each $m$. Moreover, after a measurement yielding outcome $m$, the state collapses to $M_{m}\rho M^{\dag}_{m}/p_{m}$. 


Operations on quantum systems can be described using unitary operators. An operator, $U$, is unitary if its Hermitian conjugate is its own inverse, \textit{i.e.}, $U^{\dag} U= UU^{\dag} = I$. For a pure state $|\psi \rangle$, a unitary operator $U$ describes an evolution from $|\psi \rangle$ to $ U|\psi \rangle$. Similarly, for a density operator $\rho $, the corresponding evolution is $\rho \mapsto U\rho U^{\dag}$. For example, the bit flip gate $X=\big(\begin{smallmatrix}
  0 & 1\\
  1 & 0
\end{smallmatrix}\big)$ maps  $\vert 0 \rangle$  to  $\vert 1 \rangle$ and  $\vert 1 \rangle$  to  $\vert 0 \rangle$. On the other hand, the Hadamard gate $H= \frac{1}{\sqrt{2}}\big(\begin{smallmatrix}
  1 & 1\\
  1 & -1
\end{smallmatrix}\big)$ maps $\vert 0 \rangle$ to  $ \frac{\vert 0 \rangle + \vert 1 \rangle }{\sqrt{2}} $ (denoted as $\vert + \rangle $) and $\vert 1 \rangle$ to $ \frac{\vert 0 \rangle - \vert 1 \rangle }{\sqrt{2}} $ (denoted as $\vert - \rangle $). There are also multi-qubit gates, such as $C\hspace{-2pt}N\hspace{-1pt}O\hspace{-1pt}T$, which leaves the states $\vert 0 0 \rangle$ and  $\vert 0 1 \rangle$ unchanged, and maps $\vert 1 0 \rangle$ and $\vert 1 1 \rangle$ to each other.

More broadly, the evolution of a quantum system can be defined by a super-operator $E$, which is a completely-positive and trace-preserving linear map from $\mathcal{D} (n)$ to $\mathcal{D} (m)$. A super-operator $E$ is called positive if it sends positive matrices to positive matrices, \textit{i.e.} $A \geq 0 \Rightarrow{} E A \geq 0$. A super-operator is said to be completely positive if, for any positive integer $k$ and any $k$-dimensional Hilbert space $\mathbb{C}^{2^{k}}$, the super-operator $E \otimes I_{\mathbb{C}^{2^{k}}}$ is a positive map on $\mathcal{D}(n \times k)$. Finally, a super-operator
$E$ is called trace-preserving if $\text{Tr} \hspace{ 2pt} E A = \text{Tr} A$ \cite{watrous2018theory}. Completely-positive, trace-preserving super-operators are traditionally called quantum channels.

For every super-operator $ E: \mathcal{D}(n) \xrightarrow{} \mathcal{D}(m)$, there exists a set of Kraus operators $\{\epsilon_{k}\}_{k}$ such that $ E(\rho)= \Sigma_{k} \hspace{2pt} \epsilon_{k}\hspace{2pt} \rho \hspace{2pt} \epsilon_{k}^{\dag}$  for any input $\rho \in  \mathcal{D}(n) $. Note that the set of Kraus operators is finite if the Hilbert space is finite-dimensional. The Kraus form of $E$ is written as $E = \Sigma_{k} \hspace{2pt} \epsilon_{k} \circ  \epsilon_{k}^{\dag}$.

A matrix $A \in  \mathbb{C}^{n\times n}$ is Hermitian if $A = A^{\dag}$.
A matrix $A \in \mathbb{C}^{n\times n}$ is said to be normal if $AA^{\dag} =  A^{\dag}A$. Clearly every Hermitian matrix is normal. Note also that for every matrix $A \in C^{n\times n}$ the matrix $A^{\dag}A$ is Hermitian. Next, it is well-known that by appealing to the spectral theorem [NC16], every normal matrix $A \in  \mathbb{C}^{n\times n}$ can be expressed as a linear combination $\sum_{i} \lambda_{i}b_{i}b_{i}^{\dag}$ where the set $\{b_{i}, \ldots , b{n}\}$ is an orthonormal basis of $\mathbb{C}^{n}$. Using this last result we can extend any function $f:\mathbb{C} \xrightarrow{} \mathbb{C}$, to normal matrices via,
\begin{equation} \label{eq:apply_f_diag}
  f(A) = \sum_{i} f(\lambda_{i})b_{i}b_{i}^{\dag}
\end{equation}
$\ldots$
The Bloch vector is given by 
\begin{equation}
  \label{eq:Bloch_vector}
  r_{\mu} = \text{Tr}(\rho \sigma_{\mu})
  \end{equation}

\todo[inline,size=\normalsize]{add trace, partial trace, reduced density matrix, and respective Bloch Vector, put the last paragragh in the right place and rewrite it} %\label{eq:Bloch\_vector})}


In the quantum paradigm, a potential notion of approximate equivalence arises from the so-called diamond norm \cite{watrous2018theory}, which induces a metric (roughly, a distance function) on the space of quantum programs (seen semantically as completely positive trace-preserving super-operators). This norm relies on another norm known as the trace norm. The $\lVert  \rVert_{1}$ latter is defined by  $\lVert A \rVert_{1} = \text{Tr}\sqrt{A^{\dag}A}$  for matrices $A \in \mathbb{C}^{n\times n}$. The trace norm induces a metric on the set of density matrices which is defined by $d(\rho, \sigma) = \lVert \rho -\sigma\rVert_{1}$. On the other hand, it is well known that the distance $d(vv^{\dag}, uu^{\dag})$ between two quantum states $v$ and $u$ is their Euclidean distance in the Bloch
sphere \cite{wallman2016noise,nielsen2010quantum}. The Euclidean norm of a vector $u \in \mathbb{C}^{n} $ is defined as:
\begin{equation} \label{eq:euclidean_distance}
\begin{centering}
\hspace{80pt}
\lVert u \rVert_{2} = \sqrt{\langle u, u\rangle} 
 \end{centering}
\end{equation}
The trace distance between two super-operators $E, E': \mathbb{C}^{n\times n} \xrightarrow{} \mathbb{C}^{m\times m }$,  denoted as $T(E,E')$, is defined as follows:
\begin{equation} \label{eq:trace_distance}
\begin{centering}
\hspace{80pt}
 T(E,E')= \max\{\lVert (E-E') A \rVert_{1} \hspace{2pt}  \vert \hspace{2pt}  \lVert A \rVert_{1}=1\} 
 \end{centering}
\end{equation}
Unfortunately, this norm is not stable under tensoring \cite{watrous2018theory}, and consequently, the diamond norm, which is based on the trace norm, is used instead. The diamond norm between two super-operators $E, E': \mathbb{C}^{n\times n} \xrightarrow{} \mathbb{C}^{m\times m }$ is defined as:
\begin{equation}  \label{eq:diamond_distance}
\begin{centering}
\hspace{110pt}
 \lVert E-E'\rVert_{\diamondsuit} =  T(E \otimes I_{n},E' \otimes I_{n}) 
 \end{centering}
\end{equation}
where $I_{n} $ is the identity super-operator over the space $\mathbb{C}^{n\times n}$.


Consider an operator  $ \text{r} : (\mathbb{C}^{n} \xrightarrow[]{} \mathbb{C}^{m}) \xrightarrow[]{} (\mathbb{C}^{n\times n}\xrightarrow[]{} \mathbb{C}^{m\times m})$ that sends an operator $T$ to the mapping $A \mapsto TAT^{\dag}$. The exact calculation of distances induced by $\lVert \rVert_{\diamondsuit}$ tends to be quite complicated, but a useful property for calculating the distance between quantum channels in the image of $r$ is provided \cite{watrous2018theory}:
Consider two operators $T, S : n \xrightarrow{} m$. There exists a unit vector $v \in \mathbb{C}^{n}$ such that, 
\begin{equation} \label{eq:norm_iso_r}
\begin{centering}
\lVert r(T) (vv^{\dag})-r(S) (vv^{\dag}) \rVert_{1} = \lVert r(T)-r(S) \rVert_{\diamondsuit}
 \end{centering}
\end{equation}







\section{Quantum Lambda Calculus:Interpretation} \label{sec:Quantum Lambda Calculus:Interpretation}

In order to define the interpretation of judgments $\Gamma \triangleright v: \mathbb{A}$, it is necessary to establish some notation first. Considering $v \in V$, $w \in W$, and $u \in U$  where $V, W, U$ represent vector spaces,  $\textsc{sw}_{V,W} : V\otimes W \xrightarrow{} W \otimes V$, denotes the swap operator, defined as $\textsc{sw}_{V,W}= v\otimes w \mapsto w \otimes v$;    $\rho_{V} : \mathbb{C} \otimes V \xrightarrow{} V $ is the left unitor defined as $\rho_{V}= 1 \otimes v \mapsto v $; $\lambda_{V} : V  \otimes \mathbb{C} \xrightarrow{} V $ is the right unitor defined as $\lambda_{V}= v \otimes 1 \mapsto v$; $\alpha_{V,W,U} : V  \otimes (W \otimes U) \xrightarrow{} (V  \otimes W) \otimes U$ is the left associator, defined as $\alpha_{V,W,U}= v \otimes (w \otimes u) \mapsto (v \otimes w) \otimes u $; and $!_{V}: V \xrightarrow{} \mathbb{C}$ is the trace operation applied to a vector, defined as  $!_{V}= v \xrightarrow{} \text{Tr} \hspace{1pt}v$. Moreover, for all operators $f: V \otimes W \xrightarrow{} U$, the operator $\overline{f} : V \xrightarrow{} (W \multimap U)$ denotes the corresponding curried version, defined as $\overline{f}(v) = w \mapsto  f(v,w)$. The subscripts in these operators will be omitted unless ambiguity arises.

For all ground types $X \in G$  the interpretation of $[\![X]\!]$  is postulated as a vector space $V$. Types are interpreted inductively using the unit $\mathbb{I}$, the tensor $\otimes$, and the linear map $\multimap$. Given a non-empty context $\Gamma=\Gamma',x: \mathbb{A}$, its interpretation is defined by $[\![\Gamma',x: \mathbb{A}]\!] = [\![\Gamma']\!] \otimes [\![\mathbb{A}]\!]$ if $\Gamma'$ is non-empty and $[\![\Gamma',x: \mathbb{A}]\!] = [\![\mathbb{A}]\!]$ otherwise. The empty context $-$ is interpreted as $[\![-]\!] = \mathbb{I}$. Given $X_{1}, . . . ,X_{n} \in V$, the $n$-tensor $(\ldots (X_1 \otimes X_2) \otimes \ldots ) \otimes X_{n}$ is denoted as $X_1 \otimes \ldots \otimes X_{n}$, and similarly for operators. 


``Housekeeping" operators are employed to handle interactions between context interpretation and the vectorial model. Given $\Gamma_{1}, \ldots, \Gamma_{n}$, the operator that splits $[\![\Gamma_{1}, \ldots, \Gamma_{n}]\!]$ into $[\![\Gamma_{1}]\!] \otimes \ldots \otimes [\![\Gamma_{n}]\!]  $ is denoted by $\text{sp}_{\Gamma_1;\ldots;\Gamma_n}: [\![\Gamma_{1}, \ldots, \Gamma_{n}]\!] \xrightarrow{} [\![\Gamma_{1}]\!] \otimes \ldots \otimes [\![\Gamma_{n}]\!] $.
On the other hand, $\text{jn}_{\Gamma_1;\ldots;\Gamma_n}$ denotes the inverse of $\text{sp}_{\Gamma_1;\ldots;\Gamma_n}$. Next, given $\Gamma, x : \mathbb{A}, y : \mathbb{B},\Delta$, the operator permuting $x$ and $y$ is denoted by $\text{exch}_{\Gamma, x : \mathbb{A}, y : \mathbb{B},\Delta}: [\![\Gamma, x : \mathbb{A}, y : \mathbb{B},\Delta]\!] \xrightarrow{} [\![\Gamma, y : \mathbb{B}, x : \mathbb{A}, \Delta]\!] $. The shuffling operator $\text{sh}_{E}: [\![E]\!] \xrightarrow{} [\![\Gamma_1, \ldots, \Gamma_n ]\!]$ is defined as a suitable composition
of exchange operators.

For every operation symbol $f: \mathbb{A}_{1}, \ldots, \mathbb{A}_{n} \xrightarrow{} \mathbb{A}$ we assume the existence of an operator $[\![f]\!]: [\![\mathbb{A}_{1}]\!] \otimes \ldots \otimes [\![\mathbb{A}_{n}]\!] \xrightarrow{}  [\![\mathbb{A}]\!] $.
The interpretation of judgments is defined by induction over derivations according to the rules in \autoref{fig:denotational_sem} \cite{dahlqvist2022syntactic}.
\vspace{-7pt}
\begin{figure} [H]
\begin{equation*}
\begin{split}
\begin{aligned}
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
      [\![\Gamma_{i} \triangleright v_{i}: \mathbb{A}_{i} ]\!]=m_{i}  \quad f: \mathbb{A}_{1}, \ldots, \mathbb{A}_{n} \in \Sigma \quad E \in \text{Sf}(\Gamma_{1}; \ldots; \Gamma_{n})\\
    \hline
  [\![E \triangleright f( v_{1},\ldots,v_{n}): \mathbb{A} ]\!] = [\![ f]\!] \cdot (m_{1}\otimes \ldots \otimes m_{n}) \cdot \text{sp}_{\Gamma_1;\ldots;\Gamma_n}\cdot \text{sh}_{E}
\end{array}
$
\end{minipage}
\hspace{204pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
      \\
    \hline
  [\![ x:\mathbb{A} \triangleright x:\mathbb{A}]\!] = \text{id}_{[\![\mathbb{A} ]\!]}
\end{array}
$ \end{minipage} \\
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \\  
    \hline
   [\![ - \triangleright *: \mathbb{I}]\!] = \text{id}_{[\![\mathbb{I} ]\!]}
\end{array}
$
\end{minipage}
\hspace{-31pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
      [\![\Gamma \triangleright v: \mathbb{A} \otimes \mathbb{B} ]\!]=m  \quad [\![\Delta,x: \mathbb{A}, y: \mathbb{B}  \triangleright w: \mathbb{C} ]\!] =n  \quad E \in \text{Sf}(\Gamma;\Delta)\\
    \hline
  [\![ E\triangleright \text{pm } v \text{ to } x \otimes y. w :\mathbb{C}]\!] = n \cdot \text{jn}_{\Delta;\mathbb{A};\mathbb{B}} \cdot \alpha \cdot \text{sw}\cdot (m \otimes \text{id}) \cdot \text{sp}_{\Gamma;\Delta} \cdot \text{sh}_{E}
\end{array}
$ \end{minipage} \\
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}  
     [\![ \Gamma \triangleright v: \mathbb{A} ]\!] =m \quad [\![\Delta \triangleright w: \mathbb{B} ]\!]=n \quad E \in \text{Sf}(\Gamma;\Delta) \\
    \hline
  [\![ E \triangleright v \otimes w: \mathbb{A} \otimes \mathbb{B} ]\!] = (m \otimes n) \cdot \text{sp}_{\Gamma;\Delta} \cdot \text{sh}_{E}
\end{array} 
$
\end{minipage}\\
&
 \begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c} 
    [\![\Gamma \triangleright v: \mathbb{I} ]\!]=m  \quad [\![\Delta \triangleright w: \mathbb{A}]\!]=n \quad E \in \text{Sf}(\Gamma;\Delta)  \\
    \hline
  [\![E \triangleright v \text { to } *.w: \mathbb{A} ]\!]=n \cdot \lambda \cdot (m \otimes \text{id}) \cdot \text{sp}_{\Gamma;\Delta} \cdot \text{sh}_{E}
\end{array}
$ \end{minipage} 
\hspace{130 pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c} 
     [\![\Gamma,x:\mathbb{A} \triangleright v: \mathbb{B} ]\!] = m \\
    \hline
   [\![ \Gamma \triangleright \lambda x:\mathbb{A} . \hspace{2pt } v: \mathbb{A} \multimap \mathbb{B}]\!] = \overline{m \cdot \text{jn}_{\Gamma;\mathbb{A}}}
\end{array}
$
\end{minipage} \\
&
 \begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c} 
     [\![\Gamma \triangleright v: \mathbb{A} \multimap \mathbb{B} ]\!] = m \quad [\![  \Delta \triangleright w: \mathbb{A} ]\!] =n \quad E \in S\hspace{-3pt}f(\Gamma;\Delta)  \\
    \hline
  [\![ E \triangleright v w: \mathbb{A} ]\!] = \text{app} \cdot (m \otimes n) \cdot \text{sp}_{\Gamma;\Delta} \cdot \text{sh}_{E}
\end{array}
$ \end{minipage}
\hspace{190 pt} %[\![ ]\!]
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     [\![\Gamma \triangleright v: \mathbb{A}]\!]  = f \\
    \hline
   [\![ \Gamma \triangleright \text{dis}(v):  \mathbb{I} ]\!] = !_{[\![ \mathbb{A} ]\!]} \cdot f
\end{array}
$
\end{minipage}
\end{aligned}
\end{split}
\end{equation*}
\caption{Judgment interpretation}
\label{fig:denotational_sem}
\end{figure}







\todo[inline,size=\normalsize]{Adicionar os operadores CPTP que vou usar} %\label{eq:Bloch\_vector})}

In the case of quantum lambda calculus, which combines classical and quantum features, it is natural to consider two distinct basic data types: a type $\textit{bit}$ of classical bits and a type $\textit{qbit}$ of quantum bits.  The interpretation of these types is defined as  $[\![\textit{bit}]\!]=\mathbb{C}\oplus\mathbb{C}$ and $[\![\textit{qbit}]\!]=\mathbb{C}^{2\cdot 2}$. The type $\mathbb{I}$ is interpreted as $[\![\mathbb{I}]\!]=\mathbb{C}$.

The following operations are considered: $\textit{new} \hspace{2pt} 0  :\mathbb{I}  \multimap \textit{bit} $, $\textit{new} \hspace{2pt} 1  :\mathbb{I}  \multimap \textit{bit} $, $q : \textit{bit}  \multimap \textit{qbit}$, $\textit{meas}:\textit{qbit} \xrightarrow{} \textit{bit}$, and $\textit{U}:\textit{qbit},\ldots,\textit{qbit} \xrightarrow{} \textit{qbit}^{\otimes n}$. Their correspondent judgment interpretation is shown in \autoref{fig:interpret_ops}. 



\begin{figure}[H]
  \begin{equation*}
  \begin{split}
  \begin{aligned}
  &
  \hspace{0pt}
  \begin{minipage}[t]{0.45\textwidth}
  $\begin{aligned}
    [\![\textit{new} \, 0 ]\!] : \hspace{2pt}& \mathbb{C} \multimap \llbracket \textit{bit} \rrbracket  \\
  & 1 \mapsto (1,0)
  \end{aligned}$
  \end{minipage}
  \hspace{-30pt}
  \begin{minipage}[t]{0.45\textwidth}
  $\begin{aligned}
    [\![\textit{new} \, 1 ]\!] :\hspace{2pt}& \mathbb{C} \multimap \llbracket \textit{bit} \rrbracket  \\
    & 1 \mapsto (0,1)
  \end{aligned}$
  \end{minipage} 
  \hspace{-30pt}
  \begin{minipage}[t]{0.45\textwidth}
  $\begin{aligned}
    [\![q ]\!] : \hspace{2pt}&\llbracket \textit{bit} \rrbracket \multimap \llbracket \textit{qbit} \rrbracket\\
     &(a,b) \mapsto \big(\begin{smallmatrix}
    a & 0\\
    0 & b
  \end{smallmatrix}\big) 
  \end{aligned}$
  \end{minipage} \\
  &
  \hspace{0pt}
  \begin{minipage}[t]{0.45\textwidth}
  $\begin{aligned}
    [\![\textit{meas}]\!]:\hspace{2pt} & \llbracket \textit{qbit} \rrbracket \xrightarrow{} \llbracket \textit{bit} \rrbracket  \\
    &\rho \mapsto ( \text{Tr} (M_{0} \rho M_{0}^{\dag}), \text{Tr} (M_{1} \rho M_{1}^{\dag})) 
  \end{aligned}$
  \end{minipage} 
  \hspace{118pt}
  \begin{minipage}[t]{0.45\textwidth}
  $\begin{aligned}
    [\![\textit{U} ]\!] : \hspace{2pt} & \llbracket \textit{qbit} \rrbracket^{\otimes n} \xrightarrow{} \llbracket 
    \textit{qbit} \rrbracket^{\otimes n} \\
    & \rho \mapsto U \rho \hspace{2pt}  U^{\dag}
  % & \rho,...,\rho_{n} \mapsto U \hspace{-2pt}\left(\bigotimes_{i=1}^{n}\rho_{i}\right ) U^{\dag}
  \end{aligned}$
  \end{minipage} \\
  \end{aligned}
  \end{split}
  \end{equation*}
  \caption{Judgment interpretation of the operations in quantum lambda calculus.}
  \label{fig:interpret_ops}
  \end{figure}

