







%It should be noted that the concept of a norm, as well as the properties of some norms, are relevant here,  as the existence of a metric system implies that operators have a well-defined norm. 



%\section{Functional Analysis} \label{sec:funal}



 %Functional analysis can be viewed as the  branch of mathematics that studies how the properties of finite-dimensional vector spaces generalize in infinite dimensional spaces.

%As a result, 
%p.26/28




%p.57->Bruce
%p97/100 -> conway




%p110, p.85


%\begin{lemma}
  %In the finite dimensional setting the norm topology and the weak topology coincide.
%\end{lemma}




%p.243 infinite dimensional analysis 

%IMPORTANTE:Since a finite dimensional space has only one Hausdorff linear topology, the norm topology and the weak topology must be the same.



%\section{Probabilistic Programming/Measure theory} \label{sec:pp}
 






%\subsection{Probabilistic Programming and Measure Theory}
% livro probabilistic programming 

% Probabilistic programs describe recipes for inferring statistical conclusions from a complex mixture of uncertain data and real-world observations. They can represent probabilistic graphical models are expected to have a major impact on machine intelligence. Probabilistic programs are ubiquitous. They steer autonomous robots and self-driving cars, are key to describe security mechanisms, naturally code up randomised algorithms for solving NP-hard or even unsolvable problems, and are rapidly encroaching on AI. Probabilistic programming aims to make probabilistic modelling and machine learning accessible to the programmer.


% INTRO Medidas e espaços mensuraveis 



  


   







%\todo[inline,size=\normalsize]{Normas} 

% def de valor abs p.133 (2.4) measure_theoritic_probability_by_athreya__lahiri.

%Lebesgue decomposition p.360 - measure theory


%\section{C* and W*-Algebras} \label{sec:c*_w*}

%Proposition 5.13. theory of op algebras 1 Takesaki -> f \otimes g é cp se f e g são cp





\todo[inline,size=\normalsize]{Colocar um frase bonitinha sobre como isto acaba por ser tb um resumo do que eu aprendi e portanto são apresentados os conceitos de raiz} 

\chapter{Metric Lambda Calculus} \label{ch:metriclambda}

\todo[inline,size=\normalsize]{Cenas de Met-enriched e afins ficam neste capitulo ou passam para o próximo? (Estou a considerar a possibilidade de colocar só no próximo por causa de estar a definir 2 vezes metric lambda theory e cenas desse género. Also este capitulo vai ficar gigante.)}

\todo[inline,size=\normalsize]{Sintaxe-> acrescentar exemplos com case, regras dos condicionais e respetiva explicação, a cena das free variables e a cena das props com prova.}


\todo[inline,size=\normalsize]{Categorias -> tirar as cenas de cptp e ban e meter as cenas de quocientes algures}

\todo[inline,size=\normalsize]{interpretação -> acrescentar a interpretação dos condicitinais; ver a interpretação em set dos programas exemplo da sintaxe}

\todo[inline,size=\normalsize]{Mudar a descrição do capítulo} 

The Lambda Calculus, developed by Church and Curry in the 1930s, serves as a formal language capturing the key attribute of higher-order functional languages, treating functions as first-class citizens, allowing them to be passed as arguments \cite{barendregt1984lambda}.  Moreover, lambda calculus has been proven to be universal in the sense that any computable function can be represented as an expression within the language \cite{bernays1936alonzo} . Beyond its foundational aspects, this calculus incorporates extensions for modeling side effects, including probabilistic or non-deterministic behaviors and shared memory.  Higher-order functions form a pivotal abstraction in practical programming languages such as LISP, Scheme, ML, and Haskell.

%The metric lambda calculus incorporates a metric equational system, enabling reasoning about approximate program equivalence.

This chapter introduces the metric lambda calculus as presented in \cite{dahlqvist2022syntactic} drawing also \cite{mackieLanguageAutonomous1993,croleCategoriesTypes1994,selinger2013lecture}. The metric lambda calculus integrates notions of
approximation into the equational system of affine lambda calculus, a variant of lambda calculus that restricts each variable to being used at most once.  This chapter offers a brief insight into lambda calculus and an overview of the syntax, metric equational system and interpretation of the metric lambda calculus. It also includes an exposition of the definitions and results from category theory used throughout the remainder of the thesis, based on \cite{yanofskyMonoidalCategoryTheory2024,barrCategoryTheoryComputing1990,maclane13}.
For structural reasons, soundness and completeness with respect to the ``traditional'' equational system are discussed in this chapter, while the corresponding notions for the metric $\lambda$-theory are addressed in the following chapter. It is worth noting that we explicitly prove certain results concerning conditionals; although these results are well known, their proofs appear to be absent from the existing literature. Additionally, we illustrate the usefulness of the ``traditional'' equational system by utilizing it to demonstrate that the terms $\inl(*)$ and $\inr(*)$ possess certain properties that are characteristic of booleans in classical logic.
For a more detailed study of lambda calculus theory, the reader is referred to \cite{barendregt1984lambda}.

 
%We then illustrate the use of the language for describing quantum and probabilistic programs. 



\section{The Lambda Calculus}

The concept of a function takes a central role in the lambda calculus. But what exactly is a function?  In most mathematics, the “functions as graphs” paradigm the “functions as graphs” paradigm is the most elegant and appropriate framework for understanding functions. Within this paradigm, each function $f$ has a fixed domain $X$ and a fixed codomain $Y$. The function $f$ is then a subset of $X \times Y$ that satisfies the property that for each $x \in X$ there is a unique $y \in Y$ such that $(x,y) \in f$. Two functions $f$ and $g$ are equal if they yield the same output on each input, that is if $f(x) = g(x)$ for all $x \in X$. This perspective is known as the extensional view of functions, as it emphasizes that the only observable property of a function is how it maps inputs to outputs.

On the other hand, the “functions as rules” paradigm is more appropriate within computer science. In this context, defining a function involves specifying a rule or procedure for computing the function. Such a rule is often expressed in the form of a formula, for example, \( f(x) = x^2 \). As with the mathematical paradigm, two functions are considered extensionally equal if they exhibit the same input-output behavior. However, this view also introduces the notion of intensional equality: two functions are intensionally equal if they are defined by (essentially) the same formula.


In the lambda calculus, functions are described explicitly as formulae. The function $f:x \mapsto f(x)$ is represented as $\lambda x.f(x)$.  Applying a function to an argument is done by juxtaposing the two expressions. For instance consider the function $f:x \mapsto x+1$, to compute $f(2)$ one writes $(\lambda x.x+1)(2)$.

The expression of higher‑order functions - functions whose inputs and/or outputs are themselves functions- in a simple manner is an essential feature of lambda calculus. For example, the composition operator $f,g \mapsto f \circ g$ is written as $\lambda f. \lambda g. \lambda x. f(g(x))$. Considering the functions $f:x \mapsto x^2$ and $g:x \mapsto x+1$, to compute $(f \circ g)(2)$ one writes $$(\lambda f. \lambda g. \lambda x. f(g(x)))(\lambda x.x^2)(\lambda x.x+1)(2).$$

As mentioned above,  within  the “functions as rules” paradigm, is not
always necessary to specify the domain and codomain of a function in advance. For instance, the identity function $f: x \mapsto x$, can have any set $X$ as its domain and codomain, provided that the domain and codomain are the same. In this case, one says that $f$ has type $X \rightarrow{} X$. In the case of the composition operator, $h=\lambda f. \lambda g. \lambda x. f(g(x))$, the domain and codomain of the functions $f$ and $g$ must match. Specifically, $f$ can have any set $X$ as its domain and any set  $Y$ as its codomain, provided that $Y$ is the domain of $g$. Similarly, $g$ can have any set $Z$ as its codomain.  Thus,  $h$ has type $$(X \rightarrow{} Y) \rightarrow{} (Y \rightarrow{} Z) \rightarrow{} (X \rightarrow{} Z).$$ 

This flexibility regarding domains and codomains enables operations on functions that are not possible in ordinary mathematics. For instance, if $f = \lambda x.x$ is the identity function, then one has that $f(x) = x$ for any $x$. In particular, by substituting $f$ for $x$, one obtains $f(f) = (\lambda x.x)(f) = f$. Note that the equation $f(f) = f$ is not valid in conventional mathematics, as it is not permissible, due to set-theoretic constraints, for a function to belong to its own domain.

Nevertheless this remarkable aspect of lambda calculus, this work focuses on a more restricted version of the lambda calculus, known as the simply-typed lambda calculus. Here, each expression is always assigned a type, which is very similar to the situation in mathematics. A function may only be applied to an argument if the argument's type aligns with the function's expected domain. Consequently, terms such as $f(f)$ are not allowed, even if $f$ represents the identity function.




%In order to be able to manipulate lambda-terms more easily, one can associate a type to each lambda-term


\section{Syntax}

The grammar and term formation rules of the affine lambda calculus, discussed in \cite{dahlqvist2022syntactic}, are presented in this subsection.

\subsection{Type system}

As previously mentioned, this work focuses on the simply-typed lambda calculus, this work focuses on the simply-typed lambda calculus, where each lambda term is assigned a \emph{type}. Unlike sets, types are \emph{syntactic} objects, meaning they can be discussed independently of their elements. One can conceptualize types as names or labels for set. The definition of the grammar of types for affine lambda calculus is as follows, where $G$ represents a set of ground types, is given by the following \acrfull{bnf} \cite{backus1960report}.
\begin{equation} \label{eq:grammartypes}
\centering
\hspace{95pt} \mathbb{A} ::= X \in G \hspace{3 pt} \vert \hspace{3 pt} \mathbb{I}  \hspace{3 pt}  \vert \hspace{3 pt} \mathbb{A}  \otimes  \mathbb{A} \hspace{3 pt}  \vert \hspace{3 pt} \mathbb{A}  \oplus  \mathbb{A} \hspace{3 pt} \vert  \hspace{3 pt}  \mathbb{A} \multimap  \mathbb{A}
\end{equation}
Note that this is an inductive definition. Ground types are things such as booleans, integers, and so forth. The type $\mathbb{I}$ is the unit/empty type with only one element. The type $\mathbb{A} \otimes \mathbb{A}$ corresponds to the tensor of two types. The type $\mathbb{A} \oplus \mathbb{A}$ can be seen as the coproduct/sum of types. Finally, the type $\mathbb{A} \multimap \mathbb{B}$ is the type of linear maps one type to another.

 %It can be intuitively understood as the disjoint union of two types, analogous to the disjoint union in set theory: an element of $\mathbb{A} \oplus \mathbb{B}$ is either an element of $\mathbb{A}$ or an element of $\mathbb{B}$, together with an indication which of the two it belongs to. 

%The type $\mathbb{A} \oplus \mathbb{B}$ can be intuitively understood as the disjoint union of two types, analogous to the disjoint union in set theory: an element of $\mathbb{A} \oplus \mathbb{B}$ is either an element of $\mathbb{A}$ or an element of $\mathbb{B}$, together with a tag indicating which of the two it belongs to.


\subsection{(Raw)Terms}


The expressions of the lambda calculus are called lambda terms. In the simply-typed lambda calculus, each lambda term is assigned a type. The terms without the specification of a type are called \emph{raw typed lambda terms}. The grammar of \emph{raw typed lambda terms} is given by the \acrshort{bnf} below.
\begin{equation*} \label{eq:grammarlambda}
\begin{split}
 v,v_1, \ldots, v_n,w \hspace{10 pt} ::= \hspace{10 pt}& x \hspace{3 pt} \vert \hspace{3 pt} f(v_1, \ldots, v_n) \hspace{3 pt} \vert \hspace{3 pt} *  \hspace{3 pt} \vert \hspace{3 pt} (\lambda x: \mathbb{A}. v )\hspace{3 pt} \vert \hspace{3 pt} (v w) \hspace{3 pt}  \vert \hspace{3 pt} v \otimes w \hspace{3 pt} \vert
 \\&    \text{pm} \hspace{3 pt} v \hspace{3 pt} \text{to} \hspace{3 pt} x \otimes y. w  \hspace{3 pt}  \vert \hspace{3 pt} v \hspace{3 pt} \text{ to } *.w \hspace{3 pt} \vert \hspace{3 pt} \text{dis}(v) \hspace{3 pt} \vert \hspace{3 pt} \text{inl} (v) \hspace{3 pt} \vert \hspace{3 pt} \text{inr} (v) \hspace{3 pt} \vert
 \\& \text{ case } v \,   \{\text{inl}_{\typeB} (x) \Rightarrow w ; \, \text{inr}_{\typeA} (y) \Rightarrow u\}
\end{split}
\end{equation*}

Here $x$ ranges over an infinite set of variables. $f \in \Sigma$, where  $\Sigma$ corresponds to a class of sorted operation symbols, and $f(v_1, \ldots, v_n)$ corresponds to the aplication of the function $f$ to the arguments $v_1, \ldots, v_n$. The symbol $*$ is the unit element of the type $\mathbb{I}$. The term $(\lambda x: \mathbb{A}. v )$ is the lambda abstraction term, which represents a function that takes an argument of type $\mathbb{A}$ and returns the value of $v$. The term $(v w)$ is the application term, which applies the function $v$ to the argument $w$.  The term $v \otimes w$ is the tensor product of $v$ and $w$. The term $\text{pm} \hspace{3 pt} v \hspace{3 pt} \text{to} \hspace{3 pt} x \otimes y. w$ is the pattern-matching construct, which is used to deconstruct a tensor product into components $x$ and $y$. The term $v \text{ to } *.w$ is used to discard a variable $v$ of the unit type. The term $\text{dis}(v)$ is the discard term, which is used to discard a term $v$. The terms $\text{inl}_{\typeB}(v)$ and $\text{inr}_{\typeA}(v)$ represent the left and right injections of $v$, respectively. Intuitively, the case statement executes $w$ when $v$ is a left injection, and $u$ when $v$ is a right injection, and a ``mixture'' of both otherwise.

%evaluates $v$ and stores the value of the right and left components in variables $x$ and $y$, respectively, and then 


%Then, based on (the left and right injections of) these values, 


%These serve a similar role to the traditional boolean values ``true'' and ``false'', as illustrated by the case statement, which evaluates $v$ and stores the value of the right and left components in variables $x$ and $y$, respectively. Then, we use the left and right injections of  $x$ and $y$, respectively, as if they were ``true'' and ``false'', respectively, in the sense that we evaluate 

 %to $w$ when $v$ is a left injection, and to $u$ when $v$ is a right injection. 

%? The term in1M is simply an elementof the left component of A + B.
%The term (caseM ofxA ⇒ N |yB ⇒ P) is a case distinction: evaluate M of type A + B. The answer is either an element o 
%the left component A or of the right component B. In the first case, assign the answer to the variable x and evaluate N. In the second case, assign the answer to the variable y and evaluate P. Since both N and P are of type C, we get a final result of type C. 

\todo[inline,size=\normalsize]{Ver o que por antes do ::= porque v1,..., vn tb são termos } 

\subsection{Free and Bound Variables}
An occurrence of a variable $x$ within a term of the form $\lambda x.v$ is referred to as \emph{bound}.  Similarly, the variables $x$ and $y$ in the term $\text{pm} \hspace{3 pt} v \hspace{3 pt} \text{to} \hspace{3 pt} x \otimes y. w$ are also bound. A variable occurrence that is not bound is said to be \emph{free}. For example, in the term $\lambda x.xy$, the variable $y$ is free, whereas the variable $x$ is bound.  

The set of free variables of a term $v$ is denoted by \gls{fv}, and is defined inductively as follows:

\begin{comment}
\begin{equation*}
\begin{split}
FV(x) &= \{x\}, &  FV(*) &= \emptyset,  \\
FV(f(v_1, \ldots, v_n)), &= FV(v_1) \cup \ldots \cup FV(v_n)& FV(\lambda x: \mathbb{A}. v) &= FV(v) \backslash \{x\}, \\
FV(v w) &= FV(v) \cup FV(w), & FV(v \otimes w) &= FV(v) \cup FV(w), \\
FV(\text{pm} \hspace{3 pt} v \hspace{3 pt} \text{to} \hspace{3 pt} x \otimes y. w), &= FV(v) \cup (FV(w)  \backslash \{x,y\}) & FV(\text{dis}(v)) &= FV(v),\\
FV(v \text{ to } *.w) &= FV(v) \cup FV(w)  &  FV(\text{inl}_\typeB) &=  FV(v). \\
\end{split}
\end{equation*}
\end{comment}

\begin{equation*}
\begin{split}
&FV(x) = \{x\}, &&  FV(*) = \emptyset,  \\
&FV(f(v_1, \ldots, v_n)), = FV(v_1) \cup \ldots \cup FV(v_n)&& FV(\lambda x: \mathbb{A}. v) = FV(v) \backslash \{x\}, \\
&FV(v w) = FV(v) \cup FV(w), && FV(v \otimes w) = FV(v) \cup FV(w), \\
& FV(\text{pm} \hspace{3 pt} v \hspace{3 pt} \text{to} \hspace{3 pt} x \otimes y. w), = FV(v) \cup (FV(w)  \backslash \{x,y\}) && FV(\text{dis}(v)) = FV(v),\\
&FV(v \text{ to } *.w) = FV(v) \cup FV(w)  &&  FV(\text{inl}_\typeB (v)) =  FV(\text{inr}_\typeA (v)) = FV(v). \\
\end{split}
\end{equation*}
\vspace{-20pt}
\begin{equation*}
  \begin{split}
& \hspace{-30pt} FV(\text{case } v \,   \{\text{inl}_{\typeB} (x) \Rightarrow w ; \, \text{inr}_{\typeA} (y) \Rightarrow u\}) = FV(v) \cup  (FV(w) \backslash \{x\}) \cup (FV(u)\backslash \{y\})
\end{split}
\end{equation*}


\subsection{Term formation rules}

To prevent the formation of nonsensical terms within the context of lambda calculus, such as $(v \otimes w) (u)$, the \emph{typing rules} are imposed.

A \emph{typed} term is a pair consisting of a term and its corresponding type. The notation \gls{typed-term} denotes that the term $v$ has type $\mathbb{A}$. Typing rules are formulated using \emph{typing judgments}. A typing judgment is an expression of the form $x_{1}: \mathbb{A}_{1}, \ldots, x_{n}: \mathbb{A}_{n} \hspace{1pt} \triangleright \hspace{1pt} v: \mathbb{A}$ (where $n \geq 1$), which asserts that the term $v$ is a well-typed term of type $\mathbb{A}$ under the assumption that each variable variable $x_{i}$ has type $\mathbb{A}_{i}$, for $1 \leq i \leq n$. The list $x_{1}: \mathbb{A}_{1}, \ldots, x_{n}: \mathbb{A}_{n}$ of typed variables is called the \emph{typing context} of the judgment, and it might be empty.  Each variable $x_i$ (where $1 \leq i \leq n$) must occur at most once in $x_1, \ldots, x_n$. The typing contexts are denoted by Greek letters \gls{typingcontexts}, and from now on, when referring to an abstract judgment, the notation \gls{judgement} will be employed.
 The empty context is denoted by $-$. Note that in the affine lambda calculus, different contexts do not share variables. For example, if $\Gamma = x:\mathbb{A},y:\mathbb{B}$ none of these variables can appear in any other context. 


The concept of \emph{shuffling} is employed to construct a linear typing system that ensures the admissibility of the exchange rule and enables unambiguous reference to judgment's denotation $[\![ \Gamma \triangleright v: \mathbb{A} ]\!]$. An admissible rule is not explicitly included in the formal definition of type theory, but its validity can be proven by demonstrating that whenever the premises can be derived, it is possible to construct a derivation of its conclusion. Shuffling is defined as a permutation of typed variables in a sequence of contexts, $\Gamma_1, \ldots, \Gamma_n$, preserving the relative order of variables within each $\Gamma_i$ \cite{shulman2019practical}. For instance, if $\Gamma_1=x:\mathbb{A}, y:\mathbb{B}$ and $\Gamma_2=z:\mathbb{D}$, then $z:\mathbb{D}, x:\mathbb{A}, y:\mathbb{B}$ is a valid shuffle of $\Gamma_1, \Gamma_2$. On the other hand, $y:\mathbb{B}, x:\mathbb{A}, z:\mathbb{D}$ is not a shuffle because it alters the occurrence order of $x$ and $y$ in $\Gamma_1$. The set of shuffles in $\Gamma_1, \ldots, \Gamma_n$ is denoted as $\text{Sf} (\Gamma_1, \ldots, \Gamma_n)$. A valid typing derivation is constructed using the inductive rules shown in \autoref{fig:typing_rules_linear}.
%An admissible rule is not explicitly included in the formal definition of the type theory, but it can be proven valid using the fact that whenever one has derivations of its premises it is possible to construct a derivation of its conclusion.
%an admissible rule is one that is not asserted as part of the specification of the type theory, but for which we can prove after the fact that whenever we have derivations of its premises we can construct a derivation of its conclusion — usually by inductively traversing and modifying the given derivations of its premises. 
\begin{figure} [H]
  \small{
\begin{equation*}
\begin{split}
\begin{aligned}
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \Gamma_{i} \triangleright v_{i}: \mathbb{A}_{i} \quad f: \mathbb{A}_{1}, \ldots, \mathbb{A}_{n} \xrightarrow{} \mathbb{A} \in \Sigma \quad E \in \text{Sf}(\Gamma_{1}; \ldots; \Gamma_{n})\\
    \hline
   E \triangleright f( v_{1},\ldots,v_{n}): \mathbb{A}
\end{array}
$
\end{minipage}
\hspace{148pt}
\text{(ax)} 
 \hspace{30pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
      \\
    \hline
   x:\mathbb{A} \triangleright x:\mathbb{A}
\end{array}
$ \end{minipage}
\hspace{-68pt} \text{(hyp)} \\
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    \\
    \hline
   - \triangleright *: \mathbb{I}
\end{array}
$
\end{minipage}
\hspace{-87pt}
\text{($\mathbb{I}_{i}$)} 
 \hspace{90pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \Gamma \triangleright v: \mathbb{A} \otimes \mathbb{B} \quad  \Delta,x: \mathbb{A}, y: \mathbb{B}  \triangleright w: \mathbb{D}  \quad E \in \text{Sf}(\Gamma;\Delta)\\
    \hline
   E\triangleright \text{pm } v \text{ to } x \otimes y. w :\mathbb{D}
\end{array}
$ \end{minipage}
\hspace{117pt} (\otimes_{e}) \\
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \Gamma \triangleright v: \mathbb{A} \quad  \Delta \triangleright w: \mathbb{B}  \quad E \in \text{Sf}(\Gamma;\Delta) \\
    \hline
   E \triangleright v \otimes w: \mathbb{A} \otimes \mathbb{B} 
\end{array}
$
\end{minipage}
\hspace{41pt} (\otimes_{i}) 
 \hspace{35pt}
 \begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \Gamma \triangleright v: \mathbb{I} \quad  \Delta \triangleright w: \mathbb{A}  \quad E \in \text{Sf}(\Gamma;\Delta)  \\
    \hline
   E \triangleright v \text { to } *.w: \mathbb{A}  
\end{array}
$ \end{minipage}
\hspace{38pt} (\mathbb{I}_{e}) \\
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \Gamma,x:\mathbb{A} \triangleright v: \mathbb{B} \\
    \hline
   \Gamma \triangleright \lambda x:\mathbb{A} . v: \mathbb{A} \multimap \mathbb{B} 
\end{array}
$
\end{minipage}
\hspace{-27pt} (\multimap_{i}) 
 \hspace{64pt}
 \begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \Gamma \triangleright v: \mathbb{A} \multimap \mathbb{B} \quad  \Delta \triangleright w: \mathbb{A}  \quad E \in \text{Sf}(\Gamma;\Delta)  \\
    \hline
   E \triangleright v w: \mathbb{B}  
\end{array}
$ \end{minipage}
\hspace{67pt} (\multimap_{e}) \\
& 
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \Gamma \triangleright v: \mathbb{A}  \\
    \hline
   \Gamma \triangleright \text{dis}(v):  \mathbb{I} 
\end{array}
$
\end{minipage}
\hspace{-67pt} (\text{dis})
\hspace{55pt}
    %
    \begin{prooftree}
        \hypo{\Gamma \vljud v: \typeA}
        \infer1[(inl)]{\Gamma \vljud \inl_{\typeB}(v): \typeA \oplus \typeB}
    \end{prooftree}
    %
    \hspace{55pt}
    %
    \begin{prooftree}
        \hypo{\Gamma \vljud v: \typeB}
        \infer1[(inr)]{\Gamma \vljud \inr_{\typeA}(v): \typeA \oplus \typeB}
    \end{prooftree} 
    %
    \\[10pt]
    &\hspace{40pt}
    %
    \begin{prooftree}
        \hypo{\Gamma \vljud v: \typeA \oplus \typeB}
        \hypo{\Delta, x: \typeA \vljud w: \typeD}
        \hypo{\Delta, y: \typeB \vljud u: \typeD}
        \hypo{E \in \Shuff(\Gamma; \Delta)}
        \infer4[(case)]{E \vljud \text{case } v\,
        \{\inl_{\typeB}(x) 
            \Rightarrow w ; \,
          \inr_{\typeA}(y) \Rightarrow u
        \}: \typeD}
    \end{prooftree}
\end{aligned}
\end{split}
\end{equation*}
  }
\caption{Term formation rules of affine lambda calculus.}
\label{fig:typing_rules_linear}
\end{figure}
The rule (ax) states that if there is a function $f \in \Sigma$ that has type $\mathbb{A}_1, \ldots, \mathbb{A}_n \rightarrow \mathbb{A}$ and a set of variables $v_1,\ldots, v_n$ whose types match the type of the arguments of $f$, then if that function is applied to $v_1,…,v_n$ the respective result is of type $\mathbb{A}$.
The rule (hyp) is a tautology: under the assumption that $x$ has type $\mathbb{A}$, $x$ has type $\mathbb{A}$. 
The rule ($\mathbb{I}_{i}$) asserts that the unit element $*$ always has type $\mathbb{I}$. 
The rule ($\multimap_i$) expresses that if $v$ is a term of type $\mathbb{B}$ with a variable $x$ of type $\mathbb{A}$, then $\lambda x:\mathbb{A} . v$ is a function of type $\mathbb{A} \multimap \mathbb{B} $. 
The rule $(\multimap_e)$ states that a function of type $\mathbb{A} \multimap \mathbb{B}$  can be applied to an argument of type $\mathbb{A}$  to produce a result of type $\mathbb{B}$. 
The rule $(\mathbb{\otimes}_i)$  asserts that if there is a term $v$ of type $\mathbb{A}$ and a term $w$ of type $\mathbb{B}$,  then the tensor of these terms is of type $\mathbb{A} \otimes \mathbb{B}$.
The rule $(\mathbb{\otimes}_e)$ expresses if there is a term $w$ of type $\mathbb{D}$ with variables $x$ and $y$ of types $\mathbb{A}$ and $\mathbb{B}$, respectively, and a term $v$ of type $\mathbb{A} \otimes \mathbb{B}$, then $v$ can be deconstructed into $x \otimes y$. 
The rule $(\mathbb{I}_e)$ states that if there is a term $w$ of type $\mathbb{A}$ and a term $v$ of type $\mathbb{I}$, then $v$ can be discarded, and only the term $w$ remains. 
The rule $(\text{dis})$ asserts that a term $v$ of type $\mathbb{A}$ can be discarded, resulting in a term of type $\mathbb{I}$. The rules $(\text{inl}_\typeB)$ (resp. $(\text{inr}_\typeA)$) states that if we inject a term $v$ of type $\typeA$ (resp. $\typeB$) into $\typeA \oplus \typeB$ we obtain a term of type $\typeA \oplus \typeB$. 
Finally, the rule $\text{(case)}$ states that if there are two programs of type $\typeD$ to be executed depending on the value of a variable $v$ of type $\typeA \oplus \typeB$ (whose right and left components are assigned to variables $x$ and $y$, respectively), then the resulting program also has type $\typeD$.


For a better understanding of the rules, a few straightforward programming examples are provided.  

\begin{example}

For instance, the program that swaps the elements of a tensor product can be written as follows:
\begin{equation*}
\begin{split}
& x : \mathbb{A},  y : \mathbb{B} \triangleright \text{pm} \hspace{3 pt} x \otimes y\hspace{3 pt} \text{to} \hspace{3 pt} a \otimes b. \hspace{1pt} b \otimes a : \mathbb{B} \otimes \mathbb{A}
\end{split}
\end{equation*}
Now, to prove that this program is well-typed one can write the following typing derivation:
\begin{equation*}
\begin{split}
1 \hspace{10 pt} & x : \mathbb{A} \triangleright x : \mathbb{A}  \hspace{10 pt} & {(\text{hyp})} \\
2 \hspace{10 pt} &  y : \mathbb{B} \triangleright   y : \mathbb{B} \hspace{10 pt} & {(\text{hyp})} \\
3 \hspace{10 pt} & x : \mathbb{A},  y : \mathbb{B} \triangleright x \otimes y : \mathbb{A} \otimes \mathbb{B} \hspace{10pt} & \text{($1,2,\otimes_i$)} \\
4 \hspace{10 pt} &  b : \mathbb{B} \triangleright   b : \mathbb{B} \hspace{10 pt}&{(\text{hyp})} \\
5 \hspace{10 pt} &   a : \mathbb{A} \triangleright  a : \mathbb{A} \hspace{10 pt}&{(\text{hyp})} \\
6 \hspace{10 pt} &   b : \mathbb{B},a : \mathbb{A} \triangleright b \otimes a : \mathbb{B} \otimes \mathbb{A} \hspace{10pt} &\text{($4,5,\otimes_i$)} \\
7\hspace{10 pt}& x : \mathbb{A},  y : \mathbb{B} \triangleright \text{pm} \hspace{3 pt} x \otimes y\hspace{3 pt} \text{to} \hspace{3 pt} a \otimes b. \hspace{1pt} b \otimes a : \mathbb{B} \otimes \mathbb{A}& \hspace{10pt} \text{($3,6,\otimes_e$)}
\end{split}
\end{equation*}
Observe that in the notation of the third column, the numbers correspond to the premises utilized in the application of the rule.
\end{example}

\begin{example}
Another example is the function that recieves a tensor product and returns first element, discarding the second:
\begin{equation*}
\begin{split}
& - \triangleright \lambda x: \mathbb{A \otimes A}. \text{pm} \hspace{3 pt} x \hspace{3 pt} \text{to} \hspace{3 pt} a \otimes b. \hspace{1 pt} \text{dis}(b) \hspace{3 pt} \text{ to } *.a: \mathbb{A}
\end{split}
\end{equation*}
To prove that this program is well-typed one can write the following typing derivation:
\begin{equation*}
\begin{split}
1  \hspace{10 pt} & b : \mathbb{A} \triangleright b : \mathbb{A}  \hspace{10 pt} & {(\text{hyp})} \\
2 \hspace{10 pt} & b : \mathbb{A} \triangleright \text{dis}(b): \mathbb{I} \hspace{10 pt} & {(1,\text{dis})} \\
3 \hspace{10 pt} & a : \mathbb{A} \triangleright a : \mathbb{A}  \hspace{10 pt} & {(\text{hyp})} \\
4 \hspace{10 pt} &  a : \mathbb{A}, b : \mathbb{A}  \triangleright \text{dis}(b) \hspace{3 pt} \text{ to } *.a  & {(2,3,\mathbb{I}_{e})} \\
5 \hspace{10 pt} & x : \mathbb{A \otimes A} \triangleright x : \mathbb{A \otimes A}  \hspace{10 pt} & {(\text{hyp})} \\
6 \hspace{10 pt} & x : \mathbb{A \otimes A} \triangleright \text{pm} \hspace{3 pt} x \hspace{3 pt} \text{to} \hspace{3 pt} a \otimes b. \hspace{1 pt} \text{dis}(b) \hspace{3 pt} \text{ to } *.a : \mathbb{A} \hspace{10pt} & \text{($4,5,\otimes_{e}$)} \\
7 \hspace{10 pt} & - \triangleright \lambda x: \mathbb{A \otimes A}. \text{pm} \hspace{3 pt} x \hspace{3 pt} \text{to} \hspace{3 pt} a \otimes b. \hspace{1 pt} \text{dis}(b) \hspace{3 pt} \text{ to } *.a: \mathbb{A} \hspace{10pt} & \text{($6,\multimap_i$)}
\end{split}
\end{equation*}
\end{example}

\begin{example}
  Let us designate the program presented in the last by $\textbf{Dis2nd}$.  Consider an analogous program that that recieves a tensor product and returns
  second element, discarding the first: 
  \begin{equation*}
\begin{split}
& \textbf{Dis1st} \triangleq - \triangleright \lambda x: \mathbb{A \otimes A}. \text{pm} \hspace{3 pt} x \hspace{3 pt} \text{to} \hspace{3 pt} a \otimes b. \hspace{1 pt} \text{dis}(a) \hspace{3 pt} \text{ to } *.b: \mathbb{A \otimes A} \multimap \mathbb{A}
\end{split}
\end{equation*}
Following a similar line of reasoning as in the previous example, it is straightforward to verify that this $\lambda$-term is also well-typed.  
Now, let us examine a program that receives both a coproduct/sum and a tensor product, and applies either $\textbf{Dis1st}$ or $\textbf{Dis2nd}$ to the tensor product (or a mixture of both), depending on the value of the coproduct:
\begin{equation*}
\begin{split}
&  - \triangleright  \lambda x: \mathbb{\typeB \oplus \typeB}. \, \lambda y: \mathbb{A \otimes A}. \, 
\text{case } x \,  
  \left\{
    \begin{aligned} 
    &\inl_{\typeI}(w) \Rightarrow \text{dis}(w) \text{ to} * . \, \textbf{Dis1st} \, y; \\
    &\inr_{\typeI}(z) \Rightarrow  \text{dis}(z) \text{ to} *. \textbf{Dis2nd} \, y   \\ 
  \end{aligned}  
  \right\}  & \\
\end{split}
\end{equation*}


To prove that this program is well-typed one can write the following typing derivation (the derivations regarding \textbf{Dis1st} and \textbf{Dis2nd} will be omitted):
\begin{equation*}
\begin{split}
1  \hspace{10 pt} & y : \mathbb{A} \otimes \mathbb{A}  \triangleright y : \mathbb{A}  \otimes \mathbb{A} \hspace{10 pt} & {(\text{hyp})} \\
2  \hspace{10 pt} & y : \mathbb{A}  \otimes \mathbb{A} \triangleright \textbf{Dis1st}   \, y : \mathbb{A} & {(\multimap_e)} \\
3  \hspace{10 pt} & y : \mathbb{A}  \otimes \mathbb{A}  \triangleright \textbf{Dis2nd}  \, y : \mathbb{A}  & {(\multimap_e)} \\
4  \hspace{10 pt} & w : \mathbb{B} \triangleright w : \mathbb{B}  \hspace{10 pt} & {(\text{hyp})} \\
5 \hspace{10 pt} & w : \mathbb{B} \triangleright \text{dis}(w): \mathbb{I} \hspace{10 pt} & {(4,\text{dis})} \\
6  \hspace{10 pt} & z : \mathbb{B} \triangleright z : \mathbb{B}  \hspace{10 pt} & {(\text{hyp})} \\
7 \hspace{10 pt} & z : \mathbb{B} \triangleright \text{dis}(z): \mathbb{I} \hspace{10 pt} & {(6,\text{dis})} \\
8 \hspace{10 pt} &  y : \mathbb{A}  \otimes \mathbb{A},  w : \mathbb{B},   \triangleright \text{dis}(w) \text{ to} * . \, \textbf{Dis1st} \, y : \typeA  & {(2,5,\mathbb{I}_{e})} \\
9 \hspace{10 pt} &   y : \mathbb{A}  \otimes \mathbb{A}, z : \mathbb{B}   \triangleright \text{dis}(z) \text{ to} * . \, \textbf{Dis2nd} \, y : \typeA & {(3,7,\mathbb{I}_{e})} \\
10 \hspace{10 pt} & x : \mathbb{B \oplus B} \triangleright x : \mathbb{B \oplus B}  \hspace{10 pt} & {(\text{hyp})} \\
11 \hspace{10 pt} &    x: \mathbb{\typeB \oplus \typeB},  y: \mathbb{A \otimes A} \triangleright \, 
\text{case } x \,  
  \left\{
    \begin{aligned} 
    &\inl_{\typeI}(w) \Rightarrow \text{dis}(w) \text{ to} * . \, \textbf{Dis1st} \, y; \\
    &\inr_{\typeI}(z) \Rightarrow  \text{dis}(z) \text{ to} *. \textbf{Dis2nd} \, y   \\ 
  \end{aligned}  
  \right\}  & \text{($8,9,10,\text{case}$)} \\
12 \hspace{10 pt} & x: \mathbb{\typeB \oplus \typeB} \triangleright \lambda y: \mathbb{A \otimes A}. \, 
\text{case } x \,  
  \left\{ \ldots 
  \right\}   & \text{($11,\multimap_i$)} \\
13 \hspace{10 pt} & - \triangleright  \lambda x: \mathbb{\typeB \oplus \typeB}. \, \lambda y: \mathbb{A \otimes A}. \, 
\text{case } x \,  
  \left\{ \ldots  
  \right\}   & \text{($12,\multimap_i$)}
\end{split}
\end{equation*}
\end{example}


\subsection{$\alpha$-equivalence}
 
A natural notion of equivalence definition stems from the fact that terms that differ only in the names of their bound variables represent the same program. For instance, the functions $\lambda x:\mathbb{A}.x $ and $\lambda y:\mathbb{A}.y$ have the same input-output behavior, despite being represented by different lambda terms. This equivalence is called $\alpha$\emph{-equivalence}.

\begin{definition}
  The $\alpha$-equivalence is an equivalence relation on lambda terms that is used to rename bound variables. To rename a variable $x$ as $y$ in a term $v$, denoted by $v\{y/x\}$, is to replace all occurrences of $x$ in $v$ by $y$. Two terms $v$ and $w$ are $\alpha$-equivalent, written $=_{\alpha}$, if one can be derived from the other by a series of
  changes of bound variables
\end{definition}

\begin{convention}
  Terms are considered up to $\alpha$-equivalence from now on.
\end{convention}

\subsection{Substitution}
The substitution of a variable $x$ for a term $w$ in a term $v$ is denoted by \gls{substitution}. It is only  permitted  to replace free variables. For instance, $\lambda x. \hspace{1pt} x  \hspace{2pt} [v/x]$ is $\lambda x. \hspace{1pt} x  \hspace{2pt}$ and not  $\lambda x. \hspace{1pt} v  \hspace{2pt}$. Moreover, it is necessary to avoid the unintended binding of free variables. For example, $$(\text{pm} \hspace{3 pt} x \otimes y\hspace{3 pt} \text{to} \hspace{3 pt} a \otimes b. \hspace{1pt} b \otimes a \otimes z) \hspace{2 pt}  [z/\text{pm} \hspace{3 pt} c \otimes d\hspace{3 pt} \text{to} \hspace{3 pt} e \otimes f. \hspace{1pt} f \otimes e \otimes a]$$ is not the same as $$\text{pm} \hspace{3 pt} x \otimes y\hspace{3 pt} \text{to} \hspace{3 pt} a \otimes b. \hspace{1pt} b \otimes a \otimes (\text{pm} \hspace{3 pt} c \otimes d\hspace{3 pt} \text{to} \hspace{3 pt} e \otimes f. \hspace{1pt} f \otimes e \otimes a ). $$ Instead, the bounded variable $a$ must be renamed before the substitution, and in this case, the proper substitution is $$(\text{pm} \hspace{3 pt} x \otimes y\hspace{3 pt} \text{to} \hspace{3 pt} t \otimes b. \hspace{1pt} b \otimes t \otimes z) \hspace{2 pt}  [z/\text{pm} \hspace{3 pt} c \otimes d\hspace{3 pt} \text{to} \hspace{3 pt} e \otimes f. \hspace{1pt} f \otimes e \otimes a]$$ which is equal to $$\text{pm} \hspace{3 pt} x \otimes y\hspace{3 pt} \text{to} \hspace{3 pt} t \otimes b. \hspace{1pt} b \otimes t \otimes (\text{pm} \hspace{3 pt} c \otimes d\hspace{3 pt} \text{to} \hspace{3 pt} e \otimes f. \hspace{1pt} f \otimes e \otimes a) .$$

Note that a simple way of ensuring these restrictions are satisfied is not allowing the variable $x$ to occur in the context of $w$ in $v[w/x]$. Since $x$ is in the context of $v$, this is always the case in the affine lambda calculus.

\begin{definition}
Given the typings judgments $\Gamma, x: \mathbb{A} \triangleright v:\mathbb{B}$ and $\Delta \triangleright w: \mathbb{A}$, the substitution $\Gamma, \Delta \, \triangleright \,  v[w/x]:\mathbb{B}$ is defined below. The types of judgments are omitted as no ambiguity arises.
\begin{align*}
  \hspace{-23pt}\Gamma,  \Delta \triangleright y[w/x] &=  \Gamma, \Delta \triangleright y, \\
  \hspace{-23pt}  \Delta \triangleright *[w/x] &=   \Delta \triangleright * ,\\
  \hspace{-23pt} \Gamma,  \Delta \triangleright (\lambda y: \mathbb{B}. v)[w/x] &= \Gamma,  \Delta \triangleright  \lambda y: \mathbb{B}. v[w/x],  \\
  \hspace{-23pt}(\text{dis}(v))[w/x] &= \text{dis}(v[w/x]),\\
  \hspace{-23pt}\text{In the next three cases, } \Gamma,x: \mathbb{A} \in & \text{Sf}(\Gamma_1,\ldots,\Gamma_i,\ldots,\Gamma_n) \text{ and } \Gamma_{i}  \triangleright v_{i}\\
  \hspace{-23pt} \Gamma, \Delta  \triangleright(f(v_1, \ldots, v_n))[w/x] &= \Gamma, \Delta  \triangleright f(v_1[w/x], \ldots, v_n),& (\text{ if } x: \mathbb{A} \in \Gamma_1)  \\
  \hspace{-23pt} \Gamma, \Delta  \triangleright(f(v_1, \ldots,v_i,\ldots, v_n))[w/x] &= \Gamma, \Delta  \triangleright f(v_1, \ldots,v_i[w/x],\ldots, v_n),& (\text{ if } x: \mathbb{A} \in T_i)  \\
  \hspace{-23pt}\Gamma, \Delta  \triangleright(f(v_1, \ldots, v_n))[w/x] &= \Gamma, \Delta  \triangleright f(v_1, \ldots, v_n[w/x]),& (\text{ if } x: \mathbb{A} \in \Gamma_n)  \\
  \hspace{-23pt}\text{In the next two cases, }\Gamma,x: \mathbb{A} & \in \text{Sf}(\Gamma_1,\Gamma_2), \Gamma_1 \triangleright v \text{, and } \Gamma_2 \triangleright u  \\
  \hspace{-23pt}\Gamma, \Delta  \triangleright (v \hspace{1pt}  u)[w/x] &= \Gamma, \Delta  \triangleright (v[w/x] \hspace{1pt} u), & (\text{ if } x: \mathbb{A} \in \Gamma_1)\\
  \hspace{-23pt}\Gamma, \Delta  \triangleright (v \hspace{1pt}  u)[w/x] &= \Gamma, \Delta  \triangleright (v \hspace{1pt} u[w/x]), & (\text{ if } x: \mathbb{A} \in \Gamma_2)\\
  \hspace{-23pt}\text{In the next two cases, }\Gamma,x: \mathbb{A} & \in \text{Sf}(\Gamma_1,\Gamma_2), \Gamma_1 \triangleright v \text{, and } \Gamma_2 \triangleright u  \\
  \hspace{-23pt}\Gamma, \Delta  \triangleright (v \otimes u)[w/x] &= \Gamma, \Delta  \triangleright v[w/x] \otimes u, & (\text{ if } x: \mathbb{A} \in \Gamma_1)\\ 
  \hspace{-23pt}\Gamma, \Delta  \triangleright (v \otimes u)[w/x] &= \Gamma, \Delta  \triangleright v \otimes u[w/x], & (\text{ if } x: \mathbb{A} \in \Gamma_2)\\
  \hspace{-23pt}\text{In the next two cases, }\Gamma,x: \mathbb{A}  \in \text{Sf}(&\Gamma_1,\Gamma_2), \Gamma_1 \triangleright v \text{, and } \Gamma_2, y: \mathbb{D}, z:\mathbb{E} \triangleright u  \\
  \hspace{-23pt} \Gamma, \Delta  \triangleright (\text{pm} \hspace{3 pt} v \hspace{3 pt} \text{to} \hspace{3 pt} y \otimes z. u)[w/x] &= \Gamma, \Delta  \triangleright \text{pm} \hspace{3 pt} v[w/x] \hspace{3 pt} \text{to} \hspace{3 pt} y \otimes z. u,  &  (\text{ if } x: \mathbb{A} \in \Gamma_1) \\
  \hspace{-23pt} \Gamma, \Delta  \triangleright (\text{pm} \hspace{3 pt} v \hspace{3 pt} \text{to} \hspace{3 pt} y \otimes z. u)[w/x] &= \Gamma, \Delta  \triangleright \text{pm} \hspace{3 pt} v \hspace{3 pt} \text{to} \hspace{3 pt} y \otimes z. u[w/x],  &  (\text{ if } x: \mathbb{A} \in \Gamma_2) \\
  \hspace{-23pt}\text{In the next two cases, }\Gamma,x: \mathbb{A} &  \in \text{Sf}(\Gamma_1,\Gamma_2), \Gamma_1 \triangleright v \text{, and } \Gamma_2 \triangleright u  \\
  \hspace{-23pt}\Gamma, \Delta  \triangleright(v \hspace{3 pt} \text{to} \hspace{3 pt} *.u)[w/x] &= \Gamma, \Delta  \triangleright v[w/x] \hspace{3 pt} \text{to} \hspace{3 pt} *.u&  (\text{ if } x: \mathbb{A} \in \Gamma_1),\\
  \hspace{-23pt}\Gamma, \Delta  \triangleright(v \hspace{3 pt} \text{to} \hspace{3 pt} *.u)[w/x] &= \Gamma, \Delta  \triangleright v \hspace{3 pt} \text{to} \hspace{3 pt} *.u[w/x] &  (\text{ if } x: \mathbb{A} \in \Gamma_2).\\
\end{align*}
\end{definition}

\todo[inline,size=\normalsize]{Estou aqui} 

The sequential substitutions $M[M_i/x_i] \ldots [M_n/x_n]$ are writen as $M[M_i/x_i, \ldots ,M_n/x_n]$.


\subsection{Properties}


The calculus defined in \autoref{fig:typing_rules_linear} possesses several desirable properties, which are listed below. Before proceeding, it is necessary to introduce some auxiliary notation. Given a context $\Gamma$, $te(\Gamma)$ denotes context $\Gamma$ with all types erased. The expression $\Gamma \simeq_{\pi} \Gamma'$ denotes that the contexts $\Gamma$ is a permutation of context $\Gamma'$.This notation also applies to non-repetitive lists of untyped variables $te(\Gamma)$. Additionally, a judgment $\Gamma \triangleright v: \mathbb{A}$ will often be abbreviated into $\Gamma \triangleright v $ or even just $v$ when no ambiguities arise.

\begin{theorem} \label{thm:exch_sub_no_cond} (\cite{dahlqvist2023complete})
   The calculus defined by the rules of \autoref{fig:typing_rules_linear} enjoys the following properties:
   \begin{enumerate}
   \item for all judgements $\Gamma \triangleright v$ and $\Gamma' \triangleright v$, te($\Gamma$) $\simeq_{\pi}$  te($\Gamma'$); 
   \item additionally if $\Gamma \triangleright v: \mathbb{A}, \Gamma'\triangleright v: \mathbb{A}'$, and $\Gamma \simeq_{\pi} \Gamma' $, then $\mathbb{A}$ must be equal to $\mathbb{A}'$;
   \item all judgements $\Gamma \triangleright v:\mathbb{A}$ have a unique derivation.
   \item (exchange) For every judgement $\Gamma,x:\mathbb{A}, y:\mathbb{B}, \Delta \triangleright v: \mathbb{D}$ it is possible to derive $\Gamma, y:\mathbb{B}, x:\mathbb{A}, \Delta \triangleright v: \mathbb{D}$. 
   \item (substitution) For all judgements  $\Gamma,x:\mathbb{A} \triangleright v: \mathbb{B}$ and $\Delta \triangleright w: \mathbb{A}$ it is possible to derive $ \Gamma, \Delta \triangleright v[w/x]: \mathbb{B}$.
 \end{enumerate}
\end{theorem}


 
 


\subsection{Equations-in-context}
The simply typed lambda calculus is a formal language that captures operations like the application of a function to an argument and the elimination of variables. To express these operations there is a set of rules known as reduction rules. These rules fall into two primary categories: the $\beta$\emph{-reductions}, which perform operations and enforce the implicit meaning of the term, and $\eta$\emph{-reductions}, which simplify terms by exploiting the extensionality of functions. 
There is also a secondary class of reductions known as \emph{commuting conversions}, which serve to disambiguate terms that, while equivalent, have different representations.
As a result, affine $\lambda$-calculus comes equipped with the so-called equations-in-context \gls{equation-in-context}, depicted in \autoref{fig:equations-linear-lambda}.
\begin{figure}[H]
  \centering
  \begin{tabular}{ |ccccc| }
    \hline
$(\beta)$ &  $\Gamma, \Delta \triangleright (\lambda x : \mathbb{A}.$ $v) \hspace{1pt}  w = v[w/x]: \mathbb{B} $ & &$(\eta)$ &  $\Gamma  \triangleright \lambda x : \mathbb{A} .(v \hspace{1pt} x) = v: \mathbb{A} \multimap \mathbb{B} $ \\
$(\beta_{\mathbb{I}_{e}})$ &   $ \Gamma \triangleright * \text { to } *.$ $v = v:\mathbb{A}$ && $(\eta_{\mathbb{I}_{e}})$ & $ \Delta, \Gamma \triangleright v$ to $*$ . $w[* / z] = w[v / z]: \mathbb{A}$  \\
$(\beta_{\otimes_{e}})$   &\multicolumn{4}{c|}{$ \hspace{-10pt}  E, \Gamma, \Delta \hspace{1pt}\triangleright \text{pm } v \otimes w$ to $x \otimes y.$ $u = u[v/x,w/y]:\mathbb{A}$ }\\
$(\eta_{\otimes_{e}})$   &\multicolumn{4}{c|}{$\Delta , \Gamma\hspace{1pt}\triangleright \text{pm } v$ to $x \otimes y.$ $u[x \otimes y/z] = u[v/z] :\mathbb{A} $}\\
 $(c_{\mathbb{I}_{e}})$  &\multicolumn{4}{c|}{ $\Delta,\Gamma, E \triangleright u[v \text{ to } \ast . w/z] = v \text{ to } \ast . u[w/z]:\mathbb{A}$ }\\
$(c_{\otimes_{e}})$ & \multicolumn{4}{c|}{ $\Delta,\Gamma, E  \triangleright u[$pm $v$ to $x \otimes y.$ $w/z] =$ pm $v$ to $x \otimes y.$ $u[w/z]: \mathbb{A} $ }\\
$(\eta_{\text{dis}})$ & \multicolumn{4}{c|}{ $x_1:\mathbb{A}_1, \ldots,x_n:\mathbb{A}_n\triangleright v = \text{dis}(x_1) \text{ to } \ast.$ $\ldots$ $\text{dis}(x_{n-1}) \text{ to } \ast \text{ dis}(x_{n}): \mathbb{ I}$ }\\
\hline
  \end{tabular}
\caption{Equations-in-context for affine lambda calculus}
\label{fig:equations-linear-lambda}
\end{figure}

It is evident that, for example, equation $(\beta)$ enforces the meaning of  $(\lambda x : \mathbb{A}.$ $v) \hspace{1pt} w $, which is interpreted as ``$v$ with $w$ in place of $x$". The equation $(\eta)$, on the other hand, is a simplification rule that states that a function that applies another function $v$ to an argument $x$ can be simplified to the function $v$ itself. The remaining $\beta$ e $\eta$ equations follow similar reasoning. The commuting conversion $(c_{\mathbb{I}_{e}})$ expresses that substituting a variable $z$ by a term that maps a term $v$ to the unit element $*$ in a term $w$ is equivalent to mapping a term $v$ to the unit element $*$ and then replacing $z$ by $w$. The other commuting conversion has a similar interpretation.
%\begin{figure}[H]
  %\centering
  %\begin{tabular}{ |c|c| }
      %\hline 
      %Monoidal structure & Higher-order structure \\
      %\hline
      %pm $v \otimes w$ to $x \otimes y.$ $u = u[v/x,w/y]$& \\
      %pm $v$ to $x \otimes y.$ $u[x \otimes y/z] = u[v/z]$ & $(\lambda x : A.$ $v) w = v[w/x]$\\
      %$* \text { to } *.$ $v = v$ & $\lambda x : A.(v x) = v$ \\
      %$v$ to $*$ . $w[* / z] = w[v / z]$ & \\
      %\hline
      %\multicolumn{2}{|c|}{Commuting conversions} \\
      %\hline
      %\multicolumn{2}{|c|}{$u[v \text{ to } \ast . w/z] = v \text{ to } \ast . u[w/z]$}  \\
      %\multicolumn{2}{|c|}{$u[$pm $v$ to $x \otimes y.$ $w/z] =$ pm $v$ to $x \otimes y.$ $u[w/z]$} \\
      %\hline
      %\multicolumn{2}{|c|}{Discard} \\
      %\hline
      %\multicolumn{2}{|c|}{$v: \mathbb{I} = \text{dis}(x_1) \text{ to } \ast.$ $\ldots$ $\text{dis}(x_{n-1}) \text{ to } \ast \text{ dis}(x_{n})$} \\
      %\hline
  %\end{tabular}
  %\caption{Equations-in-context for affine lambda calculus}
  %\label{fig:equations-linear-lambda}
%\end{figure}



\begin{example} \label{ex:eq_contex_gen}
  For instance, consider the $\lambda$-term 
  $$ - \triangleright \big(\lambda z : \typeI \otimes \typeA. \, \text{pm } z \text{ to} * \otimes y. \, y\big) \, (v \otimes w): \typeA$$
Applying the $\beta$ reduction, we have:
\begin{align*}
 - \triangleright \big(\lambda z : \typeI \otimes \typeA. \, \text{pm } z \text{ to } * \otimes y. \, y\big) \, (v \otimes w) 
&= \text{pm }  v \otimes w \text{ to} * \otimes y. \, y : \typeA. 
\end{align*}
Next, applying the $\beta_{\otimes_e}$-reduction, it follows:
\begin{align*}
\text{pm }  v \otimes w \text{ to} * \otimes y. \, y : \typeA = w : \typeA. 
\end{align*}
\end{example}

\todo[inline,size=\normalsize]{Não sei se este é o lugar mais indicado para estas definições} 

\subsubsection{Equivalence}

\begin{definition}
  Let \( S \) be a set. A \emph{relation} on \( S \) is a subset \( R \subseteq S \times S \). An ordered pair \( (s_1, s_2) \in R \) means that \( s_1 \) is related to \( s_2 \).
\end{definition}

\begin{definition}
  A relation on a set is an \emph{equivalence relation} if it is reflexive, symmetric, and transitive. We denote such a relation by \( \sim \subseteq S \times S \), and write \( r \sim s \) to mean that \( (r, s) \in \sim \).
\end{definition}

\begin{definition}
  Given an equivalence relation on a set \( S \), we can describe disjoint subsets of \( S \) called \emph{equivalence classes}. If \( s \in S \), then the \emph{equivalence class} of \( s \) is the set of all elements related to it:
\[
[s] = \{ r \in S \mid r \sim s \}.
\]
That is, \( [s] \) is the set of all elements that are considered “the same” as \( s \) under the relation \( \sim \). For a given set \( S \) and an equivalence relation \( \sim \) on \( S \), we define the \emph{quotient set}, denoted \( S / \sim \), whose elements are all the equivalence classes of elements in \( S \). There is an obvious \emph{quotient function} from \( S \) to \( S / \sim \) that maps each element \( s \in S \) to its equivalence class \( [s] \).
\end{definition}

For instance, consider a set of cars \( S \). We can define an equivalence relation on \( S \) by grouping cars according to their colour. This results in subsets such as the set of blue cars, the set of red cars, the set of green cars, and so on — these subsets are the \emph{equivalence classes}. Moreover, the collection of all such equivalence classes forms a new set, called the \emph{quotient set}.


\todo[inline,size=\normalsize]{Def congruence} 

\begin{definition}
  In this seting a \emph{congruence relation} or \emph{congruence} is an equivalence relation that respects the term formation rules, exchange and substitution.
\end{definition}


\begin{definition} \label{def:linear_lambda_theory}
  Consider a pair $(G, \Sigma)$, where $G$ is a class of ground types and $\Sigma$ is a class of sorted operation symbols. A \emph{linear $\lambda$-theory} is a triple $((G, \Sigma), Ax)$, where $Ax$ is a class of equations-in-context over linear $\lambda$-terms constructed from $(G, \Sigma)$. The elements of $Ax$ are called the \emph{axioms} of the theory.
\end{definition}





 Let $Th(Ax)$ denote the smallest congruence containing $Ax$, the equations presented in \autoref{fig:equations-linear-lambda}, and closed under exchange and substitution (\autoref{thm:exch_sub_no_cond}). The elements of $Th(Ax)$ are called the \emph{theorems} of the theory.

 For instance recall \autoref{ex:eq_contex_gen}: 
 $$- \triangleright \big(\lambda z : \typeI \otimes \typeA. \, \text{pm } z \text{ to} * \otimes y. \, y\big) \, (v \otimes w): \typeA =  w : \typeA $$
 is a theorem.

\subsection{Metric equational system}


\emph{Metric equations} \cite{mardare2016quantitative}, \cite{mardare2017axiomatizability} are a strong candidate for reasoning about approximate program equivalence. These equations take the form of \gls{metric-equation}, where  $\epsilon$ is a non-negative rational representing the ``maximum distance" between the two terms $t$ and $s$. The metric equational system for linear lambda calculus is depicted in \autoref{fig:metric deductive system}.

\begin{figure} [H]
\begin{equation*}
\begin{split}
\begin{aligned}
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \\
    \hline
   v=_{0}v
\end{array}
$
\end{minipage}
\hspace{-90pt}
\text{(refl)} 
 \hspace{55pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    v=_{q}w \quad w=_{r}u  \\
    \hline
   v=_{q + r} u
\end{array}
$ \end{minipage}
\hspace{-40pt} \text{(trans)} 
\hspace{55pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    v=_{q}w \quad r\geq q  \\
    \hline
   v=_{r} w
\end{array}
$ \end{minipage}
\hspace{-50pt} \text{(weak)} \\
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    \forall r > q . \hspace{4pt} v=_{r} w \\
    \hline
   v=_{q}w
\end{array}
$
\end{minipage}
\hspace{-45pt}
\text{(arch)} 
 \hspace{50pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    \forall i \leq n. \hspace{4pt} v=_{q_i} w\\
    \hline
   v=_{\wedge q_i} w
\end{array}
$ \end{minipage}
\hspace{-40pt} \text{(join)} 
\hspace{58pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    v=_{q} w \\
    \hline
   w =_{q } v
\end{array}
$ \end{minipage}
\hspace{-88pt}\text{(sym)}   \\
&
\begin{minipage}[t]{0.3\textwidth}
  $\begin{array}{c}
      v=_{q} w \quad v'=_{r} w' \\
      \hline
     v \otimes v' =_{q + r} w \otimes w'
  \end{array}
  $ \end{minipage}
  \hspace{-14pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
   \forall i \leq n. \hspace{4pt} v_{i}=_{q_i} w_{i}\\
    \hline
   f(v_{1},...,v_{n})=_{\Sigma q_i} f(w_{1},...,,w_{n}) 
\end{array}
$
\end{minipage}
 \hspace{47pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    v=_{q} w  \\
    \hline
  \lambda x : \mathbb{A}. \hspace{4pt} v=_{q} \lambda x:\mathbb{A}. \hspace{4pt} w
\end{array}
$ \end{minipage}
\hspace{20pt}  \\
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    v=_{q} w \quad  v'=_{r} w'  \\
    \hline
   \text{pm} \hspace{4pt} v \hspace{4pt} \text{to} \hspace{4pt} x \otimes y. \hspace{4pt} v'=_{q + r}\text{pm} \hspace{4pt} w \hspace{4pt} \text{to} \hspace{4pt} x \otimes y .  \hspace{4pt} w'
\end{array}
$
\end{minipage}
\hspace{95pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    v =_{q} w    \\
    \hline
  \text{dis}(v) =_{q} \text{dis}(w)
\end{array}
$ \end{minipage}
\hspace{-35pt}
\begin{minipage}[t]{0.3\textwidth}
  $\begin{array}{c}
      v=_{q} w \quad v'=_{r} w' \\
      \hline
     v \hspace{1pt} v' =_{q + r} w \hspace{1pt}  w'
  \end{array}
  $ \end{minipage}
 \\
 &
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
  \Gamma \triangleright v =_{q} w: \mathbb{A} \quad \Delta \in \text{perm}(\Gamma)\\
    \hline
   \Delta \triangleright v =_{q} w: \mathbb{A}
\end{array}
$
\end{minipage}
\hspace{36pt}
\begin{minipage}[t]{0.3\textwidth}
  $\begin{array}{c}
     v=_{q}w  \quad v'=_{r}w'\\
      \hline
      v \text { to } *.v' =_{q+r} w \text { to } *.w'
  \end{array}
  $ \end{minipage}
  \hspace{14pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
    v =_{q} w \quad v'=_{r} w'    \\
    \hline
  v[v'/x]=_{q + r} w[w'/x]
\end{array}
$ \end{minipage}
\hspace{10pt}
\end{aligned}
\end{split}
\end{equation*}
\caption{Metric equational system}
\label{fig:metric deductive system}
\end{figure}

Here, $\text{perm} (\Gamma)$ denotes the set of possible permutions of context $\Gamma$. The rules (refl), (trans), and (sym)  generalize the properties of reflexivity, transitivity, and symmetry of equality.  Rule (weak) asserts that if two terms are at a maximum distance $q$ from each other, then they are also separated by any $r \geq q$. Rule (arch) states that if $v =_r w$ for all approximations $r$ of $q$, then it necessarily follows that $v =_q w$. The rule  (join) expresses that if several maximum distances between two terms are known, the actual maximum distance between them is the minimum of these distances. The rule that follows conveys that if the maximum distance between two terms $v$ and $w$ is $q$, and the maximum distance between terms $v'$ and $w'$ is $r$, then the maximum distance between the tensor products $v \otimes v'$ and $w \otimes w'$ is $q + r$. The remaining rules follow similar reasoning.

% dizer o que é perm

\begin{example}
  To ilustrate the usefulness of these equations, consider the program $P$ that recieves a tensor product, swaps its elements and then applies a function $f$ to to the new second element of the tensor  pair:
\begin{equation*}
\begin{split}
& P = x : \mathbb{A},  y : \mathbb{B} \triangleright \text{pm} \hspace{3 pt} x \otimes y\hspace{3 pt} \text{to} \hspace{3 pt} a \otimes b. \hspace{1pt} b \otimes f(a) : \mathbb{D} \otimes \mathbb{A} &
\end{split}
\end{equation*}
Now, consider the case where $f$ is an idealized version of function $f^{\epsilon}$ mapping $a$ to $f(a)^{\epsilon}$. The program that applies the ``real'' function $f$ to the first element of the tensor pair is $P^{\epsilon}$:
\begin{equation*}
  \begin{split}
  & P^{\epsilon} = x : \mathbb{A},  y : \mathbb{B} \triangleright \text{pm} \hspace{3 pt} x \otimes y\hspace{3 pt} \text{to} \hspace{3 pt} a \otimes b. \hspace{1pt} b \otimes f(a)^{\epsilon}  : \mathbb{D} \otimes \mathbb{A} &
  \end{split}
  \end{equation*}
Knowing that $f(a)^{\epsilon} =_{\epsilon} f(a)$, it is possible to show that $P^{\epsilon} =_{\epsilon} P $ using the metric equational system. The prove is as follows. The types and contexts are omitted for brevity as no ambiguity arises.
\begin{equation*}
  \begin{split}
  1 \hspace{10 pt} & f(a)^{\epsilon} =_{\epsilon} f(a) \\
  2 \hspace{10 pt} &  b =_{0} b & {(\text{refl})} \\
  3 \hspace{10 pt} & b \otimes f(a)^{\epsilon}  =_{\epsilon} b \otimes f(a)  & \text{($1,2,\otimes_i$)} \\
  4 \hspace{10 pt} &   x \otimes y =_{0}  x \otimes y  &{(\text{refl})}  \\
  5\hspace{10 pt}& \text{pm} \hspace{3 pt} x \otimes y\hspace{3 pt} \text{to} \hspace{3 pt} a \otimes b. \hspace{1pt} b \otimes f(a)^{\epsilon} =_{\epsilon} \text{pm} \hspace{3 pt} x \otimes y\hspace{3 pt} \text{to} \hspace{3 pt} a \otimes b. \hspace{1pt} b \otimes f(a) & \hspace{10pt} \text{($3,4,\otimes_e$)}
  \end{split}
  \end{equation*}
\end{example}

\begin{definition}
  Consider a tuple \( (G, \Sigma) \), where \( G \) is a class of ground types and \( \Sigma \) is a class of sorted operation symbols of the form \( f : A_1, \ldots, A_n \to A \) with \( n \geq 1 \). A \emph{linear metric $\lambda$-theory} is a tuple \( ((G, \Sigma), Ax) \), where \( Ax \) is a class of \emph{metric equations-in-context} over linear $\lambda$-terms constructed from \( (G, \Sigma) \).
\end{definition}

The elements of \( Ax \) are called the \emph{axioms} of the theory. Let \( Th(Ax) \) denote the smallest class that contains \( Ax \) and is closed under the rules presented in \autoref{fig:equations-linear-lambda} (i.e., the classical equational system) and \autoref{fig:metric deductive system}. The elements of \( Th(Ax) \) are called the \emph{theorems} of the theory.







\section{Category theory} \label{sec:catgories}


\todo[inline,size=\normalsize]{Cenas para a descrição da secção: ref awodeyCategoryTheory2010 e nota sobre a maioria dos exemplos serem retirados do noson} 

Category theory originated as an effort to connect and unify two distinct areas of mathematics.  The goal was to study and classify specific geometric structures—such as topological spaces, manifolds, and bundles—by associating them with corresponding algebraic structures like groups, rings, and abelian groups. It became clear that a language was needed to connect geometric and algebraic objects—one not explicitly tailored to geometry or algebra. Only a language of such generality could allow meaningful discussion across both fields.  This is the birth of category theory.
Described as "a language about nothing, and therefore about everything," category theory provides a highly general way of discussing mathematical concepts.  It was invented by Samuel Eilenberg and Saunders MacLane \cite{eilenbergGeneralTheoryNatural1945}. They organized various mathematical structures into categories called geometric others algebraic. To connect these categories, they defined functors, which map objects and morphisms from one category to another, much like functions do. They further introduced natural transformations, which provide a way to compare functors, translating the results of one functor into those of another. \cite{yanofskyMonoidalCategoryTheory2024}


\subsection{Categories}

\begin{definition}
   A \emph{category} $\catC$ consists of
   \begin{itemize}
    \item a collection of objects $A, B, C, \ldots$, denoted $|\catC|$ or $\text{Obj}(\catC)$;
    \item a collection of morphisms $f, g, \ldots $, usually denoted $\catC(A,B)$, $\mathrm{Hom}_{\catC}(A,B)$, or $\mathrm{Hom}(A,B)$ if there is no ambiguity. 
   \end{itemize}
    The collection for morphisms has the following structure:
    \begin{itemize}
      \item Each morphism has a specified domain and codomain; the notation $ f : A \to B $ indicates that $ f $ is a morphism from object $ A $ to object $ B $.  
       \item Every object $ A $ has an identity morphism $ \id_A : A \to A $.  
      \item For any pair of morphisms $ f : A \to B $ and $ g : B \to C $, where the codomain of $ f $ matches the domain of $ g $, there exists a composite morphism $ g \circ f : X \to Z $. We will also write $g \circ f$ as $f \cdot g$ or simply $f g$.
    \end{itemize}

     The composition is required to satisfy the two following laws: if $f : A \to B, g : B \to C,$ and $h:C \to D$ are morphisms, then
     \begin{itemize}
      \item  $f \circ \id_a = f = \id_b \circ f$;
      \item  $  (f \circ g) \circ h = f \circ (g \circ h) $.
     \end{itemize}
\end{definition}




%Sets

\begin{example}
 $\catSet$ is the category whose objects are sets and whose  morphisms are functions between them. Given a function \(f: A \to B\), it assigns to each element \(a \in A\) a unique image \(f(a) \in B\). 
 For any two functions \(f: A \to B\) and \(g: B \to C\), their composition is defined by
$$
(g \circ f)(a) = g(f(a)) \quad \text{for all } a \in A.
$$
This composition is \emph{associative}. That is, for any further function \(h: C \to D\), we have
\[
(h \circ g) \circ f = h \circ (g \circ f),
\]
since for every \(a \in A\),
\[
((h \circ g) \circ f)(a) = h(g(f(a))) = (h \circ (g \circ f))(a).
\]

Moreover, for every set \(A\), there exists an \emph{identity function}
\[
\id_A : A \to A, \quad \text{defined by } \id_A(a) = a,
\]
which satisfies the unit laws for composition:
\[
f \circ \id_A = f \quad \text{and} \quad \id_B \circ f = f
\]
for any function \(f: A \to B\).

Therefore, \(\mathbf{Set}\), with sets as objects and functions as morphisms, satisfies the axioms of a category.
\end{example}

Another common type of example consists of categories of sets equipped with additional structure, along with functions that preserve that structure.


\begin{definition}
A \emph{partially ordered set} or \emph{partial order} is a set $A$ equipped with a binary relation $\leq_A$ satisfying the following properties for all $a, b, c \in A$:
\begin{itemize}
    \item Reflexivity: $a \leq_A a$;
    \item Transitivity: If $a \leq_A b$ and $b \leq_A c$, then $a \leq_A c$;
    \item Antisymmetry: If $a \leq_A b$ and $b \leq_A a$, then $a = b$.
\end{itemize}
\end{definition}

\begin{example}
The set of real numbers \(\mathbb{R}\), equipped with the usual ordering \(\leq\), forms a poset. Moreover, it is \emph{linearly ordered} (or \emph{totally ordered}), since for any \(x, y \in \mathbb{R}\), either \(x \leq y\) or \(y \leq x\) holds.
\end{example}

\begin{definition}
Given two partial orders \((A, \leq_A)\) and \((B,\leq_B)\), a function \(m: A \to B\) is called a \emph{monotone map} (or \emph{order-preserving map}) if for all \(a, a' \in A\),
\[
a \leq_A a' \quad \Rightarrow \quad m(a) \leq_B m(a').
\]
\end{definition}



\begin{example}
  $\catPO$ is the category of all partial orders and all monotone maps. First, for any poset \(A\), the identity function \(\id_A : A \to A\) is monotone. Indeed, for all \(a \in A\),
\[
a \leq_A a \quad \Rightarrow \quad \id_A(a) \leq_A \id_A(a).
\]

Next, given monotone maps \(f : A \to B\) and \(g : B \to C\), their composition \(g \circ f : A \to C\) is also monotone. For all \(a, a' \in A\), if \(a \leq_A a'\), then
\[
f(a) \leq_B f(a') \quad \text{and} \quad g(f(a)) \leq_C g(f(a')),
\]
so it follows that
\[
(g \circ f)(a) \leq_C (g \circ f)(a').
\]

\end{example}

\begin{example}
  Each partially ordered set naturally defines a category. Let \( (P, \leq) \) be a poset. We define a category \( \catfont{B(P, \leq)} \), often denoted simply by \( \catfont{B(P)} \) or even \( \catfont{P} \), where the objects are the elements of \( P \), and there is a unique morphism \( p \to q \) if and only if \( p \leq q \). The reflexivity of the order \( \leq \) ensures the existence of identity morphisms, while transitivity guarantees that morphisms compose appropriately. Moreover, since there is at most one morphism between any two objects, composition is trivially associative. 
\end{example}

\begin{example}
 $\catVect$ is the category of finite complex vector spaces and linear mappings.
\end{example}

\begin{example}
Given a functional programming language $L$, we can define a category $\catCompFunc$.  In this category, the objects represent the data types of the language \( L \), and the morphisms correspond to computable functions or programs. A function is considered \emph{computable} if a computer program is capable of executing that function.

The composition of morphisms is defined as follows: given two morphisms \( f \colon X \to Y \) and \( g \colon Y \to Z \), the composition \( g \circ f \colon X \to Z \) is defined by applying \( g \) to the output of \( f \). This composition is often written as \( f;g \).

Additionally, the identity morphism \( \id_X \colon X \to X \) represents the ``identity program," which returns its input without making any changes (i.e., it "does nothing").
\end{example}

\begin{example} \label{ex:cat_cptp}
The category $\catCPTP$ is the category whose objects are natural numbers $n \geq 1$ and whose morphisms $n \rightarrow m$ are quantum channels $C^{n \times n} \rightarrow C^{m\times m}$.
\end{example}

\begin{example} \label{ex:cat_cps}
The category $\catCPS$ is the category whose objects are natural numbers $n \geq 1$ and whose morphisms $n \rightarrow m$ are completely positive trace-nonincreasing maps $C^{n \times n} \rightarrow C^{m\times m}$.
\end{example}

\begin{example}
  The category $\catBan$ is the category of Banach spaces and short maps.
\end{example}


\begin{definition} 
 A morphism $f : A \to B$  in a category $\catC$ be a category is called an \emph{isomorphism} if there exists a morphism $f^{-1} : B \to A$ such that
\[
f^{-1} \circ f = \id_A \quad \text{and} \quad f \circ g = \id_B.
\]
In this case, $f^{-1}$ is called the \emph{inverse} of $f$, and it is unique. If such an isomorphism exists, we say that $A$ and $B$ are \emph{isomorphic}, written
$A \cong B.$
\end{definition}

One of the central ideas in category theory is \emph{duality}. Simply put, for a given definition of a structure, there is often a corresponding dual concept obtained by reversing the directions of all the arrows. 

\begin{definition} 
Let \(\catC\) be a category. The \emph{opposite category}, denoted \(\catC^{\mathrm{op}}\), is defined as follows:
\begin{itemize}
  \item The objects of \(\catC^{\mathrm{op}}\) are the same as those of \(\catC\).
  \item For any pair of objects \(A, B\), the hom-set in \(\catC^{\mathrm{op}}\) is defined by
  \[
  \textit{Hom}_{\catC^{\mathrm{op}}}(A, B) = \textit{Hom}_{\catC}(B, A),
  \]
  that is, each morphism \(f: A \to B\) in \(\catC^{\mathrm{op}}\) corresponds to a morphism \(f: B \to A\) in \(\catC\).
  \item Composition in \(\catC^{\mathrm{op}}\) is defined using the composition in \(\catC\), but in reverse order. That is, if
  \[
  A \xrightarrow{ \quad f \quad } B \xrightarrow{\quad g \quad } C
  \]
  are morphisms in \(\catC^{\mathrm{op}}\), corresponding to morphisms
  \[
  C \xrightarrow{ \quad g \quad} B \xrightarrow{ \quad f \quad} A
  \]
  in \(\catC\), then the composition in \(\catC^{\mathrm{op}}\) is defined by
  \[
  g \circ f := f \circ_{\catC} g.
  \]
\end{itemize}

Thus, \(\catC^{\mathrm{op}}\) reverses the direction of morphisms and composition while retaining the same collection of objects.
\end{definition}

\begin{definition}
  A subcategory \( \catD \) of a category \( \catC \) is a category such that 
  \begin{itemize}
    \item All the objects of \( \catD \) are objects of \( \catC \), and all the morphisms of \( \catD \) are morphisms of \( \catC \) (that is, \( \catD_0 \subseteq \catC_0 \) and \( \catD_1 \subseteq \catC_1 \)).
    \item The domain and codomain of any morphism in \( \catD \) are the same as in \( \catC \) (in other words, the domain and codomain maps for \( \catD \) are the restrictions of those for \( \catC \)).
    \item  It follows that for any objects \( A \) and \( B \) in \( \catD \), we have \( \mathrm{Hom}_{\catD}(A, B) \subseteq \mathrm{Hom}_{\catC}(A, B) \). If \( A \) is an object of \( \catD \), then its identity morphism \( \mathrm{id}_A \) in \( \catC \) also belongs to \( \catD \).
    \item If \( f: A \to B \) and \( g: B \to C \) are morphisms in \( \catD \), then the composite \( g \circ f \), as defined in \( \catC \), is also in \( \catD \), and coincides with the composite in \( \catD \).
  \end{itemize}
  
\end{definition}

\begin{example}
  The category $\catFinSet$, whose objects are finite sets and whose morphisms are functions between them, forms a subcategory of the category $\catSet$.
\end{example}

\begin{example}
  The category $\catCPTP$ is a subcategory of $\catCPS$. 
\end{example}

\begin{definition}
  A category is called \emph{small} if both its collection of objects and its collection of morphisms form sets.
A category is called \emph{locally small} if, for every pair of objects, the corresponding hom-set is a set.
\end{definition}


% Partial order
%Vect
%Banach spaces and short maps
%CPTP
%Linguagens de programação


%We say that a diagram commutes when for every two vertices X,Y in the diagram, all the paths from X to Y (following arrows) yield equal morphisms. 

%c_op
%iso

\subsection{Produts and coproducts}

 A category frequently possesses more intricate structure than a mere collection of objects and their morphisms. The existence of particular relationships among certain objects and morphisms can can make some objects have important properties.

It should be noted that a diagram is said to commute if, for every pair of objects $X$ and $Y$ in the diagram, all directed paths from 
$X$ to $Y$ yield equal morphisms.

\begin{definition}
  An object \( 0 \) in a category \( \catC \) is called an \emph{initial object} if for every object \( A \in \catC  \), there exists a unique morphism  $f: 0 \to A $.

\end{definition}

\begin{definition}
  An object \( T \) in a category \( \catC  \) is called a \emph{terminal object} if for every object \( A \in \catC  \), there exists a unique morphism $ f: A \to T $ .
\end{definition}

\begin{example}
In the category \( \catSet \), the empty set \( \emptyset \) is an initial object, since for any set \( S \), there exists a unique function$f : \emptyset \to S.$
This function is unique because there are no elements in \( \emptyset \) to map.

Any singleton set, such as \( \{*\} \) or \( \{a\} \), is a terminal object in this category. For any set \( S \), there exists a unique function $f : S \to \{*\}$,
which maps every element of \( S \) to the sole element of the singleton set
\end{example}

\begin{example}
  Let $(P, \leq)$ be a partial order and $\catfont{P}$ be its associated
 category.
  Here, the initial object is the \emph{bottom element}—an element that is less than or equal to every other element in $P$. The terminal object in $\catP$ is the \emph{top element}—an element that is greater than or equal to every other element in $P$.
\end{example}



\begin{definition} [\emph{Product}]
  Consider a category $\catC$.  We say that it has (binary) products if for any
objects $A$ and $B$ in $\catC$ there also exists an object $A \times B$
$\catC$ with morphisms $\pi_A : A \times B \to A$ and $\pi_B :  A \times B \to  B$
that satisfy a certain universal property: specifically for every two morphisms
$f  : C \to A$ and $g : C \to B$ there exists a \emph{unique} morphism $\langle f,g \rangle :
C \to A \times B $ called \emph{pairing} that makes the diagram below commute.
\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes,row sep=4em,column sep=7em,minimum width=2em]
  {
   & C &  \\
    A  & A \times B & B\\
  };
  \path[-stealth]
    (m-1-2) edge  node [above] {$f$} (m-2-1)
    (m-1-2) edge  node [above] {$g$} (m-2-3)
    (m-2-2) edge  node [below] {$\pi_A$} (m-2-1)
    (m-2-2) edge  node [below] {$\pi_B$} (m-2-3)
    (m-1-2) edge [dotted]  node [right] {$\langle f,g \rangle$} (m-2-2);
    ;
\end{tikzpicture}
\]
\end{definition}

  \begin{definition}
Let \( A \times B \) be a product of objects \( A \) and \( B \), and let \( A' \times B' \) be a product of objects \( A' \) and \( A' \) in a category $\catC$. Suppose we are given morphisms \( f : A \to A' \) and \( g : B \to B' \). 

Then there exists a unique morphism
\[
f \times g : a \times b \to a' \times b'
\]
such that the following diagram commutes.
\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes,row sep=4em,column sep=7em,minimum width=2em]
  {
   A & A \times B & B \\
    A'  & A' \times B' & B'\\
  };
  \path[-stealth]
    (m-1-2) edge  node [below] {$\pi_A$} (m-1-1)
    (m-1-2) edge  node [below] {$\pi_B$} (m-1-3)
    (m-1-1) edge  node [left] {$f$} (m-2-1)
    (m-1-3) edge  node [right] {$g$} (m-2-3)
    (m-2-2) edge  node [below] {$\pi_A'$} (m-2-1)
    (m-2-2) edge  node [below] {$\pi_B'$} (m-2-3)
    (m-1-2) edge [dotted]  node [right] {$ f\times g$} (m-2-2);
    ;
\end{tikzpicture}
\]
This induced morphism \( f \times g \) is called the \emph{product of the morphisms} \( f \) and \( g \), and it is given explicitly by
\[
f \times g = \langle f \circ \pi_A,\, g \circ \pi_B \rangle.
\]
\end{definition}




\begin{theorem} 
  Let \( A \times B \) be the product of objects \( A \) and \( B \) in a category $\catC$. For any object $C$ and morphisms \( f : C \to A \) and \( g : C \to B \) are morphisms, it holds that:
\[
\langle f \circ h,\, g \circ h \rangle = \langle f, g \rangle \circ h.
\]
\end{theorem}

\begin{proof}

  The universal property of the product induces a unique morphism \( \langle f, g \rangle : C \to A \times B \) such that
$\pi_A \circ \langle f, g \rangle = f \quad \text{and} \quad \pi_B \circ \langle f, g \rangle = g.$

Now, let \( h : D \to C \) be another morphism. Then the compositions \( f \circ h : D \to A \) and \( g \circ h : D \to B \) also induce a unique morphism \( \langle f \circ h,\, g \circ h \rangle : D \to A \times B \) by the universal property of the product. As a result, by the universal property of the produt the following diagram commutes.

\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes,row sep=3em,column sep=4em,minimum width=8em]
  {
    & D &  \\
    & C &  \\
     & A \times B &\\
    A &  & B\\
  };
  \path[-stealth]
    (m-1-2) edge  node [right] {$h$} (m-2-2)
    (m-1-2) edge  node [left] {$f \circ h$} (m-4-1)
    (m-1-2) edge  node [right] {$g \circ h$} (m-4-3)
    (m-1-2) edge [bend left=-20] node [left] {$\langle f \circ h,g \circ h \rangle$} (m-3-2)
    (m-2-2) edge  node [right] {$\langle f,g \rangle$} (m-3-2)
    (m-2-2) edge  node [right] {$f$} (m-4-1)
    (m-2-2) edge  node [right] {$g$} (m-4-3)
    (m-3-2) edge  node [below=0.1cm] {$\pi_A$} (m-4-1)
    (m-3-2) edge  node [below=0.1cm] {$\pi_B$} (m-4-3)
    %(m-1-2) edge  node [above] {$f$} (m-2-1)
    %(m-1-2) edge  node [above] {$g$} (m-2-3)   
    %(m-1-2) edge [dotted]  node [right] {$\langle f,g \rangle$} (m-2-2);
    ;
\end{tikzpicture}
\]

\end{proof}


% exemplos

\begin{example}
In the category $\catSet$, the product of two sets $A$ and $B$ is given by their Cartesian product, denoted
\[
A \times B = \{(a, b) \mid a \in A,\ b \in B\}.
\]
The projection maps are defined by
\[
\pi_A(a, b) = a \quad \text{and} \quad \pi_B(a, b) = b.
\]
Given a set $C$ and morphisms $f: C \to A$ and $g: C \to B$, their pairing is the map
\[
\langle f, g \rangle(c) = (f(c), g(c)).
\]
\end{example}

\begin{example}
  Let $(P, \leq)$ be a partial order and $\catfont{P}$ be its associated category.  Consider a product of elements  \( p \times q \in P\). Then, by definition, there must exist projections satisfying
\[
p \times q \leq p \quad \text{and} \quad p \times q \leq q.
\]
Furthermore, for any element \( x \in P \), if
\[
x \leq p \quad \text{and} \quad x \leq q,
\]
then it follows that
\[
x \leq p \times q.
\]
This operation \( p \times q \) corresponds to what is commonly known as the \emph{greatest lower bound} or \emph{meet}, and is typically denoted by \( p \wedge q \).
\end{example}

\begin{example}
  In the category $\catVect$, the product of two vector spaces $V$ and $W$ corresponds to their direct sum, denoted by
\[
V \oplus W.
\]
The projection maps are the linear maps
\[
\pi_V : V \oplus W \to V, \quad \pi_V(v, w) = v,
\]
\[
\pi_W : V \oplus W \to W, \quad \pi_W(v, w) = w.
\]
Given any vector space $U$ and linear maps $f: U \to V$ and $g: U \to W$, the unique map $\langle f, g\rangle : U \to V \oplus W$
is defined by
\[
\langle f, g\rangle (u) = (f(u), g(u)).
\]
Similarly, in $\catCPS$ the product corresponds to the sum and the projection and paring maps are defined in a analogous way.

\end{example}


The \emph{coproduct} is the dual of the \emph{product}—it is obtained by reversing all the morphisms in the definition of a product. Consequently, a product in a category $\catC$ corresponds to a coproduct in the opposite category $\catCop$.

  
\begin{definition}
Consider a category $\catC$.  We say that it has (binary) coproducts if for any
objects $A$ and $B$ in $\catC$ there also exists an object $A \oplus B$ in
$\catC$ with morphisms $\inl : A \to A \oplus B$ and $\inr : B \to A \oplus B$
that satisfy a certain universal property: specifically for every two morphisms
$f  : A \to C$ and $g : B \to C$ there exists a \emph{unique} morphism $[f,g] :
A \oplus B \to C$ known as \emph{co-pairing} that makes the diagram below commute.
\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes,row sep=4em,column sep=7em,minimum width=2em]
  {
   & C &  \\
    A  & A \oplus B & B\\
  };
  \path[-stealth]
    (m-2-1) edge  node [above] {$f$} (m-1-2)
    (m-2-3) edge  node [above] {$g$} (m-1-2)
    (m-2-1) edge  node [below] {$\inl$} (m-2-2)
    (m-2-3) edge  node [below] {$\inr$} (m-2-2)
    (m-2-2) edge [dotted]  node [right] {$[f,g]$} (m-1-2);
    ;
\end{tikzpicture}
\]
\end{definition}

  \begin{definition}
Let \( A \oplus B \) be a coproduct of objects \( A \) and \( B \), and let \( A' \times B' \) be a coproduct of objects \( A' \) and \( A' \) in a category $\catC$. Suppose we are given morphisms \( f : A \to A' \) and \( g : B \to B' \). 

Then there exists a unique morphism
\[
f \times g : a \times b \to a' \times b'
\]
such that the following diagram commutes.
\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes,row sep=4em,column sep=7em,minimum width=2em]
  {
   A  & A \times B & B \\
    A'  & A' \times B' & B' \\
  };
  \path[-stealth]
    (m-1-1) edge  node [below] {$\inl$} (m-1-2)
    (m-1-3) edge  node [below] {$\inr$} (m-1-2)
    (m-1-1) edge  node [left] {$f$} (m-2-1)
    (m-1-3) edge  node [right] {$g$} (m-2-3)
    (m-2-1) edge  node [below] {$\inl$} (m-2-2)
    (m-2-3) edge  node [below] {$\inr$} (m-2-2)
    (m-1-2) edge [dotted]  node [right] {$ f\oplus g$} (m-2-2);
    ;
\end{tikzpicture}
\]
This induced morphism \( f \oplus g \) is called the \emph{coproduct of the morphisms} \( f \) and \( g \), and it is given explicitly by
\[
f \oplus g = [\inl \circ f,\, \inr \circ g].
\]
\end{definition}

\begin{theorem} 
  Let \( A \oplus B \) be the product of objects \( A \) and \( B \) in a category $\catC$. For any object $C$ and morphisms \( f : A \to C \) and \( g : B \to C \) are morphisms, it holds that:
\[
[h \circ f,\, h \circ g]  =  h \circ [f,g].
\]
\end{theorem}

\begin{proof}
 By the universal property of the coprodut the following diagram commutes.

\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes,row sep=3em,column sep=4em,minimum width=8em]
  {
    & D &  \\
    & C &  \\
     & A \times B &\\
    A &  & B\\
  };
  \path[-stealth]
    (m-2-2) edge  node [right] {$h$} (m-1-2)
    (m-4-1) edge  node [left] {$h \circ f$} (m-1-2)
    (m-4-3) edge  node [right] {$h \circ c$} (m-1-2)
    (m-3-2) edge [bend left=20] node [left] {$[h \circ f,h \circ g]$} (m-1-2)
    (m-3-2) edge  node [right] {$[f,g]$} (m-2-2)
    (m-4-1) edge  node [right] {$f$} (m-2-2)
    (m-4-3) edge  node [right] {$g$} (m-2-2)
    (m-4-1) edge  node [below=0.1cm] {$\inl$} (m-3-2)
    (m-4-3) edge  node [below=0.1cm] {$\inr$} (m-3-2)
    ;
\end{tikzpicture}
\]

\end{proof}

\begin{example}
  In the category $\catSet$, the coproduct \( A \oplus B \) of two sets is their disjoint union, which can be constructed as
\[
A \oplus B = \{(a, 1) \mid a \in A\} \cup \{(b, 2) \mid b \in B\}.
\]
The canonical coproduct injections are defined by
\[
i_1(a) = (a, 1), \quad i_2(b) = (b, 2).
\]
Given any set \(C\) and functions \(f: A \to C\) and \(g: B \to C\), the copairing \([f, g]: A \oplus B \to C\) is defined by
\[
[f, g](x, \delta) = 
\begin{cases}
f(x) & \text{if } \delta = 1, \\
g(x) & \text{if } \delta = 2.
\end{cases}
\]
\end{example}

\begin{example}
  Let $(P, \leq)$ be a partial order and $\catfont{P}$ be its associated category.  
Consider a coproduct of elements \( p \oplus q \in P \). Then, by definition, there must exist injections satisfying
\[
p \leq p + q \quad \text{and} \quad q \leq p + q.
\]
Furthermore, for any element \( z \in P \), if
\[
p \leq z \quad \text{and} \quad q \leq z,
\]
then it follows that
\[
p + q \leq z.
\]
This operation \( p + q \) corresponds to what is commonly known as the \emph{least upper bound} or \emph{join}, and is typically denoted by \( p \vee q \).
\end{example}

\begin{example}
  In both  $\catVect$ and $\catCPS$, the coproduct coincides with the product. In such cases, this structure is called a \emph{biproduct}. 
  In both  $\catVect$. the injection maps are the linear maps
\[
\inl: V \to  V \oplus W, \quad  \inl(v)= (v,0),
\]
\[
\inr : W \to V \oplus W, \quad \inr(w) = (0,w).
\]
Given any vector space $U$ and linear maps $f: V \to U$ and $g: W \to U$, the unique map $\langle f, g\rangle : V \oplus W \to U$
is defined by
\[
[f, g] (v,w) = f(v)+ g(w).
\]
In $\catCPTP$ the coproduct is also given by the direct sum. In both $\catCPTP$ and $\catCPS$ injections and copairing map are defined analogously to those in \(\catVect\).
\end{example}

\begin{example}
  In the category \(\catBan\), the coproduct of Banach spaces is given by their direct sum equipped with the \(L_1\)-norm. The injections and copairing map are defined analogously to those in \(\catVect\). 
\end{example}



\subsection{Functors}
  

Although categories are interesting on their own, the real strength of category theory lies in understanding how categories relate to one another. Just as functions express relationships between sets, functors play a similar role for categories. A functor maps each object in one category to an object in another category, and it does the same for morphisms, preserving the structure of the relationships.

\begin{definition}
  Let $\catC$ and $\catD$ be two categories. A \emph{functor} $F: \catC \to \catD$ consists of a mapping that assigns to each object $A$ in $\catC$ an object $FA$ in $\catD$, and to each morphism $f \in \mathrm{Hom}_{\catC}(A, B)$ a morphism $Ff \in \mathrm{Hom}_{\catD}(FA, FB)$, in such a way that the following two conditions are satisfied for all objects $A, B, C$ in $\catC$ and all morphisms $f \in \mathrm{Hom}_{\catC}(A,B)$ and $g \in \mathrm{Hom}_{\catC}(B,C)$:
\[
F(\id_A) = \id_{FA}, \qquad F(g \circ f) = F(g) \circ F(f).
\]

A functor $F: \catC \to \catD$ is said to be \emph{full} if, for all objects $A$ and $B$ in $\catC$, the induced map
\[
F_{A,B}: \mathrm{Hom}_{\catC}(A, B) \longrightarrow \mathrm{Hom}_{\catD}(FA, FB), \quad f \mapsto Ff,
\]
is surjective. The functor is called \emph{faithful} if each $F_{A,B}$ is injective, and \emph{fully faithful} if each $F_{A,B}$ is bijective.

A \emph{full embedding} is a functor that is fully faithful and, in addition, injective on objects.
\end{definition}

\begin {example}
Let $\catC$ be a category. Then there exists an \emph{identity functor} $\id_{\catC} : \catC \to \catC,$
which is defined on objects by $\id_{\catC}(A) = A$ for every object $A$ in $\catC$, and analogously on morphisms, that is, $\id_{\catC}(f) = f$ for every morphism $f$ in $\catC$.
\end{example}

\begin{example}
  Consider the natural numbers $\mathbb{N}$ as partial order category. There is a functor $(-) + 5 : \mathbb{N} \to \mathbb{N}$
that maps each object $m \in \mathbb{N}$ to $m + 5$. This defines a functor because it preserves morphisms: if $m \leq m'$, then $m + 5 \leq m' + 5$. Moreover, the identity morphisms are preserved, since $(\id_m) + 5 = \id_{m+5}$.
\end{example}

\begin{example}
  Consider the set of real numbers $\mathbb{R}$ and the set of integers $\mathbb{Z}$, each regarded as a partial order category. In this context, there exists a functor $\mathrm{Floor} : \mathbb{R} \to \mathbb{Z} $ that assigns to each real number $r \in \mathbb{R}$ the greatest integer less than or equal to $r$, denoted $\lfloor r \rfloor$. For instance, $\lfloor 6.2 \rfloor = 6$ and $\lfloor -1.66 \rfloor = -2$. 

Similarly, there exists a \emph{ceiling functor} $\mathrm{Ceil} : \mathbb{R} \to \mathbb{Z}$ that maps each real number $r$ to the least integer greater than or equal to $r$, denoted $\lceil r \rceil$.


\end{example}


\begin{definition}
  Given categories $\catC$, $\catD$, and $\catE$, a \emph{bifunctor}
$F : \catC \times \catD \to \catE$
is simply a functor from the product category $\catC \times \catD$ to $\catE$. In particular, $F$ is a rule that assigns:
\begin{itemize}
    \item to every object $A \in \catC$ and $B \in \catD$, an object $F(A, B) \in \catE$;
    \item to every morphism $f : A \to A'$ in $\catC$ and $g : B \to B'$ in $\catD$, a morphism
    $F(f, g) : F(A, B) \to F(A', B') \in \catE.$
\end{itemize}

These assignments must satisfy the following two requirements:

\begin{itemize}
    \item Respect for composition:  
    For morphisms $f : A \to A'$, $f' : A' \to A''$ in $\catC$ and $g : B \to B'$, $g' : B' \to B''$ in $\catD$, it should hold that
    \[
    F(f' \circ f,\, g' \circ g) = F(f', g') \circ F(f, g),
    \]
    where the $\circ$ on the right-hand side is composition in $\catE$.

    \item Respect for identities:  
    For all objects $A \in \catC$ and $B \in \catD$, it should hold that
    \[
    F(\id_A, \id_B) = \id_{F(A, B)},
    \]
    where $\id_A$ and $\id_B$ are the identity morphisms in $\catC$ and $\catD$, respectively, and $\id_{F(A, B)}$ is the identity morphism in $\catE$.
\end{itemize}

Many times, rather than writing the name of the bifunctor before the input, like $F(A, B)$, we write the bifunctor as an operation between the inputs, for example, $a \mathbin{\Box} b$. If we use this notation, the condition
\[
F(f' \circ f,\, g' \circ g) = F(f', g') \circ F(f, g)
\]
becomes
\[
(f' \circ f) \mathbin{\Box} (g' \circ g) = (f' \mathbin{\Box} g') \circ (f \mathbin{\Box} g).
\]
\end{definition}

\subsection{Natural Tranformations}
A \emph{natural transformation} is a morphism between functors. It provides a way of relating two functors that have the same domain and codomain. Intuitively, if we consider two functors $F, G : \catC \to \catD$ as different ways of assigning images of the category $\catC$ into the category $\catD$, then a natural transformation $\eta : F \Rightarrow G$ is a coherent way of transforming the image of $F$ into the image of $G$.

\begin{definition}
  Let $\catC$ and $\catD$ be categories, and let $F, G : \catC \to \catD$ be functors. A \emph{natural transformation} $\eta : F \Rightarrow G$ is a family of morphisms in $\catD$,
\[
\left( \eta_A : FA \to GA \right)_{A \in \mathrm{Ob}(\catC)},
\]
indexed by the objects of $\catC$, such that for every morphism $f : A \to A'$ in $\catC$, the following diagram commutes. 

\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes,row sep=4em,column sep=7em,minimum width=2em]
  {
   FA  & GA  \\
    FA'  & GA' \times B'  \\
  };
  \path[-stealth]
    (m-1-1) edge  node [above] {$\eta_A$} (m-1-2)
    (m-2-1) edge  node [below] {$\eta_{A'}$} (m-2-2)
    (m-1-1) edge  node [left] {$Ff$} (m-2-1)
    (m-1-2) edge  node [right] {$Gf$} (m-2-2)
    ;
\end{tikzpicture}
\]
Given a natural transformation \(\eta : F \Rightarrow G\), the morphism \(\eta_A : F(A) \to G(A)\) in \(\catD\) is called the \emph{component} of \(\eta\) at \(A\).
A natural transformation $\eta : F \Rightarrow G$ is represented diagrammatically as 
\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes,row sep=0.4em,column sep=2em,minimum width=1em]
  {
   \catC   & \big\Downarrow_{\eta} & \catD \\
  };
  \path[-stealth]
    (m-1-1) edge [bend left=40] node [above] {$F$} (m-1-3)
    (m-1-1) edge [bend left=-40] node [below] {$G$} (m-1-3)
    ;
\end{tikzpicture}
\]

\end{definition}


\begin{example}
  For every functor $F : \catC \to \catD$, there exists a natural transformation
  \[
    \iota_F : F \Rightarrow F
  \]
  known as  \emph{identity natural transformation},  such that for each object $A \in \catC$, each component of $\iota_F$ is the identity morphism:
  \[
    (\iota_F)_A = \id_{F(A)} : F(A) \to F(A).
    \] 
\end{example}

\begin{example}
The \emph{list functor}
\[
\mathrm{List} : \catSet \to \catSet
\]
assigns to each set \( S \) the set of all finite sequences (or lists) of its elements. 

For instance, if \( S = \{a, b, c\} \), then
\[
\mathrm{List}(S) = \{\varepsilon, a, b, c, aa, ab, ac, ba, \ldots, abc, cba, \ldots\},
\]
where \( \varepsilon \) denotes the empty list.

Given a function \( f : S \to T \), where $T=\{1,2\} $, the functor maps it to \(\mathrm{List}(f) : \mathrm{List}(S) \to \mathrm{List}(T)\), which applies \( f \) to each element of a list. For example, if
\[
f(a) = 2, \quad f(b) = 1, \quad f(c) = 2,
\]
then \(\mathrm{List}(f)(aabccba) = 2212212\).

There exists a natural transformation
\[
\mathrm{Reverse} : \mathrm{List} \Rightarrow \mathrm{List},
\]
whose component at a set \(S\), \(\mathrm{Reverse}_S\), maps each list to its reversal. For example:
\[
\mathrm{Reverse}_S(accbab) = babcca.
\]

\end{example}


\begin{definition}
  A natural transformation $\eta : F \Rightarrow G$ between functors $F, G : \catC \to \catD$ is called a \emph{natural isomorphism} if, for every object $A \in \catC$,  $\eta_A : F(A) \to G(A)$ is an isomorphism in $\catD$.
\end{definition}


\subsection{Equivalence of Categories}

In category theory, the concept of isomorphism between categories can be quite strict - is is not often is arises in a non-trivial manner. So, we weaken the notion of isomorphism and come to the concept of an \emph{equivalence of categories}.

If \( F: \catC \to \catD \) is an isomorphism of categories, then for every object \( B \in \catD \), there exists a \emph{unique} object \( A \in \catC \) such that \( F(A) = B \). This expresses the idea that \( \catC \) and \( \catD \) are structurally identical.

An \emph{equivalence of categories} relaxes this requirement. For every object \( B \in \catD \), there exists an object \( A \in \catC \) such that \( F(A) \) is not necessarily equal to \( B \), but is \emph{isomorphic} to \( B \). 

\begin{definition}
  Categories \( \catC \) and \( \catD \) are  said to be \emph{equivalent} if there exist functors 
\( F: \catC \to \catD \) and \( G: \catD\to \catC \) such that 
\( G \circ F \cong \id_{\catC} \) and \( F \circ G \cong \id_{\catD} \). 
The functors \( F \) and \( G \) are called \emph{quasi-inverses}, and we write \( \catC \simeq \catD \).
This means that for every \( A \in \catC \), there is a \( B \in \catD \) with \( G(B) \cong A \), 
and for every \( B \in \catD \), there is an \( A \in \catC \) with \( F(A) \cong B \).
\end{definition}

\begin{example}
  One of the simplest examples of an equivalence of categories is the relationship between the one-object category \( \mathbf{1} \) and the category \( \mathbf{2}_I \), which has two objects and a single isomorphism between them. We can visualize this as:
$$
\ast \;\; \quad \simeq \quad a \xlongrightarrow{\;\cong\;} b \;\; 
$$

More precisely, there is a unique functor \( ! : \mathbf{2}_I \to \mathbf{1} \), and a functor \( L : \mathbf{1} \to \mathbf{2}_I \) defined by \( L(\ast) = a \). Clearly, the composition \( ! \circ L \) is equal to \( \id_{\mathbf{1}} \), and \( L \circ ! \cong \id_{\mathbf{2}_I} \), since both objects \( a \) and \( b \) in \( \mathbf{2}_I \) are isomorphic. Thus, \( \mathbf{1} \simeq \mathbf{2}_I \).
\end{example}

\subsection{Adjoints}
If we further weaken the notion of an equivalence of categories, we we arrive at the concept of an \emph{adjunction}. A central idea in category theory is that \emph{the weaker the assumptions we impose, the more mathematical phenomena we can capture}. This principle explains why adjunctions are among category theory's most important structures.

\begin{definition}
  An adjunction between categories $\catC$ and $\catD$ is given by a quadruple 
$(L, R, \eta, \epsilon)$, where $L : \catC \to \catD$ and 
$R : \catD \to \catC$ are functors, and 
$\eta : \id_{\catC} \Rightarrow R L$ and 
$\epsilon : L R \Rightarrow \id_{\catD}$ are natural transformations such that
\[
(\eta R) \circ (R \epsilon) = \id_R \quad \text{and} \quad (L \eta) \circ (\epsilon L) = \id_L.
\]
One says that $R$ is right adjoint to $L$, or that $L$ is left adjoint to $R$, and one calls 
$\eta$ the \emph{unit} and $\epsilon$ the \emph{counit} of the adjunction.  Such an adjunction is denoted by $L \dashv R$, where the turn of the symbol $\dashv$ always points to the left adjoint.

An adjunction between categories can be characterized in multiple equivalent ways. It follows one of the alternative formulations. 

Given categories \(\catC\) and \(\catD\), a pair of functors \(L: \catC \to \catD\) and \(R: \catD \to \catC \) form an \emph{adjunction} \(L \dashv R\) if there exists a natural isomorphism:
\[
\mathrm{Hom}_{\catD}(L(A), B) 
\xlongrightarrow{\quad \Phi_{A,B} \quad}
\mathrm{Hom}_{\catC}(A, R(B)).
\]

\end{definition}

\begin{example}
  Consider the set of real numbers $\mathbb{R}$ and the set of integers $\mathbb{Z}$, each viewed as partial order categories. There is an inclusion functor $\mathrm{inc} : \mathbb{Z} \hookrightarrow \mathbb{R}$ which simply maps each integer to itself.  This inclusion has a left adjoint $L : \mathbb{R} \to \mathbb{Z}$. 

To determine this left adjoint $L$, we use the definition of an adjunction:  for all $N \in \mathbb{Z}$ and $R \in \mathbb{R}$, we have a natural isomorphism:
\[
\mathrm{Hom}_{\mathbb{Z}}(L(R), N) \cong \mathrm{Hom}_{\mathbb{R}}(R, \mathrm{inc}(N)).
\]

Since both $\mathbb{Z}$ and $\mathbb{R}$ are partial orders, the hom-sets contain at most one morphism. Hence, this isomorphism reduces to the logical equivalence:
\[
 L(R) \leq N \text{ if and only if } R \leq \mathrm{inc}(N) = N.
\]

Take $R = 7.27$ as an example. Then the inequality $R \leq N$ holds precisely when $N$ is an integer greater than or equal to $7.27$. That is:
\[
7.27 \nleq 5,\quad 7.27 \nleq 6,\quad 7.27 \nleq 7,\quad 7.27 \leq 8,\quad 7.27 \leq 9, \quad \ldots
\]
By the condition above, we must then have:
\[
L(7.27) \nleq 5,\quad L(7.27) \nleq 6,\quad L(7.27) \nleq 7,\quad L(7.27) \leq 8,\quad L(7.27) \leq 9, \quad \ldots
\]
From this, we conclude that $L(7.27) = 8$. In general, $L(R)$ is the least integer greater than or equal to $R$, \ie, the ceiling function:
\[
L(r) = \lceil r \rceil.
\]

Thus, the inclusion functor $\mathrm{inc}$ has $\lceil \; \rceil$ as a left adjoint, \ie, $\lceil  \; \rceil \dashv \mathrm{inc}$.
The unit of this adjunction is the natural transformation
$\eta : \id_{\mathbb{R}} \Rightarrow \mathrm{inc} \circ \lceil  \;  \rceil,$
which expresses the inequality $r \leq \lceil r \rceil$ for all $r \in \mathbb{R}$. The counit of the adjunction is the identity, since for any integer $n$, it holds that $\lceil N \rceil = N$.
\end{example}



\begin{definition}
  Let \( F: \catC \to \catD \) and \( G:  \catD \to  \catE \) be functors. It is said that \( G \)  \emph{preserves coproducts} if  whenever $ L $ is a coproduct of \( F \), then \( G(L) \) is a coproduct of \( G \circ F \).
\end{definition}

\begin{theorem}
 Left adjoints preserve coproducts.
\end{theorem}

% usar a def principal e a ds homsets

%adjoints
% example com o floor
%Adjoints preserve coproducts

\subsection{Monoidal categories}
\begin{definition}
A \textbf{monoid} is a triple $(M, \cdot, u)$, where $M$ is a set equipped with 
a binary operation $\cdot \colon M \times M \to M$ and a distinguished element 
$u \in M$ called the \emph{unit}, satisfying the following axioms for all 
$x, y, z \in M$:
\begin{align*}
    \text{(Associativity)} & & x \cdot (y \cdot z) &= (x \cdot y) \cdot z, \\
    \text{(Unit laws)}     & & u \cdot x &= x = x \cdot u.
\end{align*}
\end{definition}

Monoidal categories are named so because they are categories equipped with an additional structure that resembles the structure of monoids.

\begin{comment}
  
\begin{definition}
 A \emph{strict monoidal category} is a category $\catC$ equipped with a bifunctor $\otimes : \catC \times \catC \to \catC$
called the \emph{tensor product}, which is associative, meaning that for all objects $A, B, C \in \catC$,
\[
A \otimes (B \otimes C) = (A \otimes B) \otimes C. 
\]
In addition, there is a distinguished object $I \in \catC$, called the \emph{unit}, that acts as a unit for $\otimes$, satisfying
\[
I \otimes C = C = C \otimes I \quad \text{for all } C \in \catC. 
\]
\end{definition}



\begin{example}
The partially ordered set of natural numbers $\mathbb{N}$ forms a strict monoidal category when equipped with addition, denoted $(\mathbb{N}, +, 0)$.  The tensor product is given by ordinary addition, and the unit object is $0$, since for any $n \in \mathbb{N}$ we have $0 + n = n = n + 0$, and addition is strictly associative.
Moreover, the tensor product is monotonic with respect to the order: if $m \leq m'$ and $n \leq n'$, then $m + n \leq m' + n'$. This order preservation ensures functoriality of the monoidal structure.
A similar argument applies to multiplication: if $m \leq m'$ and $n \leq n'$, then $m \cdot n \leq m' \cdot n'$. Therefore, $(\mathbb{N}, \cdot, 1)$ also forms a strict monoidal category under the same ordered structure.
\end{example}

\end{comment}

\begin{definition}
  A symmetric monoidal category consists of a category $\catC$ equipped with a bifunctor $\otimes : \catC \times \catC \to \catC$
called \emph{tensor product} and a distinguished object $I \in \catC$, called \emph{unit} together with natural isomorphisms
\[
\alpha_{A,B,C} : A \otimes (B \otimes C) \rightarrow (A \otimes B) \otimes C,
\]
\[
\lambda_A :\mathbb{I}\otimes A \rightarrow A, \quad \rho_A : A \otimes\mathbb{I}\rightarrow A,
\]
known as \emph{reassociator}, \emph{left unitor},and \emph{right unitor}, respectively.

Moreover, these natural isomorphisms are required to make the following coherence diagrams commute.
\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes,row sep=3em,column sep=2em,minimum width=1em]
  {
    & (A \otimes B) \otimes (C \otimes D) & \\
   A \otimes (B \otimes (C \otimes D)) &  & ((A \otimes B) \otimes C) \otimes D  \\
    A \otimes ((B \otimes C) \otimes D)  & &  (A \otimes (B \otimes C)) \otimes D \\
  };
  \path[-stealth]
    (m-1-2) edge  node [above] {$\alpha$} (m-2-3)
    (m-3-3) edge  node [right] {$\alpha \otimes \id$} (m-2-3)
    (m-3-1) edge  node [below] {$\alpha$} (m-3-3)
    (m-2-1) edge  node [left] {$\id \otimes \alpha$} (m-3-1)
    (m-2-1) edge  node [above] {$\alpha$} (m-1-2)
    ;
\end{tikzpicture}
\]


\[
\begin{minipage}{0.45\textwidth}
\centering
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes,row sep=3em,column sep=2em,minimum width=1em]
  {
    A \otimes (\mathbb{I} \otimes A) &   & (A \otimes \mathbb{I}) \otimes A \\
     & A \otimes A & \\
  };
  \path[-stealth]
    (m-1-1) edge  node [above] {$\alpha$} (m-1-3)
    (m-1-1) edge  node [left] {$\id \otimes \lambda_A$} (m-2-2)
    (m-1-3) edge  node [right] {$\rho_A \otimes \id$} (m-2-2);
\end{tikzpicture}
\end{minipage}
\quad \quad
\begin{minipage}{0.45\textwidth}
\centering
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes,row sep=3em,column sep=3em,minimum width=1em]
  {
   \mathbb{I}\otimes\mathbb{I}&   &\mathbb{I}\otimes\mathbb{I} \\
     &\mathbb{I}& \\
  };
  \path[-stealth]
    (m-1-1) edge  node [left] {$\lambda_I$} (m-2-2)
    (m-1-3) edge  node [right] {$\rho_I$} (m-2-2);
  \draw[double equal sign distance] (m-1-1) -- (m-1-3);
\end{tikzpicture}
\end{minipage}
\]

\end{definition}






\begin{definition}
  A monoidal category is said to be \emph{symmetric} when it is
equipped with a natural isomorphism $\sw : A \otimes B \rightarrow B \otimes A$ known as \emph{braiding} such that the following diagrams commute.


\[
\begin{minipage}{0.45\textwidth}
\centering
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes,row sep=3em,column sep=3em,minimum width=1em]
  {
    A \otimes B &   & B \otimes A  \\
     & A \otimes B & \\
  };
  \path[-stealth]
    (m-1-1) edge  node [above] {$\sw_{A,B}$} (m-1-3)
    (m-1-3) edge  node [right=0.15cm] {$\sw_{B,A}$} (m-2-2);
  \draw[double equal sign distance] (m-1-1) -- (m-2-2);
\end{tikzpicture}
\end{minipage}
\quad \quad \
\begin{minipage}{0.45\textwidth}
\centering
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes,row sep=3em,column sep=3em,minimum width=1em]
  {
    A \otimes\mathbb{I}&   & \mathbb{I}\otimes A \\
     & A & \\
  };
  \path[-stealth]
    (m-1-1) edge  node [above] {$\sw_{A,I}$} (m-1-3)
    (m-1-1) edge  node [left] {$\rho_A$} (m-2-2)
    (m-1-3) edge  node [right=0.15cm] {$\lambda_A$} (m-2-2);
\end{tikzpicture}
\end{minipage}
\]

$$
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes,row sep=3em,column sep=4em,minimum width=1em]
  {
  A \otimes (B \otimes C)  & (A \otimes B) \otimes C & C \otimes (A \otimes B) \\
  A \otimes (C \otimes B) & (A \otimes C) \otimes B & (C \otimes A) \otimes B\\
  };
  \path[-stealth]
    (m-1-1) edge  node [above] {$\alpha$} (m-1-2)
    (m-1-2) edge  node [above] {$\sw$} (m-1-3)
    (m-1-3) edge  node [right] {$\alpha$} (m-2-3)
    (m-2-2) edge  node [below] {$\sw \otimes \id$} (m-2-3)
    (m-2-1) edge  node [below] {$\alpha$} (m-2-2)
    (m-1-1) edge  node [right] {$\id \otimes \sw$} (m-2-1)
    ;
\end{tikzpicture}
$$

\end{definition}

\begin{definition}
  A monoidal category $\catC$ is  said to be \emph{closed} if for each object
  $A$ in $\catC$ the functor $- \otimes A$ has a right adjoint,
  denoted by $A \multimap -$. 
\end{definition}

\begin{definition}
        A monoidal category $\catC$ with coproducts is called
        \emph{distributive} if for every object $A$ in $\catC$ the
        functor $- \otimes A$ preserves coproducts. Explicitly
        this means that the morphism,
        \[
                [\inl \otimes \id, \inr \otimes \id] : B \otimes A \oplus C \otimes                     A \to (B \oplus C) \otimes A
        \]
        is actually an isomorphism. We will denote the respective inverse
        by $\dist$. Note that if $\catC$ is monoidal closed then it is automatically
        distributive as left adjoints preserve all colimits.
\end{definition}



\begin{example}
Examples of monoidal closed categories with coproducts include $\catSet$, the $\catVect$, and the $\catBan$. In $\catSet$, the tensor product is the cartesian product, the monoidal unit is the singleton set, the coproduct is the disjoint union, and the internal hom consists of all functions between sets. For $\catVect$, the tensor product is the standard tensor product of complex vector spaces, the field of complex number $\mathbb{C}$, the coproduct is the direct sum, and the internal hom is the space of linear maps. Similarly, in $\catBan$ the tensor product is the projective tensor product, the monoidal unit is $\mathbb{R}$, the coproduct is the direct sum equipped with the $L_1$-norm, and the internal hom consists of all functions between sets corresponds to space of short (linear) maps equiped with the operator norm.
\end{example}

\begin{example}
  The (biproduct completion of ) category $\catCPS$ and, consequently, (the coproduct completion of) $\catCPTP$ provide examples of distributive monoidal categories with coproducts that are not closed \cite{selinger2004towards}. Their monoidal structure resembles that of $\catVect$. In this case, $\dist = \id$. We will explore this category in more detail in \autoref{ch:conditionals}.
\end{example}

\begin{theorem}[\emph{Coherence Theorem for Symmetric Monoidal Categories}]
Any diagram in a symmetric monoidal category constructed only from associators $\alpha$, unitors $\lambda$, $\rho$, the symmetry $\sw$, and inverses and their composition and tensor product necessarily commutes.
\end{theorem}


 

 


\todo[inline,size=\normalsize]{Esclarecer questão sobre o que é um terminal map to the unit object (of the monoidal category)}








\section{Interpretation} \label{sec: Lambda Calculus:Interpretation}

\todo[inline,size=\normalsize]{Interpretação geral com categorias} 

\todo[inline,size=\normalsize]{Não esquecer cena de lambda theories a afins, incluir def de equivalence classes -> slided categorias}


In order to define the interpretation of judgments $\Gamma \triangleright v: \mathbb{A}$, it is necessary to establish some notation first. Let $\catC$ be a symmetric monoidal category and $A$, $B$ and $C$ be objects of this category. For all morphisms $f: A \otimes B \xrightarrow{} C$, the morphism $\overline{f} : A \xrightarrow{} (B \multimap C)$ denotes the corresponding curried version. Moreover, there is the application morphism, $\text{app}: (A \multimap B) \otimes A \rightarrow B$.  

For all ground types $X \in G$  the interpretation of $[\![X]\!]$  is postulated  to be an object of $\catC$. Types are interpreted inductively using the unit $\mathbb{I}$, the tensor $\otimes$, and the linear map $\multimap$. Given a non-empty context $\Gamma=\Gamma',x: \mathbb{A}$, its interpretation is defined by $[\![\Gamma',x: \mathbb{A}]\!] = [\![\Gamma']\!] \otimes [\![\mathbb{A}]\!]$ if $\Gamma'$ is non-empty and $[\![\Gamma',x: \mathbb{A}]\!] = [\![\mathbb{A}]\!]$ otherwise. The empty context $-$ is interpreted as $[\![-]\!] = \mathbb{I}$. Given $X_{1}, . . . ,X_{n} \in V$, the $n$-tensor $(\ldots (X_1 \otimes X_2) \otimes \ldots ) \otimes X_{n}$ is denoted as $X_1 \otimes \ldots \otimes X_{n}$, and similarly for morphisms. 


``Housekeeping" morphisms are employed to handle interactions between context interpretation and the vectorial model. Given $\Gamma_{1}, \ldots, \Gamma_{n}$, the morphism that splits $[\![\Gamma_{1}, \ldots, \Gamma_{n}]\!]$ into $[\![\Gamma_{1}]\!] \otimes \ldots \otimes [\![\Gamma_{n}]\!]  $ is denoted by $\text{sp}_{\Gamma_1;\ldots;\Gamma_n}: [\![\Gamma_{1}, \ldots, \Gamma_{n}]\!] \xrightarrow{} [\![\Gamma_{1}]\!] \otimes \ldots \otimes [\![\Gamma_{n}]\!] $. For $n=1$, $\text{sp}_{\Gamma_1} = \text{id}$.
Let $\Gamma_1$ and $\Gamma_2$ be two contexts, $\text{sp}_{\Gamma_1, \Gamma_2} \rightarrow \Gamma_1\otimes \Gamma_2$ is defined as:
\begin{equation*}
  \text{sp}_{-; \Gamma_2} = \lambda^{-1} \hspace{1cm} \text{sp}_{\Gamma_1; -} = \rho^{-1} \hspace{1cm} \text{sp}_{\Gamma_1;x:\mathbb{A}} = \id \hspace{1cm} \text{sp}_{\Gamma_1; \Delta, x: \mathbb{A}} = \alpha \cdot (\text{sp}_{\Gamma_1; \Delta} \otimes \id)
\end{equation*}
For $n>2$, $\text{sp}_{\Gamma_1;\ldots;\Gamma_n}$ is is defined recursively based on the previous definition, using induction on $n$:
\begin{equation*}
  \text{sp}_{\Gamma_1;\ldots;\Gamma_n} = (\text{sp}_{\Gamma_1;\ldots;\Gamma_{n-1}} \otimes \id )\cdot \text{sp}_{\Gamma_1, \ldots, \Gamma_{n-1} ;\Gamma_n}
\end{equation*}
On the other hand, $\text{jn}_{\Gamma_1;\ldots;\Gamma_n}$ denotes the inverse of $\text{sp}_{\Gamma_1;\ldots;\Gamma_n}$. Next, given $\Gamma, x : \mathbb{A}, y : \mathbb{B},\Delta$, the morphism permuting $x$ and $y$ is denoted by $\text{exch}_{\Gamma, x : \mathbb{A}, y : \mathbb{B},\Delta}: [\![\Gamma,\underline{ x : \mathbb{A}, y : \mathbb{B}},\Delta]\!] \xrightarrow{} [\![\Gamma, y : \mathbb{B}, x : \mathbb{A}, \Delta]\!] $ and defined as:
\begin{equation*}
  \text{exch}_{\Gamma, \underline{ x : \mathbb{A}, y : \mathbb{B}},\Delta} = \text{jn}_{\Gamma; y:\mathbb{B}, x:\mathbb{A};\Delta} \cdot (\id \otimes \text{sw} \otimes \id ) \cdot \text{sp}_{\Gamma; x:\mathbb{A}, y:\mathbb{B};\Delta}
\end{equation*} 


The shuffling morphism $\text{sh}_{E}: [\![E]\!] \xrightarrow{} [\![\Gamma_1, \ldots, \Gamma_n ]\!]$ is defined as a suitable composition of exchange morphisms.


For every operation symbol $f: \mathbb{A}_{1}, \ldots, \mathbb{A}_{n} \xrightarrow{} \mathbb{A}$ it is assumed the existence of an morphism $[\![f]\!]: [\![\mathbb{A}_{1}]\!] \otimes \ldots \otimes [\![\mathbb{A}_{n}]\!] \xrightarrow{}  [\![\mathbb{A}]\!] $.
The interpretation of judgments is defined by induction over derivations according to the rules in \autoref{fig:denotational_sem} \cite{dahlqvist2022syntactic}.
\vspace{-7pt}
\begin{figure} [H]
\begin{equation*}
\begin{split}
\begin{aligned}
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
      [\![\Gamma_{i} \triangleright v_{i}: \mathbb{A}_{i} ]\!]=m_{i}  \quad f: \mathbb{A}_{1}, \ldots, \mathbb{A}_{n} \xrightarrow{} \mathbb{A} \in \Sigma \quad E \in \text{Sf}(\Gamma_{1}; \ldots; \Gamma_{n})\\
    \hline
  [\![E \triangleright f( v_{1},\ldots,v_{n}): \mathbb{A} ]\!] = [\![ f]\!] \cdot (m_{1}\otimes \ldots \otimes m_{n}) \cdot \text{sp}_{\Gamma_1;\ldots;\Gamma_n}\cdot \text{sh}_{E}
\end{array}
$
\end{minipage}
\hspace{208pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
      \\
    \hline
  [\![ x:\mathbb{A} \triangleright x:\mathbb{A}]\!] = \text{I}_{[\![\mathbb{A} ]\!]}
\end{array}
$ \end{minipage} \\
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     \\  
    \hline
   [\![ - \triangleright *: \mathbb{I}]\!] = \text{I}_{[\![\mathbb{I} ]\!]}
\end{array}
$
\end{minipage}
\hspace{-34pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
      [\![\Gamma \triangleright v: \mathbb{A} \otimes \mathbb{B} ]\!]=m  \quad [\![\Delta,x: \mathbb{A}, y: \mathbb{B}  \triangleright w: \mathbb{D} ]\!] =n  \quad E \in \text{Sf}(\Gamma;\Delta)\\
    \hline
  [\![ E\triangleright \text{pm } v \text{ to } x \otimes y. w :\mathbb{D}]\!] = n \cdot \text{jn}_{\Delta;\mathbb{A};\mathbb{B}} \cdot \alpha \cdot \text{sw}\cdot (m \otimes \text{I}) \cdot \text{sp}_{\Gamma;\Delta} \cdot \text{sh}_{E}
\end{array}
$ \end{minipage} \\
&
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}  
     [\![ \Gamma \triangleright v: \mathbb{A} ]\!] =m \quad [\![\Delta \triangleright w: \mathbb{B} ]\!]=n \quad E \in \text{Sf}(\Gamma;\Delta) \\
    \hline
  [\![ E \triangleright v \otimes w: \mathbb{A} \otimes \mathbb{B} ]\!] = (m \otimes n) \cdot \text{sp}_{\Gamma;\Delta} \cdot \text{sh}_{E}
\end{array} 
$
\end{minipage}\\
&
 \begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c} 
    [\![\Gamma \triangleright v: \mathbb{I} ]\!]=m  \quad [\![\Delta \triangleright w: \mathbb{A}]\!]=n \quad E \in \text{Sf}(\Gamma;\Delta)  \\
    \hline
  [\![E \triangleright v \text { to } *.w: \mathbb{A} ]\!]=n \cdot \lambda \cdot (m \otimes \text{I}) \cdot \text{sp}_{\Gamma;\Delta} \cdot \text{sh}_{E}
\end{array}
$ \end{minipage} 
\hspace{130 pt}
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c} 
     [\![\Gamma,x:\mathbb{A} \triangleright v: \mathbb{B} ]\!] = m \\
    \hline
   [\![ \Gamma \triangleright \lambda x:\mathbb{A} . \hspace{2pt } v: \mathbb{A} \multimap \mathbb{B}]\!] = \overline{m \cdot \text{jn}_{\Gamma;\mathbb{A}}}
\end{array}
$
\end{minipage} \\
&
 \begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c} 
     [\![\Gamma \triangleright v: \mathbb{A} \multimap \mathbb{B} ]\!] = m \quad [\![  \Delta \triangleright w: \mathbb{A} ]\!] =n \quad E \in S\hspace{-3pt}f(\Gamma;\Delta)  \\
    \hline
  [\![ E \triangleright v w: \mathbb{B} ]\!] = \text{app} \cdot (m \otimes n) \cdot \text{sp}_{\Gamma;\Delta} \cdot \text{sh}_{E}
\end{array}
$ \end{minipage}
\hspace{190 pt} %[\![ ]\!]
\begin{minipage}[t]{0.3\textwidth}
$\begin{array}{c}
     [\![\Gamma \triangleright v: \mathbb{A}]\!]  = f \\
    \hline
   [\![ \Gamma \triangleright \text{dis}(v):  \mathbb{I} ]\!] = \text{Tr} \cdot f
\end{array}
$
\end{minipage}
\end{aligned}
\end{split}
\end{equation*}
\caption{Judgment interpretation}
\label{fig:denotational_sem} 
\end{figure}

The following diagrams are useful to better understand the interpretation of judgements given in \autoref{fig:denotational_sem}.
\begin{align*}
  & \llbracket \text{ax} \rrbracket : & [\![E]\!] & \xrightarrow{\hspace{2pt}\text{sh}_{E}\hspace{2pt}}   [\![\Gamma_1,\ldots,\Gamma_n ]\!]   \xrightarrow{\hspace{1pt}\text{sp}_{\Gamma;\Delta}\hspace{1pt}}  \llbracket \Gamma_1 \rrbracket \otimes \ldots \otimes \llbracket \Gamma_n \rrbracket  \\
  & & & \xrightarrow{\hspace{2pt}m_1 \otimes \ldots \otimes m_n \hspace{2pt}} \llbracket \mathbb{A}_1 \rrbracket \otimes \ldots \otimes \llbracket \mathbb{A}_n \rrbracket \xrightarrow{\hspace{2pt}\llbracket f \rrbracket \hspace{2pt}} \llbracket \mathbb{A} \rrbracket \\
  & \llbracket \text{hyp} \rrbracket : & \llbracket \mathbb{A} \rrbracket & \xrightarrow{\hspace{2pt}I_{\llbracket \mathbb{A}\rrbracket}\hspace{2pt}} \llbracket \mathbb{A}\rrbracket \\
  & \llbracket \mathbb{I}_i \rrbracket :&  \llbracket \mathbb{I} \rrbracket & \xrightarrow{\hspace{2pt}I_{\llbracket \mathbb{I}\rrbracket}\hspace{2pt}}  \llbracket \mathbb{I} \rrbracket\\
  &\llbracket \otimes_e \rrbracket : & [\![E]\!] & \xrightarrow{\hspace{2pt}\text{sh}_{E}\hspace{2pt}}   [\![\Gamma,\Delta ]\!]   \xrightarrow{\hspace{1pt}\text{sp}_{\Gamma;\Delta}\hspace{1pt}}  [\![\Gamma ]\!] \otimes [\![\Delta ]\!] \xrightarrow{ m \hspace{1pt} \otimes \hspace{1pt} \text{I}} ([\![\mathbb{A} ]\!] \otimes [\![\mathbb{B} ]\!]) \otimes [\![\Delta ]\!]   \\
     & &  &\xrightarrow{\hspace{2pt}\text{sw}\hspace{2pt}}  [\![\Delta ]\!] \otimes ([\![\mathbb{A} ]\!] \otimes [\![\mathbb{B} ]\!]) \xrightarrow{\hspace{3pt}\alpha\hspace{3pt}}  ([\![\Delta ]\!] \otimes [\![\mathbb{A} ]\!]) \otimes [\![\mathbb{B} ]\!] \xrightarrow{\hspace{2pt}\text{jn}_{\Delta; \mathbb{A}; \mathbb{B} }\hspace{2pt}}  \llbracket \Delta, \mathbb{A},\mathbb{B}  \rrbracket  \\
     &&& \xrightarrow{\hspace{3pt}n\hspace{3pt}} \llbracket \mathbb{D} \rrbracket \\
     &\llbracket \otimes_i \rrbracket : & [\![E]\!] & \xrightarrow{\hspace{2pt}\text{sh}_{E}\hspace{2pt}}   [\![\Gamma,\Delta ]\!]   \xrightarrow{\hspace{1pt}\text{sp}_{\Gamma;\Delta}\hspace{1pt}}  [\![\Gamma ]\!] \otimes [\![\Delta ]\!]  \xrightarrow{\hspace{2pt} m \hspace{1pt} \otimes \hspace{1pt} n \hspace{2pt}} [\![\mathbb{A} ]\!] \otimes [\![\mathbb{B} ]\!] \\
     &\llbracket \mathbb{I}_e \rrbracket :  & [\![E]\!] & \xrightarrow{\hspace{2pt}\text{sh}_{E}\hspace{2pt}}   [\![\Gamma,\Delta ]\!]   \xrightarrow{\hspace{1pt}\text{sp}_{\Gamma;\Delta}\hspace{1pt}}  [\![\Gamma ]\!] \otimes [\![\Delta ]\!] \xrightarrow{ m \hspace{1pt} \otimes \hspace{1pt} \text{I}} [\![\mathbb{I} ]\!]\otimes [\![\Delta ]\!] \xrightarrow{\hspace{2pt} \lambda \hspace{3pt}} [\![\Delta ]\!]  \xrightarrow{\hspace{2pt} n \hspace{3pt}}  \llbracket \mathbb{A} \rrbracket    \\
      &\llbracket \multimap_i \rrbracket : & \llbracket \Gamma \rrbracket \otimes \llbracket \mathbb{A} \rrbracket & \xrightarrow{\hspace{2pt} \overline{m \cdot \text{jn}_{\Gamma;\mathbb{A}}}  \hspace{2pt}}  \llbracket \mathbb{A} \rrbracket \multimap \llbracket \mathbb{B} \rrbracket  \hspace{60pt} (\llbracket \Gamma \rrbracket \otimes \llbracket \mathbb{A} \rrbracket  \xrightarrow{\hspace{2pt} \text{jn}_{\Gamma; \mathbb{A}} \hspace{2pt}} \llbracket \Gamma, \mathbb{A} \rrbracket  \xrightarrow{\hspace{2pt} m \hspace{2pt}}  \llbracket \mathbb{B} \rrbracket )\\
      &\llbracket \multimap_e \rrbracket : & [\![E]\!] & \xrightarrow{\hspace{2pt}\text{sh}_{E}\hspace{2pt}}   [\![\Gamma,\Delta ]\!]   \xrightarrow{\hspace{1pt}\text{sp}_{\Gamma;\Delta}\hspace{1pt}}  [\![\Gamma ]\!] \otimes [\![\Delta ]\!]  \xrightarrow{\hspace{2pt} m \hspace{1pt} \otimes \hspace{1pt} n \hspace{2pt}} \llbracket \mathbb{A} \rrbracket \multimap \llbracket \mathbb{B} \rrbracket \otimes \llbracket \mathbb{A} \rrbracket  \xrightarrow{\hspace{2pt} \text{app} \hspace{2pt}} \llbracket \mathbb{B} \rrbracket \\
      &\llbracket \text{dis} \rrbracket : & [\![\Gamma]\!] & \xrightarrow{\hspace{2pt} f \hspace{2pt}} \llbracket \mathbb{A} \rrbracket \xrightarrow{\hspace{2pt} \text{!} \hspace{2pt}} \llbracket \mathbb{I} \rrbracket
      %& \llbracket \Gamma \rrbracket \otimes \llbracket \mathbb{A} \rrbracket  \xrightarrow{\hspace{2pt} \text{jn}_{\Gamma; \mathbb{A}} \hspace{2pt}} \llbracket \Gamma, \mathbb{A} \rrbracket  \xrightarrow{\hspace{2pt} m \hspace{2pt}}  \llbracket \mathbb{B} \rrbracket 
\end{align*} 


Regarding the interpretation of the exhange and substitution properties, we have the following lemma.

\begin{lemma}
  For any judgements $\Gamma, x: \mathbb{A}, y: \mathbb{B}, \Delta \triangleright v : \mathbb{D}$, $\Gamma, x: \mathbb{A} \triangleright v: \mathbb{B}$, and $\Delta \triangleright w: \mathbb{A}$, the following holds:
\begin{equation*}
\begin{split}
  \llbracket \Gamma, x: \mathbb{A}, y: \mathbb{B}, \Delta \triangleright v : \mathbb{D} \rrbracket & = \llbracket \Gamma,  y: \mathbb{B}, x: \mathbb{A}, \Delta \triangleright v : \mathbb{D} \rrbracket \cdot \text{exch}_{\Gamma, \underline{x: \mathbb{A}, y: \mathbb{B}}, \Delta}\\
  \llbracket \Gamma,\Delta \triangleright v[w/x]: \mathbb{B} \rrbracket & = \llbracket \Gamma, x: \mathbb{A} \triangleright v: \mathbb{B} \rrbracket \cdot \text{jn}_{\Gamma;\mathbb{A}} \cdot (\text{I} \otimes \llbracket \Delta \triangleright w: \mathbb{A} \rrbracket ) \cdot \text{sp}_{\Gamma; \Delta} 
\end{split}
\end{equation*}

\end{lemma}



\begin{theorem}
The equations presented in \autoref{fig:equations-linear-lambda} are sound with respect to judgement interpretation. 
More specifically, if \(\Gamma \vljud v = w : \typeA\) is one of the equations in \autoref{fig:equations-linear-lambda}, then 
$\llbracket \Gamma \vljud v : A  \rrbracket = \llbracket  \Gamma \vljud w : \typeA\rrbracket.$
\end{theorem}


\begin{definition} [Models of linear \(\lambda\)-theories]
Consider a linear \(\lambda\)-theory \(((G, \Sigma), Ax)\) and a symmetric monoidal closed category \(\catC\). 
Suppose that for each \(X \in G\), we have an interpretation \(\llbracket X \rrbracket\), which is an object of \(\catC\), 
and analogously for the operation symbols in \(\Sigma\). 
This interpretation structure is a \emph{model} of the theory if all axioms in \(Ax\) are satisfied by the interpretation.
\end{definition}

\begin{theorem}[Soundness and Completeness]
Consider a linear $\lambda$-theory $\mathscr{T}$. Then an equation 
$\Gamma \vljud v = w : A$
is a theorem of $\mathscr{T}$ if and only if it is satisfied by all models of the theory.
\end{theorem}

 \begin{definition}
    A \emph{metric space} a pair $(X, d)$ where $X$ is a set and $d: X \times X \to \mathbb{R}_0^+$ is a function known as \emph{distance} satisfying:
    \begin{enumerate}
        \item $0 \leq d(x, y)$, with equality if and only if $x = y$,
        \item $d(x, y) = d(y, x)$,
        \item $d(x, z) \leq d(x, y) + d(y, z)$ for all $x, y, z \in X$.
    \end{enumerate}
  \end{definition}
  
  \begin{definition}
    $\catMet$ denotes the category whose objects are metric spaces and whose morphisms are non-expansive maps, \ie, functions that do not increase the distance between points. More precisely, for two metric spaces $(X, d_X)$ and $(Y, d_Y)$, a morphism $f: (X, d_X) \to (Y, d_Y)$ is a function $f: X \to Y$ such that
$$
d_Y(f(x), f(y)) \leq d_X(x, y) \quad \text{for all } x, y \in X.
$$
  \end{definition}
    


\begin{definition}
 A category $\catC$ is $\catMet$\emph{-enriched} (or simply a $\catMet$-category) if for each pair of objects $A$ and $B$ in $\catC$, the hom-set $\catC(A, B)$ is a metric space and if the composition of $\catC$-morphisms,
 $$(\comp): \catC(A, B) \otimes \catC(B, C) \rightarrow \catC(A, C)$$
 is a functor in the category of metric spaces. 
 Given two $\catMet$-enriched categories $\catC$ and $\catD$ and a functor $F : \catC\to \catD$, we call 
$F$ a \emph{$\catMet$-enriched functor} (or simply, a \emph{$\catMet$-functor}) if for all objects $A, B$ in $\catC$, 
the map $F_{A,B} : \catC(A,B) \to \catC(FA, FB)$ is a $\catMet$-functor. 
An adjunction $\catC : F \dashv G : \catD$ is called \emph{$\catMet$-enriched} if for all objects $A \in |\catC|$ 
and $B \in |\catD|$ there exists a $\catMet$-isomorphism
\[
\mathcal{D}(FA, B) \cong \catC(A, GB)
\]
natural in $A$ and $B$.
\end{definition}


\begin{definition}
A \emph{$\catMet$-enriched symmetric monoidal category} $\catC$ is a category that is both symmetric monoidal and $\catMet$-enriched, such that the bifunctor
\[
\otimes : \catC \times \catC \to \catC
\]
is a $\catMet$-functor. 
\end{definition}

\begin{definition}
  A \emph{$\catMet$-enriched symmetric monoidal closed category} $\catC$ is a category that is both symmetric monoidal closed and a $\catMet$-enriched monoidal category, such that the adjunction
\[
(- \otimes A) \dashv (A \multimap -)
\]
is a $\catMet$-adjunction.
\end{definition}

\begin{definition}
  It is said that a metric equation $\Gamma \vljud v =_{q} w : A$ is \emph{satisfied} by the interpretation presented in \autoref{fig:denotational_sem} if
\[
q \leq d( \llbracket \Gamma \vljud v : \typeA \rrbracket,\, \llbracket  \Gamma \vljud w : \typeA \rrbracket).
\]
\end{definition}


\begin{theorem}
The rules listed in \autoref{fig:equations-linear-lambda} and \autoref{fig:metric deductive system} are sound for $\catMet$-enriched monoidal closed categories $\catC$. Specifically, if $\Gamma \vljud v =_{q} w : \typeA$
results from the rules in \autoref{fig:equations-linear-lambda} and \autoref{fig:metric deductive system}, then 
$q \leq d(\llbracket \Gamma  \vljud  v : \typeA \rrbracket,\, \llbracket \Gamma \vljud  w : \typeA\llbracket)$.
\end{theorem}

\begin{definition}[Models of linear metric $\lambda$-theories]
Consider a linear metric $\lambda$-theory $((G, \Sigma), Ax$ and a $\catMet$-enriched autonomous category $\catC$. 
Suppose that for each $X \in G$, we are given an interpretation $\llbracket X \rrbracket$ as an object of $\catC$, and analogously for the operation symbols in $\Sigma$. 
This interpretation structure is a \emph{model} of the theory if all axioms in $Ax$ are satisfied by the interpretation.
\end{definition}


\begin{definition}
  
For two types $\typeA$ and $\typeB$ of a metric $\lambda$-theory $\mathscr{T}$, consider the class \text{Values}$(\typeA,\typeB)$ of values $v$ such that $x : \typeA \vljud v : \typeB$. We equip $\text{Values}(\typeA,\typeB)$ with the function $d :\text{Values}(\typeA,\typeB) \times \text{Values}(\typeA,\typeB) \rightarrow \mathbb{R}^{+}_0$ defined by,
$$d(v,w)=\inf{\{q \, \vert \, v=_q w \text{ is a theorem } \mathscr{T} \}}$$

We then consider the equivalence relation $\sim$ on $\text{Values}(\typeA,\typeB)$ induced by $d$:
\[
v \sim w \quad \text{if and only if} \quad d(v,w) = 0.
\]

 The resulting quotient $\text{Values}(\typeA,\typeB)/{\sim}$ forms a separated $\catMet$-enriched category. We call  $\mathscr{T} $\emph{varietal} if (\text{Values}$(\typeA,\typeB),d)$/$\sim$ is a small  $\catMet$-enriched category for all types $\typeA$ and $\typeB$. 

 \end{definition}

\begin{theorem}[ Soundness and Completeness]
Consider a varietal metric $\lambda$-theory. A metric equation in context
$\Gamma \vljud v =_{q} w : \typeA$
is a theorem if and only if it holds in all models of the theory.
\end{theorem}





